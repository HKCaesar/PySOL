{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "import gdal\n",
    "from numpy import asarray, zeros, ma, flipud, pi, exp, cos, radians\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.mlab import find\n",
    "# matplotlib.use('Agg')\n",
    "from pylab import *\n",
    "\n",
    "# from PIL import Image\n",
    "from scipy.signal import wiener\n",
    "import pyresample as pr\n",
    "# from pyproj import Proj\n",
    "from scipy.interpolate import RectSphereBivariateSpline\n",
    "import simplekml\n",
    "import multiprocessing\n",
    "\n",
    "sys.path.append('/media/SOLabNFS2/tmp/sentinel/')\n",
    "\n",
    "import readS1\n",
    "from readS1 import *\n",
    "import distancelib\n",
    "import gshhs_rasterize\n",
    "\n",
    "sys.path.append('/usr/bin')\n",
    "from gdal2tiles import GDAL2Tiles\n",
    "\n",
    "# sys.path.append(\n",
    "#     os.path.dirname(\n",
    "#         os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "#     )\n",
    "# )\n",
    "from big_image import save_big_image\n",
    "\n",
    "__author__ = 'Alexander Myasoedov'\n",
    "__email__ = 'mag@rshu.ru'\n",
    "__created__ = datetime.datetime(2014, 10, 28)\n",
    "__modified__ = datetime.datetime(2015, 6, 19)\n",
    "__version__ = \"1.0\"\n",
    "__status__ = \"Development\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mkdirs(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def PR_Mouche(theta, phi):\n",
    "    A_0 = 0.00650704\n",
    "    B_0 = 0.128983\n",
    "    C_0 = 0.992839\n",
    "    A_HALF_PI = 0.00782194\n",
    "    B_HALF_PI = 0.121405\n",
    "    C_HALF_PI = 0.992839\n",
    "    A_PI = 0.00598416\n",
    "    B_PI = 0.140952\n",
    "    C_PI = 0.992885\n",
    "\n",
    "    P_0 = A_0 * exp(B_0 * theta) + C_0\n",
    "    P_HALF_PI = A_HALF_PI * exp(B_HALF_PI * theta) + C_HALF_PI\n",
    "    P_PI = A_PI * exp(B_PI * theta) + C_PI\n",
    "\n",
    "    C0 = (P_0 + P_PI + 2 * P_HALF_PI) / 4\n",
    "    C1 = (P_0 - P_PI) / 2\n",
    "    C2 = (P_0 + P_PI - 2 * P_HALF_PI) / 4\n",
    "\n",
    "    P = C0 + C1 * cos(radians(phi)) + C2 * cos(radians(2 * phi))\n",
    "\n",
    "    return P\n",
    "\n",
    "def ncepGFSmodel2swath(lats, lons, data, lats_2, lons_2):\n",
    "    func = RectSphereBivariateSpline(lats, lons, data)\n",
    "    data_2 = func.ev(\n",
    "        lats_2.ravel()*pi/180, lons_2.ravel()*pi/180\n",
    "    ).reshape(lats_2.shape)\n",
    "    return data_2\n",
    "\n",
    "def create_KML_asar(area_extent, savepath):\n",
    "    kml = simplekml.Kml()\n",
    "\n",
    "    pol = kml.newpolygon(name='area_extent', visibility=1)\n",
    "    pol.tessellate = 1\n",
    "\n",
    "    pol.altitudemode = 'clampToGround'\n",
    "    pol.outerboundaryis.coords = [(min(area_extent[0], area_extent[2]),\n",
    "                                   min(area_extent[1], area_extent[3])),\n",
    "                                  (max(area_extent[0], area_extent[2]),\n",
    "                                   max(area_extent[1], area_extent[3]))]\n",
    "    if type(savepath) == list:\n",
    "        for _savepath in savepath:\n",
    "            kml.save(_savepath)\n",
    "    else:\n",
    "        kml.save(savepath)\n",
    "\n",
    "def create_asar_tiles(png_filename, tiles_output_dir, proj):\n",
    "    local_argv = ['/usr/bin/gdal2tiles.py', '-p', 'raster', '-r', 'cubic',\n",
    "                  '-s', proj, png_filename, tiles_output_dir]\n",
    "    argv = gdal.GeneralCmdLineProcessor(local_argv)\n",
    "    if argv:\n",
    "        gdal2tiles = GDAL2Tiles(argv[1:])\n",
    "        gdal2tiles.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processingS1(inpath, fn):\n",
    "    s1 = readS1(inpath=inpath, fn=fn)\n",
    "    # s1.__dict__['raw_counts']\n",
    "\n",
    "    # get vars from s1 class\n",
    "    # polarization\n",
    "    # raw_counts\n",
    "    # incidenceAngle_2\n",
    "    # sigmaNought_2\n",
    "    # noiseLut_2\n",
    "    # sigma0\n",
    "    # lons_2\n",
    "    # lats_2\n",
    "    # GEOgrid\n",
    "    # cLUTs\n",
    "    # nLUTs\n",
    "    # manifest\n",
    "    polarization = s1.polarization\n",
    "    incidenceAngle_2 = s1.incidenceAngle_2\n",
    "    sigma0 = s1.sigma0\n",
    "    lons_2 = s1.lons_2\n",
    "    lats_2 = s1.lats_2\n",
    "    GEOgrid = s1.GEOgrid\n",
    "    manifest = s1.manifest\n",
    "\n",
    "    del s1\n",
    "    gc.collect()\n",
    "\n",
    "    scale = 32\n",
    "\n",
    "    sigma0w = {}\n",
    "    roughness = {}\n",
    "\n",
    "    print \"Scale set to: \\'%s\\' \" % scale\n",
    "\n",
    "    for p in polarization:\n",
    "        print \"Filtering Image: \\'%s\\' polarization\" % p\n",
    "\n",
    "        # filter the image\n",
    "        sigma0w[p] = wiener(\n",
    "            sigma0[p][::scale, ::scale], mysize=(7, 7), noise=None\n",
    "        )\n",
    "        # sigma0w[p] = sigma0[p]\n",
    "\n",
    "    del sigma0\n",
    "    gc.collect()\n",
    "\n",
    "    # S1 Pixel resolution\n",
    "    # we use pxlResSAR for further GSHHS rasterizing and\n",
    "    # reprojecting data with pyresample\n",
    "\n",
    "    lonlim = (lons_2[::scale, ::scale].min(), lons_2[::scale, ::scale].max())\n",
    "    latlim = (lats_2[::scale, ::scale].min(), lats_2[::scale, ::scale].max())\n",
    "\n",
    "    # enlarge lonlims for cropping a bit larger area for masking\n",
    "    lonlimGSHHS = (lonlim[0]-1.0, lonlim[1]+1.0)\n",
    "    latlimGSHHS = (latlim[0]-1.0, latlim[1]+1.0)\n",
    "\n",
    "    # Get first guess pixel resolution\n",
    "    pxlResSARm = asarray(\n",
    "        distancelib.getPixelResolution(\n",
    "            lats_2[::scale, ::scale], lons_2[::scale, ::scale],\n",
    "            lons_2[::scale, ::scale].shape, 'km'\n",
    "        )\n",
    "    )*1e3\n",
    "    pxlResSARdeg = asarray(\n",
    "        distancelib.getPixelResolution(\n",
    "            lats_2[::scale, ::scale], lons_2[::scale, ::scale],\n",
    "            lons_2[::scale, ::scale].shape, 'deg'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Define areas with pyresample\n",
    "    swath_def = pr.geometry.SwathDefinition(\n",
    "        lons=lons_2[::scale, ::scale], lats=lats_2[::scale, ::scale]\n",
    "    )\n",
    "\n",
    "    area_def_4326 = swath_area_def(name='Temporal SWATH EPSG Projection 4326',\n",
    "                                   proj='eqc', lonlim=lonlimGSHHS,\n",
    "                                   latlim=latlimGSHHS, ellps=\"WGS84\",\n",
    "                                   res=pxlResSARm)\n",
    "\n",
    "    # Get the SAR pixel resolution from the area_def\n",
    "    # for further identical shapes\n",
    "    up = min(latlimGSHHS)\n",
    "    down = max(latlimGSHHS)\n",
    "    left = min(lonlimGSHHS)\n",
    "    right = max(lonlimGSHHS)\n",
    "    area_extent_deg = (left, down, right, up)\n",
    "\n",
    "    area_extent_deg_shape = area_def_4326.shape\n",
    "\n",
    "    pxlResSARdeg = asarray(\n",
    "        (abs(area_extent_deg[2] - area_extent_deg[0]) /\n",
    "            float(area_extent_deg_shape[1]),\n",
    "         abs(area_extent_deg[3] - area_extent_deg[1]) /\n",
    "            float(area_extent_deg_shape[0]))\n",
    "    )\n",
    "\n",
    "    pxlResSARm = asarray(\n",
    "        (area_def_4326.pixel_size_x, area_def_4326.pixel_size_y)\n",
    "    )\n",
    "    print \"S1 cell resolution, %s deg\" % str(pxlResSARdeg)\n",
    "    print \"S1 cell resolution, %s m\" % str(pxlResSARm)\n",
    "\n",
    "    # Apply Mask from GSHHS\n",
    "    reload(gshhs_rasterize)\n",
    "\n",
    "    # ESRI shapefile containing land polygons\n",
    "    shapefile = '/media/SOLabNFS/store/auxdata/coastline/GSHHS_shp/f/GSHHS_f_L1.shp'\n",
    "\n",
    "    # reproject GSHHS onto S1 grid before calculations\n",
    "    print \"Rasterizing Land Mask\"\n",
    "    mask_arr_4326 = gshhs_rasterize.gshhs_rasterize_4326(\n",
    "        lonlimGSHHS, latlimGSHHS, pxlResSARdeg, area_def_4326.shape,\n",
    "        True, shapefile\n",
    "    )\n",
    "\n",
    "    del pxlResSARdeg\n",
    "\n",
    "    mask_arr_swath = pr.kd_tree.resample_nearest(\n",
    "        area_def_4326, mask_arr_4326, swath_def,\n",
    "        radius_of_influence=4*pxlResSARm.max(), epsilon=0.5, fill_value=None\n",
    "    )\n",
    "\n",
    "    print area_def_4326.shape, mask_arr_4326.shape\n",
    "    print mask_arr_swath.shape, sigma0w[p].shape, swath_def.shape\n",
    "\n",
    "    # Nice Image (Roughness)\n",
    "    sigma0wAvg = {}\n",
    "    roughnessNrmlzd = {}\n",
    "\n",
    "    if len(polarization[0]) >= 2:  # if 2 polarizations\n",
    "        for p in polarization:\n",
    "            print \"Nice Image: \\'%s\\' polarization\" % p\n",
    "            roughness[p] = ma.masked_where(mask_arr_swath, sigma0w[p])\n",
    "            sigma0wAvg[p] = ma.median(roughness[p], axis=0)\n",
    "            roughnessNrmlzd[p] = (roughness[p]-sigma0wAvg[p])/sigma0wAvg[p]\n",
    "    elif len(polarization[0]) == 1:  # if only 1 polarization\n",
    "        p = polarization\n",
    "        print \"Nice Image: \\'%s\\' polarization\" % p\n",
    "        roughness[p] = ma.masked_where(mask_arr_swath, sigma0w[p])\n",
    "        sigma0wAvg[p] = ma.median(roughness[p], axis=0)\n",
    "        roughnessNrmlzd[p] = (roughness[p]-sigma0wAvg[p])/sigma0wAvg[p]\n",
    "\n",
    "    del roughness, sigma0wAvg\n",
    "\n",
    "    # Adding Model wind\n",
    "\n",
    "    # import xmltodict\n",
    "\n",
    "    # zf = zipfile.ZipFile(inpath+fn, 'r')\n",
    "    # manifest = zf.read(fn[:-4] + '.SAFE/manifest.safe')\n",
    "    # manifest = xmltodict.parse(manifest) # Parse the read document string\n",
    "    # zf.close()\n",
    "\n",
    "    startTime = datetime.datetime.strptime(\n",
    "        manifest['xfdu:XFDU']['metadataSection']['metadataObject'][12]['metadataWrap']['xmlData']['safe:acquisitionPeriod']['safe:startTime'],\n",
    "        \"%Y-%m-%dT%H:%M:%S.%f\"\n",
    "    )\n",
    "\n",
    "    ncepGFSmodelWind = ncepGFSmodel(startTime, lats_2, lons_2)\n",
    "\n",
    "    # Reprojecting data\n",
    "    # Pixel resolution\n",
    "    # we use pxlResWind/pxlResSAR for further pyresample\n",
    "    # radius_of_influence and sigmas\n",
    "    pxlResWind = asarray(\n",
    "        distancelib.getPixelResolution(\n",
    "            ncepGFSmodelWind['lats_wind'],\n",
    "            ncepGFSmodelWind['lons_wind'],\n",
    "            ncepGFSmodelWind['lons_wind'].shape, 'km'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Note pxlResWind is in KM, multiply by 1e3 for meters\n",
    "    print \"S1 cell resolution, %s m\" % pxlResSARm\n",
    "    print \"Wind cell resolution, %s km\" % pxlResWind\n",
    "\n",
    "    # reproject NCEP onto S1 grid before calculations\n",
    "    # Using RectSphereBivariateSpline - Bivariate spline\n",
    "    # approximation over a rectangular mesh on a sphere\n",
    "    # as it is much more efficiant for full resolution\n",
    "    # as well as smoothes nicely the image\n",
    "\n",
    "    # We don't want to work with full res wind so scaling\n",
    "    # the image for about 100m resolution\n",
    "    # Adjust scale to get appropriate value\n",
    "\n",
    "    lts = flipud(ncepGFSmodelWind['lats_wind'])[:, 0]*pi/180\n",
    "    lns = ncepGFSmodelWind['lons_wind'][0, :]*pi/180\n",
    "\n",
    "    lts_2 = lats_2[::scale, ::scale]\n",
    "    lns_2 = lons_2[::scale, ::scale]\n",
    "\n",
    "    ncepGFSmodelWindSwath = {}\n",
    "    ncepGFSmodelWindSwath['wind_speed'] = ncepGFSmodel2swath(\n",
    "        lts, lns, flipud(ncepGFSmodelWind['wind_speed']), lts_2, lns_2\n",
    "    )\n",
    "    ncepGFSmodelWindSwath['wind_dir'] = ncepGFSmodel2swath(\n",
    "        lts, lns, flipud(ncepGFSmodelWind['wind_dir']),   lts_2, lns_2\n",
    "    )\n",
    "    ncepGFSmodelWindSwath['u'] = ncepGFSmodel2swath(\n",
    "        lts, lns, flipud(ncepGFSmodelWind['u']), lts_2, lns_2\n",
    "    )\n",
    "    ncepGFSmodelWindSwath['v'] = ncepGFSmodel2swath(\n",
    "        lts, lns, flipud(ncepGFSmodelWind['v']), lts_2, lns_2\n",
    "    )\n",
    "\n",
    "    pxlResWindSwath = asarray(\n",
    "        distancelib.getPixelResolution(lts_2, lns_2, lns_2.shape, 'km')\n",
    "    )\n",
    "\n",
    "    print \"Interpolated Wind cell resolution, %s km\" % pxlResWindSwath\n",
    "\n",
    "    # calculate bearing from initial lats/lons for further wind calculation\n",
    "    # Taking initial values as bearing is more accurate after\n",
    "    # interpolation than vice versa\n",
    "    bearing = zeros((GEOgrid['lons'].shape[0]-1, GEOgrid['lons'].shape[1]))\n",
    "\n",
    "    for n in range(0, GEOgrid['lons'].shape[1]):\n",
    "        col = ([GEOgrid['lats'][:-1, n], GEOgrid['lons'][:-1, n]],\n",
    "               [GEOgrid['lats'][1:, n], GEOgrid['lons'][1:, n]])\n",
    "        for m in range(0, GEOgrid['lons'].shape[0]-1):\n",
    "            bearing[m][n] = distancelib.bearing(\n",
    "                asarray(col[0])[:, m], asarray(col[1])[:, m]\n",
    "            )\n",
    "\n",
    "    # interpolate to raw_counts.shape\n",
    "    bearing_2 = imresize(bearing, ncepGFSmodelWindSwath['wind_dir'].shape)\n",
    "\n",
    "    # NB! WINDDIR = 0 WHEN WIND BLOWS TOWARDS RADAR!\n",
    "    p = polarization[0]\n",
    "\n",
    "    wind_dir_model_swath_rel = 90 + bearing_2 -\\\n",
    "        ncepGFSmodelWindSwath['wind_dir']\n",
    "\n",
    "    del bearing, bearing_2\n",
    "\n",
    "    if p == 'hh':\n",
    "        PR = PR_Mouche(\n",
    "            incidenceAngle_2[p][::scale, ::scale], wind_dir_model_swath_rel\n",
    "        )\n",
    "        try:\n",
    "            from cmod.cmod_gpu import rcs2windOpenCl\n",
    "            wind_speed_asar = rcs2windOpenCl(\n",
    "                sar=sigma0w[p]*PR, windir=wind_dir_model_swath_rel,\n",
    "                theta=incidenceAngle_2[p][::scale, ::scale]\n",
    "            )\n",
    "        except Exception:\n",
    "            from cmod.cmod_vect import rcs2windPar\n",
    "            wind_speed_asar = rcs2windPar(\n",
    "                sigma0w[p]*PR, cmdv=5, windir=wind_dir_model_swath_rel,\n",
    "                theta=incidenceAngle_2[p][::scale, ::scale], nprocs=numProcs\n",
    "            )\n",
    "    elif p == 'vv':\n",
    "        try:\n",
    "            from cmod.cmod_gpu import rcs2windOpenCl\n",
    "            wind_speed_asar = rcs2windOpenCl(\n",
    "                sar=sigma0w[p], windir=wind_dir_model_swath_rel,\n",
    "                theta=incidenceAngle_2[p][::scale, ::scale]\n",
    "            )\n",
    "        except Exception:\n",
    "            from cmod.cmod_vect import rcs2windPar\n",
    "            wind_speed_asar = rcs2windPar(\n",
    "                sigma0w[p], cmdv=5, windir=wind_dir_model_swath_rel,\n",
    "                theta=incidenceAngle_2[p][::scale, ::scale], nprocs=numProcs\n",
    "            )\n",
    "\n",
    "    del sigma0w, PR\n",
    "    gc.collect()\n",
    "\n",
    "    # Add mask to initial NCEP data\n",
    "    area_def_ncep = pr.geometry.SwathDefinition(\n",
    "        lons=ncepGFSmodelWind['lons_wind'], lats=ncepGFSmodelWind['lats_wind']\n",
    "    )\n",
    "    mask_arr_ncep = pr.kd_tree.resample_nearest(\n",
    "        area_def_4326, mask_arr_4326, area_def_ncep,\n",
    "        radius_of_influence=4*pxlResWind.max(), epsilon=0.5, fill_value=None\n",
    "    )\n",
    "\n",
    "    del area_def_4326, mask_arr_4326, pxlResWind, area_def_ncep\n",
    "\n",
    "    ncepGFSmodelWind['wind_speed'] = ma.masked_where(\n",
    "        mask_arr_ncep, ncepGFSmodelWind['wind_speed']\n",
    "    )\n",
    "\n",
    "    # Add mask to ASAR wind and reprojected NCEP\n",
    "    wind_speed_asar = ma.masked_where(mask_arr_swath, wind_speed_asar)\n",
    "    ncepGFSmodelWindSwath['wind_speed'] = ma.masked_where(\n",
    "        mask_arr_swath, ncepGFSmodelWindSwath['wind_speed']\n",
    "    )\n",
    "\n",
    "    del mask_arr_swath, ncepGFSmodelWind, mask_arr_ncep, ncepGFSmodelWindSwath\n",
    "    gc.collect()\n",
    "\n",
    "    # return_values = ['lats_2', 'lons_2', 'roughnessNrmlzd', 'wind_speed_asar',\n",
    "                     # 'pxlResSARm', 'polarization', 'swath_def']\n",
    "\n",
    "    return_values = {}\n",
    "    return_values['lats'] = lats_2\n",
    "    return_values['lons'] = lons_2\n",
    "    return_values['roughnessNrmlzd'] = roughnessNrmlzd\n",
    "    return_values['wind_speed_asar'] = wind_speed_asar\n",
    "    return_values['pxlResSARm'] = pxlResSARm\n",
    "    return_values['polarization'] = polarization\n",
    "    return_values['swath_def'] = swath_def\n",
    "    return return_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start granule:  S1A_IW_GRDH_1SDV_20150603T154002_20150603T154027_006211_0081A9_5F10.zip\n"
     ]
    }
   ],
   "source": [
    "inpath = '/media/SOLabNFS2/tmp/different_SAR/sentinel-1/Ania_Ladoga_29_May_2015/'\n",
    "fileNameList = ['S1A_IW_GRDH_1SDV_20150603T154002_20150603T154027_006211_0081A9_5F10.zip',\n",
    "                'S1A_IW_GRDH_1SDV_20150529T041657_20150529T041722_006131_007F51_F751.zip',\n",
    "                'S1A_EW_GRDM_1SDH_20150517T153117_20150517T153221_005963_007AED_56B0.zip']\n",
    "\n",
    "fn = fileNameList[0]\n",
    "\n",
    "prog = re.compile(r'(\\d{8})')\n",
    "file_date = prog.findall(fn)[0]\n",
    "\n",
    "year = file_date[:4]\n",
    "month = file_date[4:6]\n",
    "day = file_date[6:]\n",
    "# day = '04'\n",
    "\n",
    "print 'Start granule: ', fn\n",
    "\n",
    "return_values = processingS1(inpath, fn)\n",
    "\n",
    "print 'preprocessing done'\n",
    "# for key in return_values:\n",
    "#     locals()[key] = return_values[key]\n",
    "\n",
    "lats = return_values['lats']\n",
    "lons = return_values['lons']\n",
    "roughnessNrmlzd = return_values['roughnessNrmlzd']\n",
    "wind_speed_asar = return_values['wind_speed_asar']\n",
    "pxlResSARm = return_values['pxlResSARm']\n",
    "polarization = return_values['polarization']\n",
    "swath_def = return_values['swath_def']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import math\n",
    "from netCDF4 import Dataset as ncDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def array_size_normalize(input_array):\n",
    "    avail_resolution_list = [int(256*math.pow(2, i)) for i in range(15)]\n",
    "    # print avail_resolution_list\n",
    "    shape = input_array.shape\n",
    "    # print 'shape: ', shape\n",
    "    current_pixels = max(shape)\n",
    "    # print 'current pixels: ', current_pixels\n",
    "    necessary_pixels = min(filter(lambda x: current_pixels < x,\n",
    "                                  avail_resolution_list))\n",
    "    # print 'necessary_pixels: ', necessary_pixels\n",
    "\n",
    "    source_array = input_array[:]\n",
    "\n",
    "    # src =\n",
    "    #\n",
    "    # xxx\n",
    "    # xxx\n",
    "    #\n",
    "    # top_array =\n",
    "    #\n",
    "    # xxx\n",
    "    # xxx\n",
    "    #\n",
    "    # res =\n",
    "    #\n",
    "    # xxx\n",
    "    # xxx\n",
    "    # xxx\n",
    "    # xxx\n",
    "    #\n",
    "    # right_array =\n",
    "    #\n",
    "    # x\n",
    "    # x\n",
    "    # x\n",
    "    # x\n",
    "    #\n",
    "    # res 4x4 =\n",
    "    #\n",
    "    # xxxx\n",
    "    # xxxx\n",
    "    # xxxx\n",
    "    # xxxx\n",
    "\n",
    "    top_array = np.ma.masked_all((necessary_pixels-shape[0], shape[1]))\n",
    "\n",
    "    right_array = np.ma.masked_all((necessary_pixels, necessary_pixels-shape[1]))\n",
    "\n",
    "    source_array = ma.concatenate((top_array, source_array), axis=0)\n",
    "    # print source_array.shape\n",
    "    source_array = ma.concatenate((source_array, right_array), axis=1)\n",
    "    # print source_array.shape\n",
    "\n",
    "    del top_array, right_array\n",
    "    return source_array\n",
    "\n",
    "def create_base_tiles(input_array):\n",
    "    number_tiles = input_array.shape[0]/256\n",
    "\n",
    "    lines = []\n",
    "    all_list = []\n",
    "\n",
    "    for i in range(number_tiles):\n",
    "        for j in range(number_tiles):\n",
    "            # print '[%d:%d' % (j*256, (j+1)*256), ',%d:%d]'%(i*256, (i+1)*256)\n",
    "            lines.append(input_array[j*256:(j+1)*256, i*256:(i+1)*256])\n",
    "\n",
    "        all_list.append(lines)\n",
    "        lines = []\n",
    "    return all_list\n",
    "\n",
    "def decrease_zoom(source_array):\n",
    "    rows, cols = source_array.shape\n",
    "    rows_2 = rows/2\n",
    "    cols_2 = cols/2\n",
    "    sh = rows_2, rows//rows_2, cols_2, cols//cols_2\n",
    "    return source_array.reshape(sh).mean(-1).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_tile_to_nc(nc_variable, tiles_array, variable, zoom, _min=0, _max=4):\n",
    "    # print len(tiles_array)\n",
    "    for row_number in range(len(tiles_array)):\n",
    "        tile_row = tiles_array[row_number]\n",
    "        for col_number in range(len(tile_row)):\n",
    "            m = tile_row[col_number]\n",
    "\n",
    "            m = np.where(m <= _min, _min + 0.0001, m)\n",
    "            m = np.where(m >= _max, _max, m)\n",
    "\n",
    "            # 0-254 , 255 for mask\n",
    "            m = (2**8-2)*m/float(_max)\n",
    "\n",
    "            m = np.where(m.mask, (2**8-1), m)\n",
    "            m = np.uint8(m)\n",
    "            # m = np.ma.masked_where(m == 255, m)\n",
    "            nc_variable[variable, zoom, row_number, col_number, :] = m\n",
    "\n",
    "def create_dataset(output_path, max_zoom):\n",
    "    max_x_tiles = 2**max_zoom\n",
    "\n",
    "    dataset = ncDataset(output_path, 'w', format='NETCDF4')\n",
    "    dataset.createDimension('vars', 2)\n",
    "    dataset.createDimension('zoom', max_zoom+1)\n",
    "    dataset.createDimension('x', max_x_tiles)\n",
    "    dataset.createDimension('y', max_x_tiles)\n",
    "    dataset.createDimension('shape0', 256)\n",
    "    dataset.createDimension('shape1', 256)\n",
    "\n",
    "    varVars = dataset.createVariable('variables', 'string', ('vars',), zlib=True, complevel=6)\n",
    "    # u1 = NC_UBYTE 0-255\n",
    "    varData = dataset.createVariable('data', 'u1', ('vars','zoom','x','y','shape0','shape1'),\n",
    "                                     zlib=True, complevel=6)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
