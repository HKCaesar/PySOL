{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from ipywidgets import widgets\n",
    "# [widget for widget in dir(widgets) if widget.endswith('Widget')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import os, sys\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "import re\n",
    "import epr\n",
    "\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "from numpy import linspace, arange, row_stack, delete, round, double, asarray\n",
    "from math import atan\n",
    "\n",
    "from createMapsEtopo1 import findSubsetIndices\n",
    "import pygrib\n",
    "\n",
    "import pyresample as pr\n",
    "from pyproj import Proj\n",
    "import distancelib\n",
    "import gshhs_rasterize\n",
    "\n",
    "from pylab import *\n",
    "\n",
    "import simplekml\n",
    "\n",
    "\n",
    "import ConfigParser\n",
    "import redis\n",
    "\n",
    "# sys.path.append(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath('__file__'))), 'cmod'))\n",
    "# sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath('__file__'))))\n",
    "\n",
    "__author__ = 'Alexander Myasoedov and Denis Spiridonov'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pxlRes = None\n",
    "proj = 'EPSG:3413'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set the number of CPUs\n",
    "# numProcs = cpu_count()-2\n",
    "numProcs = 6\n",
    "resolution = 450\n",
    "\n",
    "# redis_conf = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath('__file__'))), 'redis.conf')\n",
    "redis_conf = os.path.join('/home/mag/Documents/repos/solab/posada/', 'redis.conf')\n",
    "\n",
    "config = ConfigParser.RawConfigParser()\n",
    "config.read(redis_conf)\n",
    "redis_host = config.get('AUTH', 'HOSTNAME')\n",
    "redis_passwd = config.get('AUTH', 'PASSWORD')\n",
    "\n",
    "r = redis.Redis(host=redis_host, password=redis_passwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON parameter definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "asarJSON = {}\n",
    "asarJSON['variables_list'] = ['sigma0', 'wind_speed', 'roughness']\n",
    "asarJSON['min_max_values']  = {'sigma0':     [-35, 5],\n",
    "                               'wind_speed': [0, 35],\n",
    "                               'roughness':  [-1, 1]\n",
    "                            }\n",
    "asarJSON['default_min_max_values']  = {'sigma0':     [-25, -5],\n",
    "                                       'wind_speed': [0, 25],\n",
    "                                       'roughness':  [-.5, .5]\n",
    "                            }\n",
    "asarJSON['is_land_masked']  = {'sigma0':     False,\n",
    "                               'wind_speed': True,\n",
    "                               'roughness':  False\n",
    "                        }\n",
    "asarJSON['polarizations_list'] = ['hh', 'vv', 'hv', 'vh']\n",
    "# 'u1' (NC_UBYTE)  2**8 =0-255\n",
    "# 'u2' (NC_USHORT  2**16=0-65535\n",
    "# 'u4' (NC_UINT)   2**32=0-4294967295\n",
    "# 'u8' (NC_UINT64) 2**64=0-18446744073709551615\n",
    "# if 2\\two data types are specified-we generate nc tyle pyramid and export data at max resolution to nc file\n",
    "asarJSON['nc_data_type'] = ['u1', 'u8']\n",
    "# asarJSON['nc_data_type'] = ['u1']\n",
    "\n",
    "with open('ASAR.json', 'w') as outfile:\n",
    "    json.dump(asarJSON, outfile, indent=4, separators=(',', ': '), sort_keys=True)\n",
    "\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Func Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def windDirection(u, v):\n",
    "    U = u.ravel()\n",
    "    V = v.ravel()\n",
    "    direction = zeros(size(U))\n",
    "    for i in range(0, len(U)):\n",
    "        if U[i] >= 0 and V[i] > 0: direction[i] = ((180 / pi) * atan(abs(U[i] / V[i])) + 180)\n",
    "        if U[i] < 0 and V[i] > 0: direction[i] = (-(180 / pi) * atan(abs(U[i] / V[i])) + 180)\n",
    "        if U[i] >= 0 and V[i] < 0: direction[i] = (-(180 / pi) * atan(abs(U[i] / V[i])) + 360)\n",
    "        if U[i] < 0 and V[i] < 0: direction[i] = ((180 / pi) * atan(abs(U[i] / V[i])))\n",
    "        if V[i] == 0 and U[i] > 0: direction[i] = 270\n",
    "        if V[i] == 0 and U[i] < 0: direction[i] = 90\n",
    "        if V[i] == 0 and U[i] == 0: direction[i] = 0\n",
    "    return reshape(direction, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PR_Mouche(theta, phi):\n",
    "    A_0 = 0.00650704\n",
    "    B_0 = 0.128983\n",
    "    C_0 = 0.992839\n",
    "    A_HALF_PI = 0.00782194\n",
    "    B_HALF_PI = 0.121405\n",
    "    C_HALF_PI = 0.992839\n",
    "    A_PI = 0.00598416\n",
    "    B_PI = 0.140952\n",
    "    C_PI = 0.992885\n",
    "\n",
    "    P_0 = A_0 * exp(B_0 * theta) + C_0\n",
    "    P_HALF_PI = A_HALF_PI * exp(B_HALF_PI * theta) + C_HALF_PI\n",
    "    P_PI = A_PI * exp(B_PI * theta) + C_PI\n",
    "\n",
    "    C0 = (P_0 + P_PI + 2 * P_HALF_PI) / 4\n",
    "    C1 = (P_0 - P_PI) / 2\n",
    "    C2 = (P_0 + P_PI - 2 * P_HALF_PI) / 4\n",
    "\n",
    "    P = C0 + C1 * cos(radians(phi)) + C2 * cos(radians(2 * phi))\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ncepGFSmodel(startTime, lats_2, lons_2):\n",
    "    \"\"\"\n",
    "    NCEP GFS model wind for givven time, lat/lon crop\n",
    "    \"\"\"\n",
    "    ncepGFSmodel = {} # empty dict for ncepGFSmodel\n",
    "\n",
    "#     iPath_wind = '/nfs1/store/model/ncep/gfs/'\n",
    "    iPath_wind = '/media/SOLabNFS2/store/model/ncep/gfs/'\n",
    "\n",
    "    # find the ncep gfs filename to open from ASAR filename\n",
    "    baseHour = floor((startTime.hour+3/2)/6)*6\n",
    "    baseHour = min(18, baseHour)\n",
    "    if startTime.hour-baseHour>1.5:\n",
    "        forecastHour = 3\n",
    "    else:\n",
    "        forecastHour = 0\n",
    "\n",
    "    if startTime <= datetime.datetime(2014, 8, 19):\n",
    "        ncepFileName = 'gfs' + startTime.strftime(\"%Y%m%d\") + '/gfs.t' + '%.2d' %(baseHour) + 'z.master.grbf' + '%.2d' %(forecastHour)\n",
    "\n",
    "        grbs = pygrib.open(iPath_wind + ncepFileName)\n",
    "\n",
    "        u_wind = None\n",
    "        v_wind = None\n",
    "\n",
    "        # wind contains u=u_wind.values[:], Lats=u_wind.latlons()[0], Lons=u_wind.latlons()[1]\n",
    "        for idx, msg_info in enumerate(grbs.select()):\n",
    "            if msg_info['short_name'] == '10u':\n",
    "                u_wind = grbs.message(idx + 1)\n",
    "            elif msg_info['short_name'] == '10v':\n",
    "                v_wind = grbs.message(idx + 1)\n",
    "\n",
    "        u = u_wind.values[:]\n",
    "        v = v_wind.values[:]\n",
    "        lats_wind = u_wind.latlons()[0]\n",
    "        lons_wind = u_wind.latlons()[1]\n",
    "    else:\n",
    "        try:\n",
    "            ncepFileName = 'gfs.' + startTime.strftime(\"%Y%m%d\") + '%.2d' %(baseHour) + '/gfs.t' + '%.2d' %(baseHour) + 'z.master.grbf' + '%.2d' %(forecastHour) + '.10m.uv.grib2'\n",
    "\n",
    "            grbs = pygrib.open(iPath_wind + ncepFileName)\n",
    "\n",
    "            u_wind = grbs.message(1)\n",
    "            v_wind = grbs.message(2)\n",
    "            u = u_wind['values']\n",
    "            v = v_wind['values']\n",
    "            lats_wind = u_wind['latitudes']\n",
    "            lons_wind = u_wind['longitudes']\n",
    "            lons_wind = reshape(lons_wind, (lons_wind.shape[0]/720, 720))\n",
    "            lats_wind = reshape(lats_wind, (lats_wind.shape[0]/720, 720))\n",
    "        except Exception:\n",
    "            ncepFileName = 'gfs.' + startTime.strftime(\"%Y%m%d\") + '%.2d' %(baseHour) + '/gfs.t' + '%.2d' %(baseHour) + 'z.pgrb2.0p25.f' + '%.3d' %(forecastHour)\n",
    "\n",
    "            grbs = pygrib.open(iPath_wind + ncepFileName)\n",
    "\n",
    "            u_wind = grbs.message(1)\n",
    "            v_wind = grbs.message(2)\n",
    "            u = u_wind['values']\n",
    "            v = v_wind['values']\n",
    "            lats_wind = u_wind['latitudes']\n",
    "            lons_wind = u_wind['longitudes']\n",
    "            lons_wind = reshape(lons_wind, (lons_wind.shape[0]/1440, 1440))\n",
    "            lats_wind = reshape(lats_wind, (lats_wind.shape[0]/1440, 1440))\n",
    "\n",
    "    #Make sure the longitude is between -180.00 .. 179.9\n",
    "    lons_wind = map(lambda x : (lons_wind.ravel()[x]+180)-int((lons_wind.ravel()[x]+180)/360)*360-180, range(0,lons_wind.size))\n",
    "    lons_wind = reshape(lons_wind, lats_wind.shape)\n",
    "    # plt.close('all')\n",
    "    # plt.imshow(lons_wind)\n",
    "    # plt.colorbar()\n",
    "\n",
    "#     #Make sure the latitudes is between -90.00 .. 89.9, starting from North - positive\n",
    "#     lats_wind = map(lambda x : (lats_wind.ravel()[x]+90)-int((lats_wind.ravel()[x]+90)/180)*180-90, xrange(0,lats_wind.size))\n",
    "#     lats_wind = reshape(lats_wind, lons_wind.shape)\n",
    "#     if lats_wind[0,0] < lats_wind[-1,-1]:\n",
    "#         lats_wind = flipud(lats_wind)\n",
    "#         u = flipud(u)\n",
    "#         v = flipud(v)\n",
    "#     plt.close('all')\n",
    "#     plt.imshow(lats_wind)\n",
    "#     plt.colorbar()\n",
    "\n",
    "\n",
    "    # find subset\n",
    "    res = findSubsetIndices(lats_2.min(),lats_2.max(),lons_2.min(),lons_2.max(),lats_wind[:,0],lons_wind[0,:])\n",
    "    # expand subset by 1 pixel for better further pyresample\n",
    "    res[0]=res[0]-2\n",
    "    res[1]=res[1]+2\n",
    "    res[2]=res[2]-2\n",
    "    res[3]=res[3]+2\n",
    "\n",
    "    # crop the data\n",
    "    u = u[int(res[2]):int(res[3]),int(res[0]):int(res[1])]\n",
    "    v = v[int(res[2]):int(res[3]),int(res[0]):int(res[1])]\n",
    "    ncepGFSmodel['lats_wind'] = lats_wind[int(res[2]):int(res[3]),int(res[0]):int(res[1])]\n",
    "    ncepGFSmodel['lons_wind'] = lons_wind[int(res[2]):int(res[3]),int(res[0]):int(res[1])]\n",
    "\n",
    "    ncepGFSmodel['wind_dir'] = windDirection(u,v)\n",
    "    ncepGFSmodel['wind_speed'] = sqrt(u**2 + v**2)\n",
    "    ncepGFSmodel['u'] = u\n",
    "    ncepGFSmodel['v'] = v\n",
    "    ncepGFSmodel['baseHour'] = baseHour\n",
    "    ncepGFSmodel['forecastHour'] = forecastHour\n",
    "#     del u_wind, v_wind\n",
    "    return ncepGFSmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_KML(area_extent, savepath):\n",
    "    kml = simplekml.Kml()\n",
    "\n",
    "    pol = kml.newpolygon(name='area_extent', visibility=1)\n",
    "    pol.tessellate = 1\n",
    "\n",
    "    pol.altitudemode = 'clampToGround'\n",
    "    # minx, miny, maxx, maxy\n",
    "    pol.outerboundaryis.coords = [(min(area_extent[0], area_extent[2]),\n",
    "                                   min(area_extent[1], area_extent[3])),\n",
    "                                  (max(area_extent[0], area_extent[2]),\n",
    "                                   max(area_extent[1], area_extent[3]))]\n",
    "    if type(savepath) == list:\n",
    "        for _savepath in savepath:\n",
    "            kml.save(_savepath)\n",
    "    else:\n",
    "        kml.save(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def swath_area_def(name='Temporal SWATH EPSG Projection 4326', proj='eqc', lonlim=(-180,180), latlim=(-90,90),\n",
    "                   ellps=\"WGS84\", res=111.2e3, lat_ts=None, lat_0=None, lon_0=None):\n",
    "    \"\"\"\n",
    "    Convert given swath coordinates to pyresample area definition.\n",
    "    The arguments are standard for Proj:\n",
    "    name\n",
    "    proj\n",
    "    lonlim\n",
    "    latlim\n",
    "    ellipsoid\n",
    "    resolution(meters)\n",
    "    lat_ts (latitude of true scale)\n",
    "    lat_0,lon_0 is central point\n",
    "    EXAMPLE:\n",
    "\n",
    "    epsg3426 is the default one\n",
    "    for epsg3413:\n",
    "    swath_area_def(name='Temporal SWATH EPSG Projection 3413', proj='stere', lonlim=(-180,180), latlim=(30,90), ellps=\"WGS84\", res=111.2e3, lat_ts=70, lat_0=90, lon_0=-45)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    up    = max(latlim)\n",
    "    down  = min(latlim)\n",
    "    left  = min(lonlim)\n",
    "    right = max(lonlim)\n",
    "\n",
    "    print 'up, down, left, right: ', round(up), round(down), round(left), round(right)\n",
    "\n",
    "    area_id = name.replace(\" \", \"_\").lower()\n",
    "    proj_id = area_id\n",
    "\n",
    "    if proj == 'eqc':\n",
    "        p = Proj(proj=proj, llcrnrlat=up, urcrnrlat=down, llcrnrlon=left, urcrnrlon=right, ellps=ellps)\n",
    "        proj4_args = '+proj=' + str(proj) + ' ' + \\\n",
    "             '+llcrnrlat=' + str(up) + ' ' + \\\n",
    "             '+urcrnrlat=' + str(down) + ' ' + \\\n",
    "             '+llcrnrlon=' + str(left) + ' ' + \\\n",
    "             '+urcrnrlon=' + str(right) + ' ' + \\\n",
    "             '+ellps=' + str(ellps)\n",
    "    elif lat_ts!=None and lat_0!=None:\n",
    "        # lat_ts is latitude of true scale.\n",
    "        # lon_0,lat_0 is central point.\n",
    "        p = Proj(proj=proj, lat_0=lat_0, lon_0=lon_0, lat_ts=lat_ts, ellps=ellps)\n",
    "        proj4_args = '+proj=' + str(proj) + ' ' + \\\n",
    "             '+lat_0=' + str(lat_0) + ' ' + \\\n",
    "             '+lon_0=' + str(lon_0) + ' ' + \\\n",
    "             '+lat_ts=' + str(lat_ts) + ' ' + \\\n",
    "             '+ellps=' + str(ellps)\n",
    "    elif lon_0!=None and lat_0!=None and lat_ts==None:\n",
    "        # lon_0,lat_0 is central point.\n",
    "        p = Proj(proj=proj, lat_0=lat_0, lon_0=lon_0, ellps=ellps)\n",
    "        proj4_args = '+proj=' + str(proj) + ' ' + \\\n",
    "             '+lat_0=' + str(lat_0) + ' ' + \\\n",
    "             '+lon_0=' + str(lon_0) + ' ' + \\\n",
    "             '+ellps=' + str(ellps)\n",
    "    elif lon_0==None and lat_0==None and lat_ts==None:\n",
    "        # lon_0,lat_0 is central point.\n",
    "        lat_0 = (up + down) / 2\n",
    "        lon_0 = (right + left) / 2\n",
    "        p = Proj(proj=proj, lat_0=lat_0, lon_0=lon_0, ellps=ellps)\n",
    "        proj4_args = '+proj=' + str(proj) + ' ' + \\\n",
    "             '+lat_0=' + str(lat_0) + ' ' + \\\n",
    "             '+lon_0=' + str(lon_0) + ' ' + \\\n",
    "             '+ellps=' + str(ellps)\n",
    "\n",
    "    left_ex1, up_ex1 = p(left, up)\n",
    "    right_ex1, up_ex2 = p(right, up)\n",
    "    left_ex2, down_ex1 = p(left, down)\n",
    "    right_ex2, down_ex2 = p(right, down)\n",
    "\n",
    "    if proj == 'stere':\n",
    "        lon = (left+right)/2.0\n",
    "        if (lon >=0 and lon <90) or (lon >=-360 and lon < -270):\n",
    "            print 11111111111\n",
    "            area_extent = array((\n",
    "                           min(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                           min(down_ex1, down_ex2, up_ex1, up_ex2),\n",
    "                           max(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                           max(down_ex1, down_ex2, up_ex1, up_ex2)\n",
    "                        ))\n",
    "        elif (lon >=90 and lon <180) or (lon >=-270 and lon < -180):\n",
    "            print 2222222222222\n",
    "            area_extent = array((\n",
    "                           max(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                           max(down_ex1, down_ex2, up_ex1, up_ex2),\n",
    "                           min(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                           min(down_ex1, down_ex2, up_ex1, up_ex2)\n",
    "                        ))\n",
    "        elif (lon >= 180 and lon < 270) or (lon >= -180 and lon < -90):\n",
    "            print 333333333333\n",
    "            area_extent = array((\n",
    "                           min(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                           min(down_ex1, down_ex2, up_ex1, up_ex2),\n",
    "                           max(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                           max(down_ex1, down_ex2, up_ex1, up_ex2)\n",
    "                        ))\n",
    "        else:\n",
    "            print 44444444444444444\n",
    "            area_extent = array((\n",
    "                           min(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                           min(down_ex1, down_ex2, up_ex1, up_ex2),\n",
    "                           max(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                           max(down_ex1, down_ex2, up_ex1, up_ex2)\n",
    "                        ))\n",
    "    else:\n",
    "        # минимум из всех координат X, Y, максимум из всех координат X, Y\n",
    "        # Такой результат даёт правильный area_extent для 3413\n",
    "        # При этом для 4326 area_extent остаётся неизменным\n",
    "        # area_def_3413 = swath_area_def(name='Temporal SWATH EPSG Projection 3413', proj='stere', \\\n",
    "        #                                lonlim=(-180,180), latlim=(30,90), ellps=\"WGS84\", res=1500, \\\n",
    "        #                                lat_ts=70, lat_0=90, lon_0=-45)\n",
    "        # Area extent: (-5050747.263141337, 0.0, 0.0, 5050747.263141336)\n",
    "        area_extent = array((\n",
    "                        min(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                        min(up_ex1, up_ex2, down_ex1, down_ex2),\n",
    "                        max(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                        max(up_ex1, up_ex2, down_ex1, down_ex2)\n",
    "                    ))\n",
    "\n",
    "#     area_extent[0] = area_extent[0] + res[0]/2\n",
    "#     area_extent[1] = area_extent[1] - res[1]/2\n",
    "#     area_extent[2] = area_extent[2] + res[0]/2\n",
    "#     area_extent[3] = area_extent[3] - res[1]/2\n",
    "    modulox = (area_extent[2] - area_extent[0]) % res[0]\n",
    "    moduloy = (area_extent[3] - area_extent[1]) % res[1]\n",
    "    area_extent[0] = area_extent[0] + modulox\n",
    "    area_extent[1] = area_extent[1] + moduloy\n",
    "    area_extent[2] = area_extent[2]\n",
    "    area_extent[3] = area_extent[3]\n",
    "    #~ print 'left: ', left_ex1, left_ex2\n",
    "    #~ print 'right: ', right_ex1, right_ex2\n",
    "    #~ print 'up: ', up_ex1, up_ex2\n",
    "    #~ print 'down: ', down_ex1, down_ex2\n",
    "\n",
    "#     import ipdb\n",
    "#     ipdb.set_trace()\n",
    "#     Using abs() to avoid negative numbers of coloumns/rows as for epsg3413 for example\n",
    "    xsize = abs(int(round((area_extent[2] - area_extent[0]) / res[0])))\n",
    "    ysize = abs(int(round((area_extent[3] - area_extent[1]) / res[1])))\n",
    "    \n",
    "    swath_area_def = pr.utils.get_area_def(area_id, name, proj_id, proj4_args, xsize, ysize, area_extent)\n",
    "\n",
    "#     print swath_area_def\n",
    "\n",
    "    return swath_area_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def imresize(image, size):\n",
    "    \"\"\"\n",
    "    Resizes coefficient arrays using bivariate spline approximation.\n",
    "    \"\"\"\n",
    "    m, n = image.shape\n",
    "    X = linspace(0, m - 1, size[0])\n",
    "    Y = linspace(0, n - 1, size[1])\n",
    "    kx, ky = min([m - 1, 3]), min([n - 1, 3])\n",
    "    interp = RectBivariateSpline(\n",
    "        arange(m), arange(n), image, kx=kx, ky=ky)\n",
    "    resized = interp(X, Y)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _format_extent_spacing(extent, spacing, extmax, midazimuth=False,\n",
    "                           midrange=False):\n",
    "    \"\"\"Format (and check) extent and spacing.\"\"\"\n",
    "    # Check extent\n",
    "    ext = round(extent).flatten()\n",
    "    if ext.size != 4:\n",
    "        raise Exception('extent must contain 4 elements')\n",
    "    if (ext[0:2] < extmax[0:2]).any() or (ext[2:4] > extmax[2:4]).any():\n",
    "        exttmp = array(ext)\n",
    "        ext[0:2] = maximum(ext[0:2], extmax[0:2])\n",
    "        ext[2:4] = minimum(ext[2:4], extmax[2:4])\n",
    "        print 'Warning : extent is outside SAR image, '+str(exttmp)+\\\n",
    "            ' becomes '+str(ext)\n",
    "    if (ext[0:2] > ext[2:4]).any():\n",
    "        raise Exception('extent[0:2] must be less or equal than '+\\\n",
    "                        'extent[2:4]')\n",
    "    # Check spacing\n",
    "    spa = round(spacing).flatten()\n",
    "    if spa.size == 1:\n",
    "        spa = repeat(spa[0], 2)\n",
    "    elif spa.size == 2:\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception('spacing must contain 1 or 2 elements')\n",
    "    if (spa < [1, 1]).any():\n",
    "        spatmp = array(spa)\n",
    "        spa = maximum(spa, [1, 1])\n",
    "        print 'Warning : spacing too small, '+str(spatmp)+' becomes '+\\\n",
    "            str(spa)\n",
    "    if (spa > ext[2:4]-ext[0:2]).any():\n",
    "        spatmp = array(spa)\n",
    "        spa = minimum(spa, ext[2:4]-ext[0:2])\n",
    "        print 'Warning : spacing too large, '+str(spatmp)+' becomes '+\\\n",
    "            str(spa)\n",
    "    # Make extent to be spacing modulo\n",
    "    ext[2:4] -= (ext[2:4]-ext[0:2]) % spa\n",
    "#     # 1D extent\n",
    "#     if midazimuth == True:\n",
    "#         dim = (ext[2]-ext[0]+1)/spa[0]\n",
    "#         ext[0:3:2] = ext[0] + (dim-1)//2*spa[0] + [0, spa[0]-1]\n",
    "#     if midrange == True:\n",
    "#         dim = (ext[3]-ext[1]+1)/spa[1]\n",
    "#         ext[1:4:2] = ext[1] + (dim-1)//2*spa[1] + [0, spa[1]-1]\n",
    "    return (ext, spa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_sigma0(iPath, fileName, pxlRes=800.0):\n",
    "\n",
    "    print os.path.join(iPath, fileName)\n",
    "    try:\n",
    "        product = epr.Product(os.path.join(iPath, fileName))\n",
    "    except:\n",
    "        print 'unable to read file'\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        band = product.get_band('proc_data')\n",
    "    except epr.EPRValueError:\n",
    "        print 'unable to get band \"proc_data\": epr_get_band_id: band not found'\n",
    "        return False\n",
    "\n",
    "    sc_w = double(product.get_scene_width())\n",
    "    sc_h = double(product.get_scene_height())\n",
    "    \n",
    "\n",
    "    print 'sc_w*sc_h = %s MPs' % str(round(sc_w * sc_h / 1e6))\n",
    "#     logger.debug('sc_w*sc_h = %s MPs', str(round(sc_w * sc_h / 1e6)))\n",
    "    if sc_w*sc_h > 60*1e6:\n",
    "        logger.debug(\"ASAR Image too large, skipping...\")\n",
    "        return False\n",
    "\n",
    "\n",
    "    # Get lat/lon from geolocation grid\n",
    "    dataset = product.get_dataset('GEOLOCATION_GRID_ADS')\n",
    "    fltp_lats = map(\n",
    "        lambda x:\n",
    "        dataset.read_record(x).get_field('first_line_tie_points.lats').get_elems(),\n",
    "        range(dataset.get_num_records())\n",
    "    )\n",
    "    lltp_lats = map(\n",
    "        lambda x:\n",
    "        dataset.read_record(x).get_field('last_line_tie_points.lats').get_elems(),\n",
    "        range(dataset.get_num_records())\n",
    "    )\n",
    "    fltp_lons = map(\n",
    "        lambda x:\n",
    "        dataset.read_record(x).get_field('first_line_tie_points.longs').get_elems(),\n",
    "        range(dataset.get_num_records())\n",
    "    )\n",
    "    lltp_lons = map(\n",
    "        lambda x:\n",
    "        dataset.read_record(x).get_field('last_line_tie_points.longs').get_elems(),\n",
    "        range(dataset.get_num_records())\n",
    "    )\n",
    "\n",
    "    fltp_lats = asarray(double(fltp_lats))/1e6\n",
    "    lltp_lats = asarray(double(lltp_lats))/1e6\n",
    "    fltp_lons = asarray(double(fltp_lons))/1e6\n",
    "    lltp_lons = asarray(double(lltp_lons))/1e6\n",
    "\n",
    "    lats = row_stack((fltp_lats, lltp_lats[-1, :]))\n",
    "    lons = row_stack((fltp_lons, lltp_lons[-1, :]))\n",
    "\n",
    "    lats = fliplr(lats)\n",
    "    lons = fliplr(lons)\n",
    "\n",
    "    # Find scale to reduce image to the specified resolution\n",
    "    arrShape =  asarray([sc_w, sc_h])\n",
    "    _lats = asarray([lats[0,0], lats[-1,-1], lats[0,-1], lats[-1,0]])\n",
    "    _lons = asarray([lons[0,0], lons[-1,-1], lons[0,-1], lons[-1,0]])\n",
    "    imageRes = round(mean(asarray(distancelib.getPixelResolution(_lats, \\\n",
    "                                                                 _lons, \\\n",
    "                                                                 arrShape, 'km'))*1e3))\n",
    "    scale = pxlRes/imageRes\n",
    "\n",
    "    extMax = (0.,0.,arrShape[0]-1,arrShape[1]-1)\n",
    "    ext    = (0.,0.,arrShape[0]-1,arrShape[1]-1)\n",
    "\n",
    "    # Format extent/spacing\n",
    "    ext, spa = _format_extent_spacing(extent=ext, spacing = scale, extmax=extMax)\n",
    "    \n",
    "    # Read data with stepping=spacing\n",
    "    try:\n",
    "        raw_counts = band.read_as_array(sc_w, sc_h, xstep=spa[0], ystep=spa[1])\n",
    "        incident_angle = product.get_band('incident_angle').read_as_array(sc_w, sc_h, xstep=spa[0], ystep=spa[1])\n",
    "    except epr.EPRValueError:\n",
    "        print \"EPRValueError\"\n",
    "        return False\n",
    "\n",
    "    \n",
    "    lats_2 = imresize(lats, raw_counts.shape)\n",
    "    lons_2 = imresize(lons, raw_counts.shape)\n",
    "\n",
    "#     if lats.max() <= 35:\n",
    "#         print \"skipping no area overlap\"\n",
    "#         return False\n",
    "\n",
    "    # Trimming the array by removing zero values from rows and cols\n",
    "    msk = []\n",
    "    for m in range(raw_counts.shape[0]):\n",
    "        if raw_counts[m, :].sum() == 0:\n",
    "            msk.append(m)\n",
    "    raw_counts = delete(raw_counts, msk, axis=0)\n",
    "    lats_2 = delete(lats_2, msk, axis=0)\n",
    "    lons_2 = delete(lons_2, msk, axis=0)\n",
    "    incident_angle = delete(incident_angle, msk, axis=0)\n",
    "    polarization = product.get_sph().get_field('MDS1_TX_RX_POLAR').get_elem()\n",
    "\n",
    "    msk = []\n",
    "    for n in range(raw_counts.shape[1]):\n",
    "        if raw_counts[:, n].sum() == 0:\n",
    "            msk.append(n)\n",
    "    raw_counts = delete(raw_counts, msk, axis=1)\n",
    "    lats_2 = delete(lats_2, msk, axis=1)\n",
    "    lons_2 = delete(lons_2, msk, axis=1)\n",
    "    incident_angle = delete(incident_angle, msk, axis=1)\n",
    "\n",
    "    # Adding Sigma_0\n",
    "    calibration_constant = \\\n",
    "    product.get_dataset('MAIN_PROCESSING_PARAMS_ADS').read_record(0).get_field('calibration_factors.1.ext_cal_fact').get_elems()\n",
    "    # sigma0 = 10*log10( raw_counts**2*sin(incident_angle*pi/180)/calibration_constant )\n",
    "    sigma0 = raw_counts**2*sin(incident_angle*pi/180)/calibration_constant\n",
    "    \n",
    "    return sigma0, lats_2, lons_2, incident_angle, polarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_roughness(sigma0, incident_angle, polarisation):\n",
    "    \"\"\"Compute sea surface roughness.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma0 : ndarray\n",
    "        NRCS backscatter.\n",
    "    incident_angle : ndarray\n",
    "        Incidence angle in degrees.\n",
    "    polarisation : str\n",
    "        'VV' or 'HH' or 'VH' or 'HV'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    roughness: ndarray\n",
    "    \"\"\"\n",
    "    \n",
    "    # Lee-Wiener filtering blures to much the ASAR scenes, so we use it only for wind field\n",
    "    # from scipy.signal import wiener\n",
    "    # sigma0w = wiener(sigma0, mysize=(3,3), noise=None)\n",
    "    # sigma0w = sigma0\n",
    "\n",
    "    # # Earlier form Fabrice - simplyfied\n",
    "    # polarization = product.get_sph().get_field('MDS1_TX_RX_POLAR').get_elem()\n",
    "    # if polarization == 'H/H':\n",
    "    #     ph = (2.20495, -14.3561e-2, 11.28e-4)\n",
    "    #     sigma0_hh_ref = exp( ( ph[0]+incident_angle*ph[1]+incident_angle**2*ph[2])*log(10) )\n",
    "    #     roughness = sigma0w/sigma0_hh_ref\n",
    "    # elif polarization == 'V/V':\n",
    "    #     pv = (2.29373, -15.393e-2, 15.1762e-4)\n",
    "    #     sigma0_vv_ref = exp( ( pv[0]+incident_angle*pv[1]+incident_angle**2*pv[2])*log(10) )\n",
    "    #     roughness = sigma0w/sigma0_vv_ref\n",
    "\n",
    "    # From sar/cerbere\n",
    "    from cmod_vect import cmod5n_forward as cmod5\n",
    "    if polarisation == 'VV' or polarisation == 'V/V': # Use cmod5\n",
    "        sigma0_vv = cmod5(10, 45, incident_angle)\n",
    "        return sigma0/sigma0_vv\n",
    "    elif polarisation == 'HH' or polarisation == 'H/H': # Use cmod5 and Thompson polarisation ratio\n",
    "        sigma0_vv = cmod5(10, 45, incident_angle)\n",
    "        alpha = 0.7\n",
    "        polrat = (1 + 2*tan(incident_angle*pi/180)**2)**2 / \\\n",
    "                 (1 + alpha*tan(incident_angle*pi/180)**2)**2\n",
    "        return sigma0/sigma0_vv*polrat\n",
    "    elif polarisation == 'VH' or polarisation == 'HV' \\\n",
    "      or polarisation == 'V/H' or polarisation == 'H/V': # Use simple model\n",
    "        # nrcs_vh_db = 0.580*wsp - 35.652\n",
    "        # nrcs_vh_lin = 10^(nrcs_vh_db/10.)\n",
    "        sigma0_cross = 10**((0.58*10-35.652)/10)\n",
    "        return sigma0/sigma0_cross\n",
    "    else:\n",
    "        raise Exception('Unknown polarisation : '+polarisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_wind(fileName, sigma0w, lats_2, lons_2, incident_angle, polarization):\n",
    "    # Adding Model wind\n",
    "    startTime = datetime.datetime.strptime(fileName[14:29], \"%Y%m%d_%H%M%S\")\n",
    "    ncepGFSmodelWind = ncepGFSmodel(startTime, lats_2, lons_2)\n",
    "    if not ncepGFSmodelWind:\n",
    "        return False\n",
    "\n",
    "    # Reprojecting data\n",
    "\n",
    "    # Pixel resolution\n",
    "    # we use pxlResWind/pxlResSAR for further pyresample radius_of_influence and sigmas\n",
    "    try:\n",
    "        pxlResWind = asarray(\n",
    "            distancelib.getPixelResolution(ncepGFSmodelWind['lats_wind'],\n",
    "                                           ncepGFSmodelWind['lons_wind'],\n",
    "                                           ncepGFSmodelWind['lats_wind'].shape,\n",
    "                                           'km')\n",
    "        )\n",
    "    except IndexError:\n",
    "        return False\n",
    "    pxlResSAR = asarray(\n",
    "        distancelib.getPixelResolution(lats_2, lons_2, lons_2.shape, 'km')\n",
    "    )*1e3\n",
    "    # Note pxlResWind is in KM, multiply by 1e3 for meters\n",
    "#    print \"ASAR cell resolution, %s m\"  % pxlResSAR\n",
    "#    print \"Wind cell resolution, %s km\" % pxlResWind\n",
    "\n",
    "    # reproject NCEP onto ASAR grid before calculations\n",
    "    # Try both BivariateSpline, griddata and pyresample\n",
    "\n",
    "    ncep_def = pr.geometry.GridDefinition(lons=ncepGFSmodelWind['lons_wind'],\n",
    "                                          lats=ncepGFSmodelWind['lats_wind'])\n",
    "    swath_def = pr.geometry.SwathDefinition(lons=lons_2, lats=lats_2)\n",
    "\n",
    "    # wind_speed_model_swath = pr.kd_tree.resample_gauss(\n",
    "    #     ncep_def, ncepGFSmodelWind['wind_speed'].ravel(), swath_def,\n",
    "    #     radius_of_influence=2*pxlResWind.max()*1e3, neighbours=12,\n",
    "    #     sigmas=pxlResWind.max()*1e3, fill_value=None, nprocs=numProcs\n",
    "    # )\n",
    "    wind_dir_model_swath = pr.kd_tree.resample_gauss(\n",
    "        ncep_def, ncepGFSmodelWind['wind_dir'].ravel(), swath_def,\n",
    "        radius_of_influence=2*pxlResWind.max()*1e3, neighbours=12,\n",
    "        sigmas=pxlResWind.max()*1e3, fill_value=None, nprocs=numProcs\n",
    "    )\n",
    "\n",
    "    # calculate bearing from initial lats/lons for further wind calculation\n",
    "    bearing = zeros((lons.shape[0]-1, lons.shape[1]))\n",
    "\n",
    "    for n in range(0, lons.shape[1]):\n",
    "        col = ([lats[:-1, n], lons[:-1, n]], [lats[1:, n], lons[1:, n]])\n",
    "        for m in range(0, lons.shape[0]-1):\n",
    "            bearing[m][n] = distancelib.bearing(asarray(col[0])[:, m],\n",
    "                                                asarray(col[1])[:, m])\n",
    "\n",
    "    # interpolate to raw_counts.shape\n",
    "    bearing_2 = imresize(bearing, raw_counts.shape)\n",
    "\n",
    "    # NB! WINDDIR = 0 WHEN WIND BLOWS TOWARDS RADAR!\n",
    "    wind_dir_model_swath_rel = 90 + bearing_2 - wind_dir_model_swath\n",
    "\n",
    "    if polarization == 'H/H':\n",
    "        PR = PR_Mouche(incident_angle, wind_dir_model_swath_rel)\n",
    "        try:\n",
    "            from cmod_gpu import rcs2windOpenCl\n",
    "            wind_speed_asar = rcs2windOpenCl(sar=sigma0w*PR,\n",
    "                                             windir=wind_dir_model_swath_rel,\n",
    "                                             theta=incident_angle)\n",
    "        except Exception:\n",
    "            from cmod_vect import rcs2windPar\n",
    "            wind_speed_asar = rcs2windPar(sigma0w*PR, cmdv=5,\n",
    "                                          windir=wind_dir_model_swath_rel,\n",
    "                                          theta=incident_angle,\n",
    "                                          nprocs=numProcs)\n",
    "    elif polarization == 'V/V':\n",
    "        try:\n",
    "            from cmod_gpu import rcs2windOpenCl\n",
    "            wind_speed_asar = rcs2windOpenCl(sar=sigma0w,\n",
    "                                             windir=wind_dir_model_swath_rel,\n",
    "                                             theta=incident_angle)\n",
    "        except Exception:\n",
    "            from cmod_vect import rcs2windPar\n",
    "            wind_speed_asar = rcs2windPar(sigma0w, cmdv=5,\n",
    "                                          windir=wind_dir_model_swath_rel,\n",
    "                                          theta=incident_angle,\n",
    "                                          nprocs=numProcs)\n",
    "    \n",
    "    return wind_speed_asar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year: 2012 / Day: 040\n"
     ]
    }
   ],
   "source": [
    "asar_path = '/nfs1/store/satellite/asar/'\n",
    "# _dir = '/nfs1/store/satellite/asar/2010/270'\n",
    "# fileName = 'ASA_WSM_1PNPDK20100927_195408_000000862093_00200_44843_3688.N1'\n",
    "\n",
    "# _dir = '/nfs1/store/satellite/asar/2012/078'\n",
    "# fileName = 'ASA_WSM_1PNPDE20120318_034254_000001043112_00392_52561_3510.N1'\n",
    "\n",
    "# _dir = '/nfs1/store/satellite/asar/2012/061/'\n",
    "# fileName = 'ASA_WSM_1PNPDE20120301_091843_000001163112_00151_52320_7147.N1'\n",
    "\n",
    "# _dir = '/nfs1/store/satellite/asar/2012/078'\n",
    "# fileName = 'ASA_WSM_1PNPDE20120318_034254_000001043112_00392_52561_3510.N1'\n",
    "\n",
    "# Testing epsg3413 fliplr flipud\n",
    "# _dir = '/nfs1/store/satellite/asar/2012/040'\n",
    "# fileName = 'ASA_WSM_1PNPDE20120209_114916_000000923111_00282_52020_9173.N1'\n",
    "\n",
    "# _dir = '/nfs1/store/satellite/asar/2012/036'\n",
    "# fileName = 'ASA_WSM_1PNPDK20120205_093002_000000923111_00223_51961_2779.N1'\n",
    "\n",
    "_dir = '/nfs1/store/satellite/asar/2012/040'\n",
    "fileName = 'ASA_WSM_1PNPDE20120209_070543_000000923111_00279_52017_9057.N1'\n",
    "\n",
    "\n",
    "input_filename = os.path.join(_dir, fileName)\n",
    "dt = datetime.datetime.strptime(\n",
    "    fileName[14:22], '%Y%m%d'\n",
    ").timetuple()\n",
    "year = str(dt.tm_year)\n",
    "day = str(dt.tm_yday)\n",
    "\n",
    "if len(day) == 1:\n",
    "    day = '00' + day\n",
    "elif len(day) == 2:\n",
    "    day = '0' + day\n",
    "print \"Year: %s / Day: %s\"  % (year, day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigma0 calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating sigma0.......\n",
      "/nfs1/store/satellite/asar/2012/040/ASA_WSM_1PNPDE20120209_070543_000000923111_00279_52017_9057.N1\n",
      "sc_w*sc_h = 45.0 MPs\n"
     ]
    }
   ],
   "source": [
    "print \"Calculating sigma0.......\"\n",
    "\n",
    "sigma0, lats_2, lons_2, incident_angle, polarization = compute_sigma0(_dir, fileName, pxlRes=resolution)\n",
    "# roughness = compute_roughness(sigma0, incident_angle, polarization)\n",
    "# wind_speed_asar = compute_wind(fileName, sigma0, lats_2, lons_2, incident_angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Reprojecting and Masking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pxlRes = array((resolution, resolution))\n",
    "lonlim = (lons_2.min(), lons_2.max())\n",
    "latlim = (lats_2.min(), lats_2.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining areas.......\n",
      "    reprojecting to EPSG:3413\n",
      "up, down, left, right:  48.0 43.0 45.0 52.0\n",
      "11111111111\n"
     ]
    }
   ],
   "source": [
    "print \"Defining areas.......\"\n",
    "\n",
    "# Define areas with pyresample\n",
    "swath_def = pr.geometry.SwathDefinition(\n",
    "    lons=lons_2, lats=lats_2\n",
    ")\n",
    "\n",
    "# for proj in ['EPSG:4326', 'EPSG:3413']:\n",
    "# for proj in ['EPSG:4326']:\n",
    "print \"    reprojecting to %s\" % proj\n",
    "if proj == 'EPSG:4326':\n",
    "    area_def = swath_area_def(name='Temporal SWATH EPSG Projection 4326',\n",
    "                              proj='eqc',\n",
    "                              lonlim=lonlim,\n",
    "                              latlim=latlim, ellps=\"WGS84\",\n",
    "                              res=pxlRes)\n",
    "    # Set the parameters for GSHHS masking\n",
    "    area_def.proj_ = '4326'\n",
    "    area_def.proj_name = None\n",
    "    area_def.units = 'deg'\n",
    "elif proj == 'EPSG:3413':\n",
    "    area_def = swath_area_def(name='Temporal SWATH EPSG Projection 3413',\n",
    "                              proj='stere',\n",
    "                              lonlim=lonlim,\n",
    "                              latlim=latlim, ellps=\"WGS84\",\n",
    "                              res=pxlRes,\n",
    "                              lat_ts=70, lat_0=90, lon_0=-45)\n",
    "    # Set the parameters for GSHHS masking\n",
    "    area_def.proj_ = '+units=m +ellps=WGS84 +lon_0=-45 +proj=stere +lat_ts=70 +lat_0=90'\n",
    "    area_def.proj_name = '3413'\n",
    "    area_def.units = 'm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reprojecting non masked arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reprojecting data to new projection(s).......\n"
     ]
    }
   ],
   "source": [
    "print \"Reprojecting data to new projection(s).......\"\n",
    "\n",
    "sigma0_res = pr.kd_tree.resample_nearest(\n",
    "    swath_def, sigma0.ravel(), area_def,\n",
    "    radius_of_influence=4*pxlRes.max(),\n",
    "    epsilon=0.5, fill_value=None, nprocs=numProcs\n",
    ")\n",
    "# incident_angle_res = pr.kd_tree.resample_nearest(\n",
    "#     swath_def, incident_angle.ravel(), area_def,\n",
    "#     radius_of_influence=4*pxlRes.max(),\n",
    "#     epsilon=0.5, fill_value=None, nprocs=numProcs\n",
    "# )\n",
    "# lats_2_res = pr.kd_tree.resample_nearest(\n",
    "#     swath_def, lats_2.ravel(), area_def,\n",
    "#     radius_of_influence=4*pxlRes.max(),\n",
    "#     epsilon=0.5, fill_value=None, nprocs=numProcs\n",
    "# )\n",
    "# lons_2_res = pr.kd_tree.resample_nearest(\n",
    "#     swath_def, lons_2.ravel(), area_def,\n",
    "#     radius_of_influence=4*pxlRes.max(),\n",
    "#     epsilon=0.5, fill_value=None, nprocs=numProcs\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lon = mean(lonlim)\n",
    "if (lon >=90 and lon <180) or (lon >=-270 and lon < -180):\n",
    "    sigma0_res = fliplr(flipud(sigma0_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize array size to be a multyply of the tile size before timming the area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/mag/Documents/repos/solab/posada/handlers/')\n",
    "\n",
    "import Tiles.nctiles\n",
    "reload(Tiles.nctiles)\n",
    "from Tiles.nctiles import array_size_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "old_shape = sigma0_res.shape\n",
    "sigma0_res = array_size_normalize(sigma0_res, False)\n",
    "new_shape = sigma0_res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trimming the area_def correspondingly to the normalized array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def area_def_crop(area_def, new_shape, area_extent=None):\n",
    "    \"\"\"\n",
    "    (x_ll, y_ll, x_ur, y_ur)\n",
    "    \"\"\"\n",
    "    area_id = area_def.area_id\n",
    "    name = area_def.name\n",
    "    proj_id = area_def.proj_id\n",
    "    proj4_args = area_def.proj_dict\n",
    "    xsize = new_shape[1]\n",
    "    ysize = new_shape[0]\n",
    "\n",
    "    area_def_crop = pr.utils.get_area_def(area_id, name, proj_id, proj4_args, xsize, ysize, area_extent)\n",
    "\n",
    "    return area_def_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lon = mean(lonlim)\n",
    "if (lon >=90 and lon <180) or (lon >=-270 and lon < -180):\n",
    "    area_extent_ = (\n",
    "        abs((new_shape[1])*area_def.pixel_size_y) + area_def.area_extent[2],\n",
    "        abs((new_shape[0])*area_def.pixel_size_x) + area_def.area_extent[3],\n",
    "        area_def.area_extent[2],\n",
    "        area_def.area_extent[3]\n",
    "        )\n",
    "else:\n",
    "    area_extent_ = (\n",
    "        abs((new_shape[1])*area_def.pixel_size_y) + area_def.area_extent[0],\n",
    "        abs((new_shape[0])*area_def.pixel_size_x) + area_def.area_extent[1],\n",
    "        area_def.area_extent[0],\n",
    "        area_def.area_extent[1]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4680509.9514307166,\n",
       " 39397.988898263771,\n",
       " 5381159.9514307166,\n",
       " 649597.98889826378)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_def.area_extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bbox_area_def = area_def_crop(area_def, new_shape, area_extent=area_extent_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5602109.9514307166,\n",
       " 960997.98889826378,\n",
       " 4680509.9514307166,\n",
       " 39397.988898263771)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox_area_def.area_extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-921600.0\n",
      "-921600.0\n"
     ]
    }
   ],
   "source": [
    "print bbox_area_def.area_extent[3] - bbox_area_def.area_extent[1]\n",
    "print bbox_area_def.area_extent[2] - bbox_area_def.area_extent[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print (bbox_area_def.area_extent[3] - bbox_area_def.area_extent[1] - (bbox_area_def.area_extent[2] - bbox_area_def.area_extent[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find image corner coords"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def trim_array(input_array):\n",
    "    msk = input_array.mask\n",
    "    rows = np.flatnonzero((~msk).sum(axis=1))\n",
    "    cols = np.flatnonzero((~msk).sum(axis=0))\n",
    "    r = (rows.min(), rows.max())\n",
    "    c = (cols.min(), cols.max())\n",
    "#     return r, c, input_array[rows.min():rows.max()+1, cols.min():cols.max()+1]\n",
    "    return r, c\n",
    "\n",
    "r, c = trim_array(sigma0_res)\n",
    "# print r,c "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# from pyresample import _spatial_mp\n",
    "# pobj = _spatial_mp.Proj(area_def.proj4_string)\n",
    "# geospatial_extent = zeros((2,2))\n",
    "# k=0\n",
    "# for k in range(2):\n",
    "#     xm_, ym_ = pobj(lonlim[k], latlim[k])\n",
    "#     upl_x = area_def.area_extent[0]\n",
    "#     upl_y = area_def.area_extent[3]\n",
    "#     x__ = int((xm_ - upl_x) / area_def.pixel_size_x)\n",
    "#     y__ = int((upl_y - ym_) / area_def.pixel_size_y)\n",
    "#     print y__, x__\n",
    "#     geospatial_extent[k] = area_def.get_proj_coords(data_slice=(y__, x__))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "shp = zeros((4,))\n",
    "# Find first instance of non zero number\n",
    "shp[0] = next((i for i, x in enumerate(sigma0_res[r[0],:]) if x!=sigma0_res.fill_value), None)\n",
    "shp[1] = next((i for i, x in enumerate(sigma0_res[r[1],:]) if x!=sigma0_res.fill_value), None)\n",
    "shp[2] = next((i for i, x in enumerate(sigma0_res[:,c[0]]) if x!=sigma0_res.fill_value), None)\n",
    "shp[3] = next((i for i, x in enumerate(sigma0_res[:,c[1]]) if x!=sigma0_res.fill_value), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "geospatial_extent = (\n",
    "    bbox_area_def.get_proj_coords(data_slice=(shp[0],r[0])),\n",
    "    bbox_area_def.get_proj_coords(data_slice=(r[0],shp[2])),\n",
    "    bbox_area_def.get_proj_coords(data_slice=(shp[1],r[1])),\n",
    "    bbox_area_def.get_proj_coords(data_slice=(c[1],shp[3])),\n",
    "    bbox_area_def.get_proj_coords(data_slice=(shp[0],r[0]))\n",
    "    )\n",
    "# geospatial_extent"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "geospatial_extent_ll = Polygon((\n",
    "    bbox_area_def.get_lonlats(data_slice=(shp[0],r[0])),\n",
    "    bbox_area_def.get_lonlats(data_slice=(r[0],shp[2])),\n",
    "    bbox_area_def.get_lonlats(data_slice=(shp[1],r[1])),\n",
    "    bbox_area_def.get_lonlats(data_slice=(c[1],shp[3]))\n",
    "    ))\n",
    "# geospatial_extent_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lats_2[0,0] - lats_2.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((50.438888310483136, 43.036074734398703), (45.475959075236169, 43.745130824321627), (46.549892853360525, 48.338808541640809), (51.933249472481904, 47.619819422049204))\n"
     ]
    }
   ],
   "source": [
    "print ((lons_2[-1,-1],lats_2[-1,-1]),\n",
    "    (lons_2[-1,0],lats_2[-1,0]),\n",
    "    (lons_2[0,0],lats_2[0,0]),\n",
    "    (lons_2[0,-1],lats_2[0,-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if lats_2[0,0] < lats_2[-1,0] and lats_2[0,-1] < lats_2[-1,-1]:\n",
    "    geo_extent = (\n",
    "    (lons_2[-1,-1],lats_2[-1,-1]),\n",
    "    (lons_2[-1,0],lats_2[-1,0]),\n",
    "    (lons_2[0,0],lats_2[0,0]),\n",
    "    (lons_2[0,-1],lats_2[0,-1])\n",
    "    )\n",
    "elif lats_2[0,0] > lats_2[-1,0] and lats_2[0,-1] > lats_2[-1,-1]:\n",
    "    geo_extent = (\n",
    "    (lons_2[0,0],lats_2[0,0]),\n",
    "    (lons_2[0,-1],lats_2[0,-1]),\n",
    "    (lons_2[-1,-1],lats_2[-1,-1]),\n",
    "    (lons_2[-1,0],lats_2[-1,0])\n",
    "    )\n",
    "\n",
    "geospatial_extent_ll = Polygon(geo_extent)\n",
    "# geospatial_extent_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get list of available resolutions\n",
    "avail_resolution_list = [int(256*math.pow(2, i)) for i in range(15)]\n",
    "\n",
    "# get first guess size of area\n",
    "# size = int(256*math.pow(2, 14)/res)\n",
    "_size = abs(int(-5000000 - 5000000) / resolution)\n",
    "\n",
    "# get closest size of area from available resolutions list\n",
    "size = min(filter(lambda x: _size <= x,\n",
    "                              avail_resolution_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extent is large enough, not to get errors about points outside area\n",
    "_area_def = pr.geometry.AreaDefinition(\n",
    "           'epsg_3413_crude', 'NSIDC Polar Stereographic North EPSG:3413',\n",
    "           'epsg_3413_crude',\n",
    "           {'proj': 'stere', 'lat_0': '90',\n",
    "            'lon_0': '-45', 'lat_ts': '70', 'ellps': 'WGS84',\n",
    "            'datum': 'WGS84', 'units': 'm'}, size, size,\n",
    "           [-6000000, -6000000, 6000000, 6000000]\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ASA_WSM_1PNPDE20120209_070543_000000923111_00279_52017_9057.N1'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((46.549892853360525, 48.338808541640809),\n",
       " (51.933249472481904, 47.619819422049204),\n",
       " (50.438888310483136, 43.036074734398703),\n",
       " (45.475959075236169, 43.745130824321627))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5286071.77734375, 42297.36328125)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_area_def.get_proj_coords(data_slice=(_area_def.get_xy_from_lonlat(45.46,43.78)[::-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print (_area_def.get_xy_from_lonlat(geo_extent[0][0], geo_extent[0][1]),\n",
    "# _area_def.get_xy_from_lonlat(geo_extent[1][0], geo_extent[1][1]),\n",
    "# _area_def.get_xy_from_lonlat(geo_extent[2][0], geo_extent[2][1]),\n",
    "# _area_def.get_xy_from_lonlat(geo_extent[3][0], geo_extent[3][1]))\n",
    "\n",
    "try:\n",
    "    geospatial_extent = (\n",
    "        _area_def.get_proj_coords(data_slice=(_area_def.get_xy_from_lonlat(geo_extent[0][0], geo_extent[0][1])[::-1])),\n",
    "        _area_def.get_proj_coords(data_slice=(_area_def.get_xy_from_lonlat(geo_extent[1][0], geo_extent[1][1])[::-1])),\n",
    "        _area_def.get_proj_coords(data_slice=(_area_def.get_xy_from_lonlat(geo_extent[2][0], geo_extent[2][1])[::-1])),\n",
    "        _area_def.get_proj_coords(data_slice=(_area_def.get_xy_from_lonlat(geo_extent[3][0], geo_extent[3][1])[::-1])),\n",
    "        _area_def.get_proj_coords(data_slice=(_area_def.get_xy_from_lonlat(geo_extent[0][0], geo_extent[0][1])[::-1]))\n",
    "        )\n",
    "except:\n",
    "    # if most southern lat is less 45 degrees we take the most southern point available from the area_def    \n",
    "    geospatial_extent = (\n",
    "        _area_def.get_proj_coords(data_slice=(_area_def.get_xy_from_lonlat(geo_extent[0][0], geo_extent[0][1])[::-1])),\n",
    "        _area_def.get_proj_coords(data_slice=(_area_def.get_xy_from_lonlat(geo_extent[1][0], geo_extent[1][1])[::-1])),\n",
    "        _area_def.get_proj_coords(data_slice=((_area_def.shape[1]/2, _area_def.shape[0]))),\n",
    "        _area_def.get_proj_coords(data_slice=((_area_def.shape[1]/2, _area_def.shape[0]))),\n",
    "        _area_def.get_proj_coords(data_slice=(_area_def.get_xy_from_lonlat(geo_extent[0][0], geo_extent[0][1])[::-1]))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4713287.353515625, 127410.888671875),\n",
       " (4768829.345703125, 579986.572265625),\n",
       " (5000152.587890625, -152.587890625),\n",
       " (5000152.587890625, -152.587890625),\n",
       " (4713287.353515625, 127410.888671875))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geospatial_extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geospatial_extent_ll.wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geospatial_extent_ll.wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geospatial_extent_ll.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print lats_2[0,0],lats_2[0,-1],lats_2[-1,-1],lats_2[-1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f7c7189c310>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASMAAAECCAYAAAC10LG+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nD/wXp9C4KDYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7c7906a150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(lats_2)\n",
    "jet()\n",
    "colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create NC tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/mag/Documents/repos/solab/posada/handlers/')\n",
    "\n",
    "import Tiles.nctiles\n",
    "reload(Tiles.nctiles)\n",
    "\n",
    "from Tiles.nctiles import create_nc_tiles, write_attrib_to_nc, array_size_normalize\n",
    "\n",
    "import re\n",
    "import datetime\n",
    "def get_date_parameters(granule_name):\n",
    "    ''' return year, month and day for current granule\n",
    "\n",
    "    '''\n",
    "    prog = re.compile(r'(\\d{8})')\n",
    "    file_date = prog.findall(granule_name)[0]\n",
    "    prog = re.compile(r'(\\d{6})')\n",
    "    file_time = prog.findall(granule_name)[1]\n",
    "    year = file_date[:4]\n",
    "    month = file_date[4:6]\n",
    "    day = file_date[6:]\n",
    "    \n",
    "    startTime = datetime.datetime.strptime(year+month+day+file_time,\n",
    "    \"%Y%m%d%H%M%S\")\n",
    "\n",
    "    return year, month, day, startTime\n",
    "\n",
    "def mkdirs(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%timeit -r 1 -n 1\n",
    "\n",
    "# def create_nc_tiles(inpath, fn, out_dir, scale=1):\n",
    "print \"Creating NC tiles.......\"\n",
    "\n",
    "pn = '/home/mag/Documents/repos/solab/PySOL/notebooks/pySAR/'\n",
    "pn = '/nfs1/store/nctiles/SOLAB_ASAR/epsg_3413/'\n",
    "# pn = '/media/SOLabNFS/hyrax-cluster/data/public/allData/tzh/'\n",
    "\n",
    "granule_name = fileName[:-3]\n",
    "\n",
    "year, month, day, startTime = get_date_parameters(granule_name)\n",
    "\n",
    "out_pn = os.path.join(pn, year, month, day)\n",
    "nc_path = os.path.join(out_pn, granule_name+'.nc')\n",
    "\n",
    "mkdirs(os.path.join(pn, year))\n",
    "mkdirs(os.path.join(pn, year, month))\n",
    "mkdirs(os.path.join(pn, year, month, day))\n",
    "\n",
    "if os.path.isfile(nc_path):\n",
    "    os.remove(nc_path)\n",
    "# if not os.path.isdir(os.path.dirname(nc_path)):\n",
    "#     os.makedirs(os.path.dirname(nc_path))\n",
    "\n",
    "# set Polarization formatting to comply with standards\n",
    "p = polarization.lower().replace('/', '')\n",
    "max_zoom_level = create_nc_tiles(10*log10(sigma0_res), nc_path, 'u1', 'sigma0', p, configpath='ASAR.json')\n",
    "# max_zoom_level = create_nc_tiles(ones(sigma0_res.shape), nc_path, 'u1', 'wind_speed', p, configpath='ASAR.json')\n",
    "\n",
    "pause(1)\n",
    "\n",
    "write_attrib_to_nc(nc_path, bbox_area_def.area_extent, startTime,\n",
    "                   max_zoom_level, resolution, geospatial_extent, geospatial_extent_ll, {p}, {'sigma0'})\n",
    "\n",
    "print \"%skb\" % str(np.round(os.path.getsize(nc_path)/1024))\n",
    "print \"%sMb\" % str(np.round(os.path.getsize(nc_path)/1024/1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import redis\n",
    "r = redis.Redis(host='10.170.0.153', password='jM8vBgR4', db=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r.dbsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r.flushall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r.keys(\"*lock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache the data from a specified set of netCDF files\n",
    "#### Request only one tile from every zoom level to cache all zoom levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from netCDF4 import Dataset as ncDataset\n",
    "\n",
    "# granule = 'S1A_EW_GRDM_1SDH_20141003T183449_20141003T183553_002669_002F93_5A6D'\n",
    "\n",
    "# pn = '/media/SOLabNFS2/store/satellite/SOLAB-SENTINEL-1/2014/10/03/'\n",
    "pn = '/nfs1/store/nctiles/SOLAB_ASAR/epsg_3413/2012/'\n",
    "\n",
    "# granule_list = listdir(pn)\n",
    "granule_list = [os.path.join(dn,fn) for dn,_,fns in os.walk(pn) for fn in fns if fn.endswith('.nc')]\n",
    "\n",
    "# product = 'SOLAB-SENTINEL-1'\n",
    "product = 'SOLAB_ASAR'\n",
    "var_list = ['sigma0']\n",
    "\n",
    "urls = []\n",
    "coords = []\n",
    "\n",
    "print \"Total number of files: %s\" %len(granule_list)\n",
    "for granule in granule_list:\n",
    "    dataset = ncDataset(granule)\n",
    "    try:\n",
    "        p = dataset.polarizations\n",
    "    except Exception as e:\n",
    "        p = 'vv'\n",
    "    coords = dataset.variables['Data'].shape\n",
    "    for var in var_list:\n",
    "        for zoom in range(coords[2]):\n",
    "            urls.append(\n",
    "                'http://10.170.0.153:9090/wms?' +\n",
    "                'product=' + product +\n",
    "                '&variable=' + var +\n",
    "                '&granule=' + granule[-62:-3] +\n",
    "                '&projection=EPSG%3A3413' +\n",
    "                '&polarization=' + str(p) +\n",
    "                '&vmin=63&vmax=191&' +\n",
    "                'zoom=' + str(zoom) +\n",
    "                '&x=' + str(0) +\n",
    "                '&y=' + str(0))\n",
    "    dataset.close()\n",
    "urls.sort()\n",
    "\n",
    "print \"Total number of zoom-level requests: %s\" %len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit -r 5 -n 10\n",
    "dataset = ncDataset(granule)\n",
    "body = dataset.variables['Data'][0, 0, 0, 0, 0, :]\n",
    "dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit -r 1\n",
    "for u in urls:\n",
    "    request = urlopen(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit -r 1\n",
    "request = urlopen(urls[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import redis\n",
    "r = redis.Redis(host='10.170.0.153', password='jM8vBgR4', db=0)\n",
    "r.dbsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r.keys('*lock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r.flushall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "def ntrctv_imshow(p = 'hh', vmi=-1., vma=1., cmap='bone', crop='[:,:]', dimNum=0):\n",
    "    # check if data type is dictionary and there is no wind\n",
    "    if type(data) == dict and all(k!='wind_speed' for k in data.iterkeys()):\n",
    "        plt.figure(figsize=(8,8*double(data[p].shape[0])/double(data[p].shape[1])))\n",
    "        plt.imshow(eval(\"data[p]\"+str(crop)), vmin=vmi, vmax=vma)\n",
    "    elif type(data) == dict and any(k=='wind_speed' for k in data.iterkeys()):\n",
    "        plt.figure(figsize=(8,8*double(data[p].shape[0])/double(data[p].shape[1])))\n",
    "        X,Y = meshgrid( arange(0,eval(\"data[p]\"+str(crop)).shape[1]),arange(0,eval(\"data[p]\"+str(crop)).shape[0]) )\n",
    "        U = (data['u'])\n",
    "        V = (data['v'])\n",
    "        U = eval(\"U\"+str(crop))\n",
    "        V = eval(\"V\"+str(crop))\n",
    "        scl = 100\n",
    "        plt.quiver(X[::scl,::scl], Y[::scl,::scl], U[::scl,::scl], V[::scl,::scl])\n",
    "        plt.imshow(eval(\"data[p]\"+str(crop)), vmin=vmi, vmax=vma)\n",
    "        plt.axis('tight')\n",
    "    elif type(data) != dict and len(data.shape)>2:\n",
    "        plt.figure(figsize=(8,8*double(data[:,:,0].shape[0])/double(data[:,:,0].shape[1])))\n",
    "        plt.imshow(eval(\"data[:,:,\"+str(dimNum)+\"]\"+str(crop)), vmin=vmi, vmax=vma)\n",
    "    elif type(data) != dict:\n",
    "        plt.figure(figsize=(8,8*double(data.shape[0])/double(data.shape[1])))\n",
    "        plt.imshow(eval(\"data\"+str(crop)), vmin=vmi, vmax=vma)\n",
    "    plt.colorbar()\n",
    "    plt.set_cmap(cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scale = 1\n",
    "data = 10*log10(sigma0_res)[::scale,::scale]\n",
    "\n",
    "ntrctv = widgets.interact(ntrctv_imshow, \\\n",
    "                          vmi=widgets.FloatSlider(min=-30, max=10, value=-20, step=1), \\\n",
    "                          vma=widgets.FloatSlider(min=-30, max=10, value=5, step=1), \\\n",
    "                          cmap = ['Greys_r', 'bone', 'RdBu_r'], crop = '[:,:]', \\\n",
    "                          dimNum=['0']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исправляем некорректные bbox при генерации nc-тайлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Trimming the array by removing masked values from rows and cols after resampling\n",
    "input_array = 10*log10(sigma0_res)\n",
    "msk = input_array.mask\n",
    "rows = np.flatnonzero((~msk).sum(axis=1))\n",
    "cols = np.flatnonzero((~msk).sum(axis=0))\n",
    "input_array = input_array[rows.min():rows.max()+1, cols.min():cols.max()+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalize array shape to be a multiple of 256\n",
    "avail_resolution_list = [int(256*math.pow(2, i)) for i in range(15)]\n",
    "shape = input_array.shape\n",
    "current_pixels = max(shape)\n",
    "necessary_pixels = min(filter(lambda x: current_pixels < x,\n",
    "                              avail_resolution_list))\n",
    "\n",
    "print shape\n",
    "print avail_resolution_list\n",
    "print necessary_pixels\n",
    "\n",
    "source_array = input_array[:]\n",
    "\n",
    "if type(input_array) == np.ma.core.MaskedArray:\n",
    "    m = input_array.fill_value\n",
    "else: \n",
    "    m = source_array.max()+999999\n",
    "\n",
    "top_array   = m*np.ones((necessary_pixels-shape[0], shape[1]))\n",
    "right_array = m*np.ones((necessary_pixels, necessary_pixels-shape[1]))\n",
    "source_array = ma.concatenate((top_array, source_array), axis=0)\n",
    "source_array = ma.concatenate((source_array, right_array), axis=1)\n",
    "\n",
    "source_array = np.ma.masked_equal(source_array, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = input_array\n",
    "\n",
    "ntrctv = widgets.interact(ntrctv_imshow, \\\n",
    "                          vmi=widgets.FloatSlider(min=-30, max=10, value=-20, step=1), \\\n",
    "                          vma=widgets.FloatSlider(min=-30, max=10, value=5, step=1), \\\n",
    "                          cmap = ['Greys_r', 'bone', 'RdBu_r'], crop = '[:,:]', \\\n",
    "                          dimNum=['0']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = source_array\n",
    "\n",
    "ntrctv = widgets.interact(ntrctv_imshow, \\\n",
    "                          vmi=widgets.FloatSlider(min=-30, max=10, value=-20, step=1), \\\n",
    "                          vma=widgets.FloatSlider(min=-30, max=10, value=5, step=1), \\\n",
    "                          cmap = ['Greys_r', 'bone', 'RdBu_r'], crop = '[:,:]', \\\n",
    "                          dimNum=['0']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Попытка ускорить генерацию тайлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_array = array_size_normalize(10*log10(sigma0_res), False)\n",
    "number_tiles = source_array.shape[0]/256\n",
    "zoom_level = int(math.log(number_tiles, 2))\n",
    "\n",
    "out_array = np.ones([zoom_level+1, number_tiles, number_tiles, 256, 256])\n",
    "\n",
    "_min = -20\n",
    "_max = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decrease_zoom(source_array):\n",
    "    rows, cols = source_array.shape\n",
    "    rows_2 = rows/2\n",
    "    cols_2 = cols/2\n",
    "    sh = rows_2, rows//rows_2, cols_2, cols//cols_2\n",
    "    return source_array.reshape(sh).mean(-1).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def array_slice(m):\n",
    "    m = ma.where(m <= _min, _min + 0.0001, m)\n",
    "    m = ma.where(m >= _max, _max, m)\n",
    "    number_tiles = m.shape[0]/256\n",
    "    result = np.zeros([number_tiles, number_tiles, 256, 256])\n",
    "    # No need to use itertools etc. as this gives no speed up in this looping\n",
    "    for i in xrange(number_tiles):\n",
    "        for j in xrange(number_tiles):\n",
    "            result[i,j,:] = m[j*256:(j+1)*256, i*256:(i+1)*256]\n",
    "\n",
    "    return result\n",
    "\n",
    "def saveResult(result):\n",
    "    results.append(result)\n",
    "\n",
    "def test_par(source_array):\n",
    "    number_tiles = source_array.shape[0]/256\n",
    "    zoom_level = int(math.log(number_tiles, 2))\n",
    "    for zoom in range(zoom_level, -1, -1):\n",
    "        pool.apply_async(array_slice, args=(source_array, ), callback=saveResult)\n",
    "        if zoom:\n",
    "            source_array = decrease_zoom(source_array)\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "pool = Pool(processes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "out_array = test_par(source_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(source_array):\n",
    "    number_tiles = source_array.shape[0]/256\n",
    "    zoom_level = int(math.log(number_tiles, 2))\n",
    "    out_array = np.ones([zoom_level+1, number_tiles, number_tiles, 256, 256])\n",
    "    for zoom in range(zoom_level, -1, -1):\n",
    "        m = source_array\n",
    "        m = ma.where(m <= _min, _min + 0.0001, m)\n",
    "        m = ma.where(m >= _max, _max, m)\n",
    "        number_tiles = m.shape[0]/256\n",
    "\n",
    "        for i in xrange(number_tiles):\n",
    "            for j in xrange(number_tiles):\n",
    "                out_array[zoom, i, j, :] = m[j*256:(j+1)*256, i*256:(i+1)*256]\n",
    "\n",
    "        if zoom:\n",
    "            source_array = decrease_zoom(source_array)\n",
    "  \n",
    "    return out_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "out_array = test(source_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print source_array.shape, out_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Tiles.nctiles\n",
    "reload(Tiles.nctiles)\n",
    "# Переделать чтобы сначала маскировался массив и перегонялся в uint8, а потом уде разбивать на тайлы\n",
    "# Может будет быстрее\n",
    "# исрользовать numba или numexpr, cpython\n",
    "# оказалось, что не быстрее\n",
    "from Tiles.nctiles import create_nc_tiles, write_attrib_to_nc, array_size_normalize"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Переделать чтобы сначала маскировался массив и перегонялся в uint8, а потом уде разбивать на тайлы\n",
    "# Может будет быстрее\n",
    "# исрользовать numba или numexpr, cpython\n",
    "# оказалось, что не быстрее\n",
    "\n",
    "def create_base_tiles(input_array):\n",
    "    number_tiles = input_array.shape[0]/256\n",
    "\n",
    "    lines = []\n",
    "    all_list = []\n",
    "\n",
    "    for i in xrange(number_tiles):\n",
    "        for j in xrange(number_tiles):\n",
    "            # print '[%d:%d' % (j*256, (j+1)*256), ',%d:%d]'%(i*256, (i+1)*256)\n",
    "            lines.append(input_array[j*256:(j+1)*256, i*256:(i+1)*256])\n",
    "\n",
    "        all_list.append(lines)\n",
    "        lines = []\n",
    "    return all_list\n",
    "\n",
    "def write_tile_to_nc(nc_variable, tiles_array, variable, zoom, _min=0, _max=4,\n",
    "                     nc_data_type='u1', polarization=None):\n",
    "    for row_number in range(len(tiles_array)):\n",
    "        tile_row = tiles_array[row_number]\n",
    "        for col_number in range(len(tile_row)):\n",
    "            m = tile_row[col_number]\n",
    "            m = ma.where(m <= _min, _min + 0.0001, m)\n",
    "            m = ma.where(m >= _max, _max, m)\n",
    "\n",
    "            # 0-254 , 255 for mask\n",
    "            if nc_data_type == 'u1':\n",
    "                m = (m-_min)/float(_max-_min) * (2**8-2)\n",
    "                m = np.where(m.mask, (2**8-1), m)\n",
    "                m = np.uint8(m)\n",
    "            elif nc_data_type == 'u2':\n",
    "                m = (m-_min)/float(_max-_min) * (2**16-2)\n",
    "                m = np.where(m.mask, (2**16-1), m)\n",
    "                m = np.uint16(m)\n",
    "            elif nc_data_type == 'u4':\n",
    "                m = (m-_min)/float(_max-_min) * (2**32-2)\n",
    "                m = np.where(m.mask, (2**32-1), m)\n",
    "                m = np.uint32(m)\n",
    "            elif nc_data_type == 'u8':\n",
    "                m = (m-_min)/float(_max-_min) * (2**64-2)\n",
    "                m = np.where(m.mask, (2**64-1), m)\n",
    "                m = np.uint64(m)\n",
    "\n",
    "def write_tile_to_nc_v2(nc_variable, m, variable, zoom, _min=0, _max=4,\n",
    "                     nc_data_type='u1', polarization=None):\n",
    "\n",
    "    m = ma.where(m <= _min, _min + 0.0001, m)\n",
    "    m = ma.where(m >= _max, _max, m)\n",
    "\n",
    "    # 0-254 , 255 for mask\n",
    "    if nc_data_type == 'u1':\n",
    "        m = (m-_min)/float(_max-_min) * (2**8-2)\n",
    "        m = np.where(m.mask, (2**8-1), m)\n",
    "        m = np.uint8(m)\n",
    "        print m.shape\n",
    "    elif nc_data_type == 'u2':\n",
    "        m = (m-_min)/float(_max-_min) * (2**16-2)\n",
    "        m = np.where(m.mask, (2**16-1), m)\n",
    "        m = np.uint16(m)\n",
    "    elif nc_data_type == 'u4':\n",
    "        m = (m-_min)/float(_max-_min) * (2**32-2)\n",
    "        m = np.where(m.mask, (2**32-1), m)\n",
    "        m = np.uint32(m)\n",
    "    elif nc_data_type == 'u8':\n",
    "        m = (m-_min)/float(_max-_min) * (2**64-2)\n",
    "        m = np.where(m.mask, (2**64-1), m)\n",
    "        m = np.uint64(m)\n",
    "\n",
    "    number_tiles = m.shape[0]/256\n",
    "    lines = []\n",
    "    all_list = []\n",
    "\n",
    "    for i in xrange(number_tiles):\n",
    "        for j in xrange(number_tiles):\n",
    "            # print '[%d:%d' % (j*256, (j+1)*256), ',%d:%d]'%(i*256, (i+1)*256)\n",
    "            lines.append(m[j*256:(j+1)*256, i*256:(i+1)*256])\n",
    "\n",
    "        all_list.append(lines)\n",
    "        lines = []\n",
    "    return all_list\n",
    "\n",
    "%%timeit -r 1 -n 1\n",
    "tiles = create_base_tiles(10*log10(sigma0_res))\n",
    "write_tile_to_nc(0, tiles, 0, 0,\n",
    "                 _min=25, _max=5,\n",
    "                 nc_data_type='u1',\n",
    "                 polarization=0)\n",
    "\n",
    "%%timeit -r 1 -n 1\n",
    "tiles = write_tile_to_nc_v2(0, 10*log10(sigma0_res), 0, 0,\n",
    "                 _min=25, _max=5,\n",
    "                 nc_data_type='u1',\n",
    "                 polarization=0)\n",
    "\n",
    "%%cython -a\n",
    "\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "\n",
    "import cython\n",
    "cimport cython\n",
    "\n",
    "# DTYPE = np.float32\n",
    "# ctypedef np.float32_t DTYPE_t\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def create_base_tiles_2(np.ndarray[float, ndim=2] input_array):\n",
    "    cdef int number_tiles = input_array.shape[0]/256\n",
    "\n",
    "#     cdef int N = temp.size()\n",
    "#     cdef list OutputList = N*[0]\n",
    "    \n",
    "    lines = []\n",
    "    all_list = []\n",
    "\n",
    "    for i in xrange(number_tiles):\n",
    "        for j in xrange(number_tiles):\n",
    "#             print '[%d:%d' % (j*256, (j+1)*256), ',%d:%d]'%(i*256, (i+1)*256)\n",
    "            lines.append(input_array[j*256:(j+1)*256, i*256:(i+1)*256])\n",
    "\n",
    "        all_list.append(lines)\n",
    "        lines = []\n",
    "    return all_list\n",
    "\n",
    "%%timeit -r 1 -n 1\n",
    "tiles = create_base_tiles_2(sigma0_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLD VERSION with big_image png tiles"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from big_image import save_big_image\n",
    "__author__ = 'Alexander Myasoedov and Denis Spiridonov'\n",
    "\n",
    "# set the number of CPUs\n",
    "numProcs = cpu_count()-2\n",
    "\n",
    "redis_conf = os.path.join(\n",
    "    os.path.dirname(\n",
    "        os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "    ),\n",
    "    'redis.conf'\n",
    ")\n",
    "\n",
    "config = ConfigParser.RawConfigParser()\n",
    "config.read(redis_conf)\n",
    "redis_host = config.get('AUTH', 'HOSTNAME')\n",
    "redis_passwd = config.get('AUTH', 'PASSWORD')\n",
    "\n",
    "r = redis.Redis(host=redis_host, password=redis_passwd)\n",
    "\n",
    "\n",
    "def windDirection(u, v):\n",
    "    U = u.ravel()\n",
    "    V = v.ravel()\n",
    "    direction = zeros(size(U))\n",
    "    for i in range(0, len(U)):\n",
    "        if U[i] >= 0 and V[i] > 0:\n",
    "            direction[i] = ((180 / pi) * atan(abs(U[i] / V[i])) + 180)\n",
    "        if U[i] < 0 and V[i] > 0:\n",
    "            direction[i] = (-(180 / pi) * atan(abs(U[i] / V[i])) + 180)\n",
    "        if U[i] >= 0 and V[i] < 0:\n",
    "            direction[i] = (-(180 / pi) * atan(abs(U[i] / V[i])) + 360)\n",
    "        if U[i] < 0 and V[i] < 0:\n",
    "            direction[i] = ((180 / pi) * atan(abs(U[i] / V[i])))\n",
    "        if V[i] == 0 and U[i] > 0:\n",
    "            direction[i] = 270\n",
    "        if V[i] == 0 and U[i] < 0:\n",
    "            direction[i] = 90\n",
    "        if V[i] == 0 and U[i] == 0:\n",
    "            direction[i] = 0\n",
    "    return reshape(direction, v.shape)\n",
    "\n",
    "\n",
    "def PR_Mouche(theta, phi):\n",
    "    A_0 = 0.00650704\n",
    "    B_0 = 0.128983\n",
    "    C_0 = 0.992839\n",
    "    A_HALF_PI = 0.00782194\n",
    "    B_HALF_PI = 0.121405\n",
    "    C_HALF_PI = 0.992839\n",
    "    A_PI = 0.00598416\n",
    "    B_PI = 0.140952\n",
    "    C_PI = 0.992885\n",
    "\n",
    "    P_0 = A_0 * exp(B_0 * theta) + C_0\n",
    "    P_HALF_PI = A_HALF_PI * exp(B_HALF_PI * theta) + C_HALF_PI\n",
    "    P_PI = A_PI * exp(B_PI * theta) + C_PI\n",
    "\n",
    "    C0 = (P_0 + P_PI + 2 * P_HALF_PI) / 4\n",
    "    C1 = (P_0 - P_PI) / 2\n",
    "    C2 = (P_0 + P_PI - 2 * P_HALF_PI) / 4\n",
    "\n",
    "    P = C0 + C1 * cos(radians(phi)) + C2 * cos(radians(2 * phi))\n",
    "    return P\n",
    "\n",
    "\n",
    "def ncepGFSmodel(startTime, lats_2, lons_2):\n",
    "    \"\"\"NCEP GFS model wind for givven time, lat/lon crop\n",
    "\n",
    "    \"\"\"\n",
    "    ncepGFSmodel = {}  # empty dict for ncepGFSmodel\n",
    "\n",
    "    iPath_wind = '/media/SOLabNFS2/store/model/ncep/gfs/'\n",
    "\n",
    "    # find the ncep gfs filename to open from ASAR filename\n",
    "    baseHour = floor((startTime.hour+3/2)/6)*6\n",
    "    baseHour = min(18, baseHour)\n",
    "    if startTime.hour-baseHour > 1.5:\n",
    "        forecastHour = 3\n",
    "    else:\n",
    "        forecastHour = 0\n",
    "\n",
    "    if startTime <= datetime.datetime(2014, 8, 19):\n",
    "        ncepFileName = 'gfs' + startTime.strftime(\"%Y%m%d\") + '/gfs.t' +\\\n",
    "                       '%.2d' % (baseHour) + 'z.master.grbf' +\\\n",
    "                       '%.2d' % (forecastHour)\n",
    "\n",
    "        try:\n",
    "            grbs = pygrib.open(iPath_wind + ncepFileName)\n",
    "        except:\n",
    "            print \"File not found %s\" % (iPath_wind + ncepFileName)\n",
    "            return False\n",
    "\n",
    "        u_wind = None\n",
    "        v_wind = None\n",
    "\n",
    "        # wind contains u=u_wind.values[:], Lats=u_wind.latlons()[0], Lons=u_wind.latlons()[1]\n",
    "        for idx, msg_info in enumerate(grbs.select()):\n",
    "            if msg_info['short_name'] == '10u':\n",
    "                u_wind = grbs.message(idx + 1)\n",
    "            elif msg_info['short_name'] == '10v':\n",
    "                v_wind = grbs.message(idx + 1)\n",
    "\n",
    "        u = u_wind.values[:]\n",
    "        v = v_wind.values[:]\n",
    "        lats_wind = u_wind.latlons()[0]\n",
    "        lons_wind = u_wind.latlons()[1]\n",
    "    else:\n",
    "        ncepFileName = 'gfs.' + startTime.strftime(\"%Y%m%d\") +\\\n",
    "                       '%.2d' % (baseHour) + '/gfs.t' + '%.2d' % (baseHour) +\\\n",
    "                       'z.master.grbf' + '%.2d' % (forecastHour) +\\\n",
    "                       '.10m.uv.grib2'\n",
    "\n",
    "        grbs = pygrib.open(iPath_wind + ncepFileName)\n",
    "\n",
    "        u_wind = grbs.message(1)\n",
    "        v_wind = grbs.message(2)\n",
    "        u = u_wind['values']\n",
    "        v = v_wind['values']\n",
    "        lats_wind = u_wind['latitudes']\n",
    "        lons_wind = u_wind['longitudes']\n",
    "        lons_wind = reshape(lons_wind, (lons_wind.shape[0]/720, 720))\n",
    "        lats_wind = reshape(lats_wind, (lats_wind.shape[0]/720, 720))\n",
    "\n",
    "    # Make sure the longitude is between -180.00 .. 179.9\n",
    "    lons_wind = map(\n",
    "        lambda x:\n",
    "        (lons_wind.ravel()[x]+180)-int((lons_wind.ravel()[x]+180)/360)*360-180,\n",
    "        range(0, lons_wind.size)\n",
    "    )\n",
    "    lons_wind = reshape(lons_wind, lats_wind.shape)\n",
    "    # plt.close('all')\n",
    "    # plt.imshow(lons_wind)\n",
    "    # plt.colorbar()\n",
    "\n",
    "#     #Make sure the latitudes is between -90.00 .. 89.9, starting from North - positive\n",
    "#     lats_wind = map(lambda x : (lats_wind.ravel()[x]+90)-int((lats_wind.ravel()[x]+90)/180)*180-90, xrange(0,lats_wind.size))\n",
    "#     lats_wind = reshape(lats_wind, lons_wind.shape)\n",
    "#     if lats_wind[0,0] < lats_wind[-1,-1]:\n",
    "#         lats_wind = flipud(lats_wind)\n",
    "#         u = flipud(u)\n",
    "#         v = flipud(v)\n",
    "#     plt.close('all')\n",
    "#     plt.imshow(lats_wind)\n",
    "#     plt.colorbar()\n",
    "\n",
    "    # find subset\n",
    "    res = findSubsetIndices(lats_2.min(), lats_2.max(), lons_2.min(),\n",
    "                            lons_2.max(), lats_wind[:, 0], lons_wind[0, :])\n",
    "    # expand subset by 1 pixel for better further pyresample\n",
    "    res[0] = res[0]-2\n",
    "    res[1] = res[1]+2\n",
    "    res[2] = res[2]-2\n",
    "    res[3] = res[3]+2\n",
    "\n",
    "    # crop the data\n",
    "    u = u[int(res[2]):int(res[3]), int(res[0]):int(res[1])]\n",
    "    v = v[int(res[2]):int(res[3]), int(res[0]):int(res[1])]\n",
    "    ncepGFSmodel['lats_wind'] = lats_wind[int(res[2]):int(res[3]),\n",
    "                                          int(res[0]):int(res[1])]\n",
    "    ncepGFSmodel['lons_wind'] = lons_wind[int(res[2]):int(res[3]),\n",
    "                                          int(res[0]):int(res[1])]\n",
    "\n",
    "    ncepGFSmodel['wind_dir'] = windDirection(u, v)\n",
    "    ncepGFSmodel['wind_speed'] = sqrt(u**2 + v**2)\n",
    "\n",
    "#     del u_wind, v_wind\n",
    "    return ncepGFSmodel\n",
    "\n",
    "\n",
    "def create_KML_asar(area_extent, savepath):\n",
    "    kml = simplekml.Kml()\n",
    "\n",
    "    pol = kml.newpolygon(name='area_extent', visibility=1)\n",
    "    pol.tessellate = 1\n",
    "\n",
    "    pol.altitudemode = 'clampToGround'\n",
    "    pol.outerboundaryis.coords = [(min(area_extent[0], area_extent[2]),\n",
    "                                   min(area_extent[1], area_extent[3])),\n",
    "                                  (max(area_extent[0], area_extent[2]),\n",
    "                                   max(area_extent[1], area_extent[3]))]\n",
    "    if type(savepath) == list:\n",
    "        for _savepath in savepath:\n",
    "            kml.save(_savepath)\n",
    "    else:\n",
    "        kml.save(savepath)\n",
    "\n",
    "\n",
    "def swath_area_def(name='Temporal SWATH EPSG Projection 4326', proj='eqc',\n",
    "                   lonlim=(-180, 180), latlim=(-90, 90), ellps=\"WGS84\",\n",
    "                   res=111.2e3, lat_ts=None, lat_0=None, lon_0=None):\n",
    "    \"\"\"\n",
    "    Convert given swath coordinates to pyresample area definition.\n",
    "    The arguments are standard for Proj:\n",
    "    name\n",
    "    proj\n",
    "    lonlim\n",
    "    latlim\n",
    "    ellipsoid\n",
    "    resolution(meters)\n",
    "    lat_ts (latitude of true scale)\n",
    "    lat_0,lon_0 is central point\n",
    "    EXAMPLE:\n",
    "\n",
    "    epsg3426 is the default one\n",
    "    for epsg3413:\n",
    "    swath_area_def(name='Temporal SWATH EPSG Projection 3413',\n",
    "                   proj='stere', lonlim=(-180,180), latlim=(30,90),\n",
    "                   ellps=\"WGS84\", res=111.2e3, lat_ts=70, lat_0=90, lon_0=-45)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    up = max(latlim)\n",
    "    down = min(latlim)\n",
    "    left = min(lonlim)\n",
    "    right = max(lonlim)\n",
    "\n",
    "    print 'up, down, left, right: ', up, down, left, right\n",
    "\n",
    "    area_id = name.replace(\" \", \"_\").lower()\n",
    "    proj_id = area_id\n",
    "\n",
    "    if proj == 'eqc':\n",
    "        p = Proj(proj=proj, llcrnrlat=up, urcrnrlat=down, llcrnrlon=left,\n",
    "                 urcrnrlon=right, ellps=ellps)\n",
    "        proj4_args = '+proj=' + str(proj) + ' ' + \\\n",
    "                     '+llcrnrlat=' + str(up) + ' ' + \\\n",
    "                     '+urcrnrlat=' + str(down) + ' ' + \\\n",
    "                     '+llcrnrlon=' + str(left) + ' ' + \\\n",
    "                     '+urcrnrlon=' + str(right) + ' ' + \\\n",
    "                     '+ellps=' + str(ellps)\n",
    "    elif lat_ts is not None and lat_0 is not None:\n",
    "        # lat_ts is latitude of true scale.\n",
    "        # lon_0,lat_0 is central point.\n",
    "        p = Proj(proj=proj, lat_0=lat_0, lon_0=lon_0,\n",
    "                 lat_ts=lat_ts, ellps=ellps)\n",
    "        proj4_args = '+proj=' + str(proj) + ' ' + \\\n",
    "                     '+lat_0=' + str(lat_0) + ' ' + \\\n",
    "                     '+lon_0=' + str(lon_0) + ' ' + \\\n",
    "                     '+lat_ts=' + str(lat_ts) + ' ' + \\\n",
    "                     '+ellps=' + str(ellps)\n",
    "    elif lon_0 is not None and lat_0 is not None and lat_ts is None:\n",
    "        # lon_0,lat_0 is central point.\n",
    "        p = Proj(proj=proj, lat_0=lat_0, lon_0=lon_0, ellps=ellps)\n",
    "        proj4_args = '+proj=' + str(proj) + ' ' + \\\n",
    "                     '+lat_0=' + str(lat_0) + ' ' + \\\n",
    "                     '+lon_0=' + str(lon_0) + ' ' + \\\n",
    "                     '+ellps=' + str(ellps)\n",
    "    elif lon_0 is None and lat_0 is None and lat_ts is None:\n",
    "        # lon_0,lat_0 is central point.\n",
    "        lat_0 = (up + down) / 2\n",
    "        lon_0 = (right + left) / 2\n",
    "        p = Proj(proj=proj, lat_0=lat_0, lon_0=lon_0, ellps=ellps)\n",
    "        proj4_args = '+proj=' + str(proj) + ' ' + \\\n",
    "                     '+lat_0=' + str(lat_0) + ' ' + \\\n",
    "                     '+lon_0=' + str(lon_0) + ' ' + \\\n",
    "                     '+ellps=' + str(ellps)\n",
    "\n",
    "    left_ex1, up_ex1 = p(left, up)\n",
    "    right_ex1, up_ex2 = p(right, up)\n",
    "    left_ex2, down_ex1 = p(left, down)\n",
    "    right_ex2, down_ex2 = p(right, down)\n",
    "\n",
    "    if proj == 'stere':\n",
    "        lon = (left+right)/2.0\n",
    "        if (lon >= 0 and lon < 90) or (lon >= -360 and lon < -270):\n",
    "            print 11111111111\n",
    "            area_extent = (\n",
    "                           min(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                           min(down_ex1, down_ex2, up_ex1, up_ex2),\n",
    "                           max(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                           max(down_ex1, down_ex2, up_ex1, up_ex2)\n",
    "                          )\n",
    "        elif (lon >= 90 and lon < 180) or (lon >= -270 and lon < -180):\n",
    "            print 2222222222222\n",
    "            area_extent = (\n",
    "                       max(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                       max(down_ex1, down_ex2, up_ex1, up_ex2),\n",
    "                       min(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                       min(down_ex1, down_ex2, up_ex1, up_ex2)\n",
    "                       )\n",
    "        elif (lon >= 180 and lon < 270) or (lon >= -180 and lon < -90):\n",
    "            print 333333333333\n",
    "            area_extent = (\n",
    "                       min(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                       min(down_ex1, down_ex2, up_ex1, up_ex2),\n",
    "                       max(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                       max(down_ex1, down_ex2, up_ex1, up_ex2)\n",
    "                      )\n",
    "        else:\n",
    "            print 44444444444444444\n",
    "            area_extent = (\n",
    "                       min(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                       min(down_ex1, down_ex2, up_ex1, up_ex2),\n",
    "                       max(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                       max(down_ex1, down_ex2, up_ex1, up_ex2)\n",
    "                      )\n",
    "    else:\n",
    "        # минимум из всех координат X, Y, максимум из всех координат X, Y\n",
    "        # Такой результат даёт правильный area_extent для 3413\n",
    "        # При этом для 4326 area_extent остаётся неизменным\n",
    "        # area_def_3413 = swath_area_def(name='Temporal SWATH EPSG\n",
    "        # Projection 3413', proj='stere', \\\n",
    "        #         lonlim=(-180,180), latlim=(30,90), ellps=\"WGS84\", res=1500, \\\n",
    "        #         lat_ts=70, lat_0=90, lon_0=-45)\n",
    "        # Area extent: (-5050747.263141337, 0.0, 0.0, 5050747.263141336)\n",
    "        area_extent = (\n",
    "                min(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                min(up_ex1, up_ex2, down_ex1, down_ex2),\n",
    "                max(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                max(up_ex1, up_ex2, down_ex1, down_ex2)\n",
    "        )\n",
    "\n",
    "    print 'left: ', left_ex1, left_ex2\n",
    "    print 'right: ', right_ex1, right_ex2\n",
    "    print 'up: ', up_ex1, up_ex2\n",
    "    print 'down: ', down_ex1, down_ex2\n",
    "\n",
    "    # Using abs() to avoid negative numbers of coloumns/rows\n",
    "    # as for epsg3413 for example\n",
    "    xsize = abs(int((area_extent[2] - area_extent[0]) / res))\n",
    "    ysize = abs(int((area_extent[3] - area_extent[1]) / res))\n",
    "\n",
    "    swath_area_def = pr.utils.get_area_def(area_id, name, proj_id, proj4_args,\n",
    "                                           xsize, ysize, area_extent)\n",
    "\n",
    "#     print swath_area_def\n",
    "\n",
    "    return swath_area_def\n",
    "\n",
    "\n",
    "def imresize(image, size):\n",
    "    \"\"\"\n",
    "    Resizes coefficient arrays using bivariate spline approximation.\n",
    "    \"\"\"\n",
    "    m, n = image.shape\n",
    "    X = linspace(0, m - 1, size[0])\n",
    "    Y = linspace(0, n - 1, size[1])\n",
    "    kx, ky = min([m - 1, 3]), min([n - 1, 3])\n",
    "    interp = RectBivariateSpline(\n",
    "        arange(m), arange(n), image, kx=kx, ky=ky)\n",
    "    resized = interp(X, Y)\n",
    "    return resized\n",
    "\n",
    "\n",
    "def create_asar_image(iPath, oPaths, fileName):\n",
    "    oPath_4326, oPath_3413 = oPaths\n",
    "\n",
    "    print os.path.join(iPath, fileName)\n",
    "    try:\n",
    "        product = epr.Product(os.path.join(iPath, fileName))\n",
    "    except:\n",
    "        print 'unable to read file'\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        band = product.get_band('proc_data')\n",
    "    except epr.EPRValueError:\n",
    "        print 'unable to get band \"proc_data\": epr_get_band_id: band not found'\n",
    "        return False\n",
    "\n",
    "    sc_w = product.get_scene_width()\n",
    "    sc_h = product.get_scene_height()\n",
    "\n",
    "    print 'sc_w*sc_h = ', sc_w * sc_h\n",
    "    if sc_w*sc_h > 60000000:\n",
    "#    if sc_w*sc_h > 24000000:\n",
    "        print \"ASAR Image too large, skipping\"\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        raw_counts = band.read_as_array(sc_w, sc_h)  # , xstep=4, ystep=4)\n",
    "\n",
    "        incident_angle = product.get_band('incident_angle').read_as_array(sc_w,\n",
    "                                                                          sc_h)\n",
    "        # , xstep=4, ystep=4)\n",
    "    except epr.EPRValueError:\n",
    "        print \"EPRValueError\"\n",
    "        return False\n",
    "\n",
    "    # Get lat/lon from geolocation grid\n",
    "    dataset = product.get_dataset('GEOLOCATION_GRID_ADS')\n",
    "    fltp_lats = map(\n",
    "        lambda x:\n",
    "        dataset.read_record(x).get_field('first_line_tie_points.lats').get_elems(),\n",
    "        range(dataset.get_num_records())\n",
    "    )\n",
    "    lltp_lats = map(\n",
    "        lambda x:\n",
    "        dataset.read_record(x).get_field('last_line_tie_points.lats').get_elems(),\n",
    "        range(dataset.get_num_records())\n",
    "    )\n",
    "    fltp_lons = map(\n",
    "        lambda x:\n",
    "        dataset.read_record(x).get_field('first_line_tie_points.longs').get_elems(),\n",
    "        range(dataset.get_num_records())\n",
    "    )\n",
    "    lltp_lons = map(\n",
    "        lambda x:\n",
    "        dataset.read_record(x).get_field('last_line_tie_points.longs').get_elems(),\n",
    "        range(dataset.get_num_records())\n",
    "    )\n",
    "\n",
    "    fltp_lats = asarray(double(fltp_lats))/1e6\n",
    "    lltp_lats = asarray(double(lltp_lats))/1e6\n",
    "    fltp_lons = asarray(double(fltp_lons))/1e6\n",
    "    lltp_lons = asarray(double(lltp_lons))/1e6\n",
    "\n",
    "    lats = row_stack((fltp_lats, lltp_lats[-1, :]))\n",
    "    lons = row_stack((fltp_lons, lltp_lons[-1, :]))\n",
    "\n",
    "    lats = fliplr(lats)\n",
    "    lons = fliplr(lons)\n",
    "\n",
    "    lats_2 = imresize(lats, raw_counts.shape)\n",
    "    lons_2 = imresize(lons, raw_counts.shape)\n",
    "\n",
    "    if lats.max() <= 35:\n",
    "        print \"skipping no area overlap\"\n",
    "        return False\n",
    "\n",
    "    for p in oPaths:\n",
    "        for sp in p:\n",
    "            mkdirs(sp)\n",
    "\n",
    "    # Trimming the array by removing zero values from rows and cols\n",
    "    msk = []\n",
    "    for m in range(raw_counts.shape[0]):\n",
    "        if raw_counts[m, :].sum() == 0:\n",
    "            msk.append(m)\n",
    "    raw_counts = delete(raw_counts, msk, axis=0)\n",
    "    lats_2 = delete(lats_2, msk, axis=0)\n",
    "    lons_2 = delete(lons_2, msk, axis=0)\n",
    "    incident_angle = delete(incident_angle, msk, axis=0)\n",
    "\n",
    "    msk = []\n",
    "    for n in range(raw_counts.shape[1]):\n",
    "        if raw_counts[:, n].sum() == 0:\n",
    "            msk.append(n)\n",
    "    raw_counts = delete(raw_counts, msk, axis=1)\n",
    "    lats_2 = delete(lats_2, msk, axis=1)\n",
    "    lons_2 = delete(lons_2, msk, axis=1)\n",
    "    incident_angle = delete(incident_angle, msk, axis=1)\n",
    "\n",
    "    # Adding Sigma_0\n",
    "    calibration_constant = \\\n",
    "    product.get_dataset('MAIN_PROCESSING_PARAMS_ADS').read_record(0).get_field('calibration_factors.1.ext_cal_fact').get_elems()\n",
    "    # sigma0 = 10*log10( raw_counts**2*sin(incident_angle*pi/180)/calibration_constant )\n",
    "    sigma0 = raw_counts**2*sin(incident_angle*pi/180)/calibration_constant\n",
    "\n",
    "\tfrom scipy.signal import wiener\n",
    "\tsigma0w = wiener(sigma0, mysize=(3,3), noise=None)\n",
    "\t# Lee-Wiener filtering blures to much the ASAR scenes, so we use it only for wind field\n",
    "\t# sigma0w = sigma0\n",
    "\n",
    "\t# # Earlier form Fabrice - simplyfied\n",
    "\t# pol = product.get_sph().get_field('MDS1_TX_RX_POLAR').get_elem()\n",
    "\t# if pol == 'H/H':\n",
    "\t#     ph = (2.20495, -14.3561e-2, 11.28e-4)\n",
    "\t#     sigma0_hh_ref = exp( ( ph[0]+incident_angle*ph[1]+incident_angle**2*ph[2])*log(10) )\n",
    "\t#     roughness = sigma0w/sigma0_hh_ref\n",
    "\t# elif pol == 'V/V':\n",
    "\t#     pv = (2.29373, -15.393e-2, 15.1762e-4)\n",
    "\t#     sigma0_vv_ref = exp( ( pv[0]+incident_angle*pv[1]+incident_angle**2*pv[2])*log(10) )\n",
    "\t#     roughness = sigma0w/sigma0_vv_ref\n",
    "\n",
    "\t# From sar/cerbere\n",
    "\tfrom cmod_vect import cmod5n_forward as cmod5\n",
    "\tpol = product.get_sph().get_field('MDS1_TX_RX_POLAR').get_elem()\n",
    "\tdef compute_roughness(sigma0, incidence, polarisation):\n",
    "\t    \"\"\"Compute sea surface roughness.\n",
    "\n",
    "\t    Parameters\n",
    "\t    ----------\n",
    "\t    sigma0 : ndarray\n",
    "\t        NRCS backscatter.\n",
    "\t    incidence : ndarray\n",
    "\t        Incidence angle in degrees.\n",
    "\t    polarisation : str\n",
    "\t        'VV' or 'HH' or 'VH' or 'HV'\n",
    "\n",
    "\t    Returns\n",
    "\t    -------\n",
    "\t    ndarray\n",
    "\t    \"\"\"\n",
    "\t    if polarisation == 'VV' or polarisation == 'V/V': # Use cmod5\n",
    "\t        sigma0_vv = cmod5(10, 45, incidence)\n",
    "\t        return sigma0/sigma0_vv\n",
    "\t    elif polarisation == 'HH' or polarisation == 'H/H': # Use cmod5 and Thompson polarisation ratio\n",
    "\t        sigma0_vv = cmod5(10, 45, incidence)\n",
    "\t        alpha = 0.7\n",
    "\t        polrat = (1 + 2*tan(incidence*pi/180)**2)**2 / \\\n",
    "\t                 (1 + alpha*tan(incidence*pi/180)**2)**2\n",
    "\t        return sigma0/sigma0_vv*polrat\n",
    "\t    elif polarisation == 'VH' or polarisation == 'HV' \\\n",
    "\t      or polarisation == 'V/H' or polarisation == 'H/V': # Use simple model\n",
    "\t        # nrcs_vh_db = 0.580*wsp - 35.652\n",
    "\t        # nrcs_vh_lin = 10^(nrcs_vh_db/10.)\n",
    "\t        sigma0_cross = 10**((0.58*10-35.652)/10)\n",
    "\t        return sigma0/sigma0_cross\n",
    "\t    else:\n",
    "\t        raise Exception('Unknown polarisation : '+polarisation)\n",
    "\n",
    "\troughness = compute_roughness(sigma0, incident_angle, pol)\n",
    "\n",
    "    # Adding Model wind\n",
    "    startTime = datetime.datetime.strptime(fileName[14:29], \"%Y%m%d_%H%M%S\")\n",
    "    ncepGFSmodelWind = ncepGFSmodel(startTime, lats_2, lons_2)\n",
    "    if not ncepGFSmodelWind:\n",
    "        return False\n",
    "\n",
    "    # Reprojecting data\n",
    "\n",
    "    # Pixel resolution\n",
    "    # we use pxlResWind/pxlResSAR for further pyresample radius_of_influence and sigmas\n",
    "    try:\n",
    "        pxlResWind = asarray(\n",
    "            distancelib.getPixelResolution(ncepGFSmodelWind['lats_wind'],\n",
    "                                           ncepGFSmodelWind['lons_wind'],\n",
    "                                           ncepGFSmodelWind['lats_wind'].shape,\n",
    "                                           'km')\n",
    "        )\n",
    "    except IndexError:\n",
    "        return False\n",
    "    pxlResSAR = asarray(\n",
    "        distancelib.getPixelResolution(lats_2, lons_2, lons_2.shape, 'km')\n",
    "    )*1e3\n",
    "    # Note pxlResWind is in KM, multiply by 1e3 for meters\n",
    "#    print \"ASAR cell resolution, %s m\"  % pxlResSAR\n",
    "#    print \"Wind cell resolution, %s km\" % pxlResWind\n",
    "\n",
    "    # reproject NCEP onto ASAR grid before calculations\n",
    "    # Try both BivariateSpline, griddata and pyresample\n",
    "\n",
    "    ncep_def = pr.geometry.GridDefinition(lons=ncepGFSmodelWind['lons_wind'],\n",
    "                                          lats=ncepGFSmodelWind['lats_wind'])\n",
    "    swath_def = pr.geometry.SwathDefinition(lons=lons_2, lats=lats_2)\n",
    "\n",
    "    # wind_speed_model_swath = pr.kd_tree.resample_gauss(\n",
    "    #     ncep_def, ncepGFSmodelWind['wind_speed'].ravel(), swath_def,\n",
    "    #     radius_of_influence=2*pxlResWind.max()*1e3, neighbours=12,\n",
    "    #     sigmas=pxlResWind.max()*1e3, fill_value=None, nprocs=numProcs\n",
    "    # )\n",
    "    wind_dir_model_swath = pr.kd_tree.resample_gauss(\n",
    "        ncep_def, ncepGFSmodelWind['wind_dir'].ravel(), swath_def,\n",
    "        radius_of_influence=2*pxlResWind.max()*1e3, neighbours=12,\n",
    "        sigmas=pxlResWind.max()*1e3, fill_value=None, nprocs=numProcs\n",
    "    )\n",
    "\n",
    "    # calculate bearing from initial lats/lons for further wind calculation\n",
    "    bearing = zeros((lons.shape[0]-1, lons.shape[1]))\n",
    "\n",
    "    for n in range(0, lons.shape[1]):\n",
    "        col = ([lats[:-1, n], lons[:-1, n]], [lats[1:, n], lons[1:, n]])\n",
    "        for m in range(0, lons.shape[0]-1):\n",
    "            bearing[m][n] = distancelib.bearing(asarray(col[0])[:, m],\n",
    "                                                asarray(col[1])[:, m])\n",
    "\n",
    "    # interpolate to raw_counts.shape\n",
    "    bearing_2 = imresize(bearing, raw_counts.shape)\n",
    "\n",
    "    # NB! WINDDIR = 0 WHEN WIND BLOWS TOWARDS RADAR!\n",
    "    wind_dir_model_swath_rel = 90 + bearing_2 - wind_dir_model_swath\n",
    "\n",
    "    if pol == 'H/H':\n",
    "        PR = PR_Mouche(incident_angle, wind_dir_model_swath_rel)\n",
    "        try:\n",
    "            from cmod_gpu import rcs2windOpenCl\n",
    "            wind_speed_asar = rcs2windOpenCl(sar=sigma0w*PR,\n",
    "                                             windir=wind_dir_model_swath_rel,\n",
    "                                             theta=incident_angle)\n",
    "        except Exception:\n",
    "            from cmod_vect import rcs2windPar\n",
    "            wind_speed_asar = rcs2windPar(sigma0w*PR, cmdv=5,\n",
    "                                          windir=wind_dir_model_swath_rel,\n",
    "                                          theta=incident_angle,\n",
    "                                          nprocs=numProcs)\n",
    "    elif pol == 'V/V':\n",
    "        try:\n",
    "            from cmod_gpu import rcs2windOpenCl\n",
    "            wind_speed_asar = rcs2windOpenCl(sar=sigma0w,\n",
    "                                             windir=wind_dir_model_swath_rel,\n",
    "                                             theta=incident_angle)\n",
    "        except Exception:\n",
    "            from cmod_vect import rcs2windPar\n",
    "            wind_speed_asar = rcs2windPar(sigma0w, cmdv=5,\n",
    "                                          windir=wind_dir_model_swath_rel,\n",
    "                                          theta=incident_angle,\n",
    "                                          nprocs=numProcs)\n",
    "\n",
    "    del lats, lons\n",
    "    del sigma0, raw_counts\n",
    "    del bearing\n",
    "    del ncepGFSmodelWind\n",
    "    gc.collect()\n",
    "\n",
    "    for proj in ['EPSG:4326', 'EPSG:3413']:\n",
    "        # for proj in ['EPSG:4326']:\n",
    "        print \"    start projection %s\" % proj\n",
    "        if proj == 'EPSG:4326':\n",
    "            oPath = oPath_4326\n",
    "            for outpath in oPath:\n",
    "                mkdirs(outpath)\n",
    "            area_def = swath_area_def(\n",
    "                name='Temporal SWATH EPSG Projection 4326', proj='eqc',\n",
    "                lonlim=(lons_2.min(), lons_2.max()),\n",
    "                latlim=(lats_2.min(), lats_2.max()),\n",
    "                ellps=\"WGS84\", res=pxlResSAR.max()\n",
    "            )\n",
    "            # Set the parameters for GSHHS masking\n",
    "            proj_ = '4326'\n",
    "            proj_name = None\n",
    "            units = 'deg'\n",
    "        elif proj == 'EPSG:3413':\n",
    "            oPath = oPath_3413\n",
    "            for outpath in oPath:\n",
    "                mkdirs(outpath)\n",
    "            area_def = swath_area_def(\n",
    "                name='Temporal SWATH EPSG Projection 3413', proj='stere',\n",
    "                lonlim=(lons_2.min(), lons_2.max()),\n",
    "                latlim=(lats_2.min(), lats_2.max()),\n",
    "                ellps=\"WGS84\", res=pxlResSAR.max(),\n",
    "                lat_ts=70, lat_0=90, lon_0=-45\n",
    "            )\n",
    "            # Set the parameters for GSHHS masking\n",
    "            proj_ = '+units=m +ellps=WGS84 +lon_0=-45 +proj=stere +lat_ts=70 +lat_0=90'\n",
    "            proj_name = '3413'\n",
    "            units = 'm'\n",
    "\n",
    "        print area_def\n",
    "        print \"roughness.shape = \", roughness.shape\n",
    "\n",
    "        roughness_res = pr.kd_tree.resample_nearest(\n",
    "            swath_def, roughness.ravel(), area_def,\n",
    "            radius_of_influence=pxlResSAR.max(),\n",
    "            epsilon=0.5, nprocs=numProcs, fill_value=None\n",
    "        )\n",
    "        print \"resample_nearest done\"\n",
    "\n",
    "#        shapefile = '/media/SOLabNFS/store/auxdata/coastline/GSHHS_shp/f/GSHHS_f_L1.shp'\n",
    "#        lonlim=(lons_2.min(),lons_2.max())\n",
    "#        latlim=(lats_2.min(),lats_2.max())\n",
    "#        lakes = True\n",
    "#\n",
    "#        mask_arr = gshhs_rasterize.gshhs_rasterize(lonlim, latlim, units, roughness_res.shape,\n",
    "#                                                   proj_, proj_name, lakes, shapefile)\n",
    "#        roughness_masked = ma.masked_where(mask_arr, roughness_res)\n",
    "        roughness_masked = roughness_res\n",
    "\n",
    "        oFileName = os.path.join(oPath[0], fileName+'.png')\n",
    "        gray()\n",
    "        print 'save roughness_masked image, %s' % oFileName\n",
    "        del roughness_res\n",
    "        gc.collect()\n",
    "        print '=>>', roughness_masked.shape\n",
    "        #imsave(oFileName, roughness_masked, vmin=0, vmax=2)\n",
    "        save_big_image(oFileName, roughness_masked, vmin=0, vmax=2,\n",
    "                       temp_dir='/tmp/save_image/'+fileName)\n",
    "        del roughness_masked\n",
    "        gc.collect()\n",
    "   #     del roughness_masked, roughness_res, roughness\n",
    "\n",
    "        print \"roughness_res done\"\n",
    "        print \"wind_speed_asar.shape = \", wind_speed_asar.shape\n",
    "        wind_speed_asar_res = pr.kd_tree.resample_nearest(\n",
    "            swath_def, wind_speed_asar.ravel(), area_def,\n",
    "            radius_of_influence=pxlResSAR.max(),\n",
    "            epsilon=0.5, nprocs=numProcs, fill_value=None\n",
    "        )\n",
    "        print \"wind_speed_asar_res done\"\n",
    "\n",
    "        # Apply Mask from GSHHS\n",
    "        # ESRI shapefile containing land polygons\n",
    "#        shapefile = '/media/SOLabNFS/store/auxdata/coastline/GSHHS_shp/f/GSHHS_f_L1.shp'\n",
    "#        lonlim=(lons_2.min(),lons_2.max())\n",
    "#        latlim=(lats_2.min(),lats_2.max())\n",
    "#        lakes = True\n",
    "\n",
    "#        mask_arr = gshhs_rasterize.gshhs_rasterize(lonlim, latlim, units, roughness_res.shape,\n",
    "#                                                   proj_, proj_name, lakes, shapefile)\n",
    "#        roughness_masked = ma.masked_where(mask_arr, roughness_res)\n",
    "#        wind_speed_asar_masked = ma.masked_where(mask_arr, wind_speed_asar_res)\n",
    "        wind_speed_asar_masked = wind_speed_asar_res\n",
    "\n",
    "#        oFileName = os.path.join(oPath[0], fileName+'.png')\n",
    "#        gray()\n",
    "#        imsave(oFileName, roughness_masked, vmin=0, vmax=2)\n",
    "\n",
    "        oFileNameWind = os.path.join(oPath[1], fileName+'.png')\n",
    "        jet()\n",
    "        print 'save wind_speed_asar_masked, image, %s' % oFileNameWind\n",
    "#        del wind_speed_asar_res\n",
    "        gc.collect()\n",
    "        # imsave(oFileNameWind, wind_speed_asar_masked, vmin=0, vmax=20)\n",
    "        save_big_image(oFileNameWind, wind_speed_asar_masked, vmin=0, vmax=20,\n",
    "                       temp_dir='/tmp/save_image/'+fileName)\n",
    "#        del wind_speed_asar_masked\n",
    "        gc.collect()\n",
    "    #    del wind_speed_asar_masked, wind_speed_asar_res, wind_speed_asar\n",
    "\n",
    "        for _path in oPath:\n",
    "            create_KML_asar(area_def.area_extent,\n",
    "                            os.path.join(_path, fileName+'.kml'))\n",
    "    del roughness  # , roughness_res\n",
    "    del wind_speed_asar_masked, wind_speed_asar  # , wind_speed_asar_res\n",
    "    product.close()\n",
    "    gc.collect()\n",
    "    return True\n",
    "    # gray()\n",
    "    # pr.plot.show_quicklook(area_def, result, vmin=0, vmax=2,\n",
    "    #  label='Test', num_meridians=45, num_parallels=10, coast_res='l')\n",
    "\n",
    "import gdal\n",
    "sys.path.append('/usr/bin')\n",
    "from gdal2tiles import GDAL2Tiles\n",
    "\n",
    "\n",
    "def create_asar_tiles(png_filename, tiles_output_dir, proj):\n",
    "    local_argv = ['/usr/bin/gdal2tiles.py', '-p', 'raster', '-r', 'cubic',\n",
    "                  '-s', proj, png_filename, tiles_output_dir]\n",
    "    argv = gdal.GeneralCmdLineProcessor(local_argv)\n",
    "    if argv:\n",
    "        gdal2tiles = GDAL2Tiles(argv[1:])\n",
    "        gdal2tiles.process()\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def resize_image(filepath, basewidth, savepath):\n",
    "    if not os.path.isfile(filepath):\n",
    "        return\n",
    "#    if os.path.isfile(savepath):\n",
    "#        return\n",
    "    img = Image.open(filepath)\n",
    "    wpercent = (basewidth / float(img.size[0]))\n",
    "    hsize = int(float(img.size[1]) * float(wpercent))\n",
    "    img = img.resize((basewidth, hsize), Image.ANTIALIAS)\n",
    "    img.save(savepath)\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "def send_redis_message(granule_name, tiles_output_dir, kml_file, output_filename, r):\n",
    "    kml_text = open(kml_file, 'r').read()\n",
    "    prog = re.compile(r'<coordinates>(\\S* \\S*)</coordinates>')\n",
    "    coords = prog.findall(kml_text)[0]\n",
    "    BBox_attrib = []\n",
    "    for cs in coords.split():\n",
    "        BBox_attrib.append(cs.split(',')[0])\n",
    "        BBox_attrib.append(cs.split(',')[1])\n",
    "\n",
    "    xml_info_file = os.path.join(tiles_output_dir, 'tilemapresource.xml')\n",
    "\n",
    "    tree = ET.parse(xml_info_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    units_list = []\n",
    "    for child in root:\n",
    "        if child.tag == 'TileSets':\n",
    "            for TSchild in child:\n",
    "                # print child.attrib\n",
    "                units_list.append(TSchild.attrib['units-per-pixel'])\n",
    "    resolution_list = [int(75 * math.pow(2, i))\n",
    "                       for i in range(len(units_list))]\n",
    "    resolution_list.reverse()\n",
    "    print '=======>', BBox_attrib\n",
    "    print resolution_list\n",
    "\n",
    "    message_text = {\n",
    "      'PRODUCT_NAME': 'ASAR',\n",
    "      'GRANULE_NAME': granule_name,\n",
    "      'PNG_PATH': output_filename,\n",
    "      'OUTPUT_DIRECTORY': tiles_output_dir,\n",
    "      'METADATA': {\n",
    "          'bbox': BBox_attrib,\n",
    "          'resolution': resolution_list\n",
    "          }\n",
    "    }\n",
    "    r.publish('NewGranule', output_filename)\n",
    "\n",
    "    r.publish('Metadata', message_text)\n",
    "\n",
    "fileName = 'ASA_WSM_1PNPDK20100927_195408_000000862093_00200_44843_3688.N1'\n",
    "# input_filename = '/nfs1/store/satellite/asar/2010/270/ASA_WSM_1PNPDK20100927_195408_000000862093_00200_44843_3688.N1'\n",
    "#~ asar_path = '/nfs1/store/satellite/asar'\n",
    "asar_path = '/media/SOLabNFS2/store/satellite/asar'\n",
    "pp_names = ['roughness', 'wind_speed']\n",
    "#out_path = '/media/SOLabNFS2/http/tiles/ASAR'\n",
    "out_path_w = '/media/SOLabNFS2/http/tiles/SOLAB_ASAR_WSPD'\n",
    "out_path_r = '/media/SOLabNFS2/http/tiles/SOLAB_ASAR_ROUGH'\n",
    "\n",
    "\n",
    "def mkdirs(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "roughness_flag = True\n",
    "\n",
    "\n",
    "#Start 538 granule 2012\n",
    "\n",
    "#Start 594 granule 2011\n",
    "\n",
    "\n",
    "count = 0\n",
    "offset = 593\n",
    "for _dir, sub_dir, _files in os.walk(asar_path):\n",
    "    if not '2011' in _dir:\n",
    "        continue\n",
    "    for fileName in _files:\n",
    "        if fileName.startswith('ASA_') and fileName.endswith('.N1'):\n",
    "            count += 1\n",
    "            if count <= offset:\n",
    "                continue\n",
    "            print \"Start %d granule\" % count\n",
    "#            if fileName in ['ASA_IMM_1PNPDK20080202_152546_000001902065_00369_30984_0214.N1']:\n",
    "#                continue\n",
    "            #_dir = '/media/SOLabNFS2/store/satellite/asar/2008/001'\n",
    "            #fileName = 'ASA_IMM_1PNPDK20080101_084943_000000812064_00408_30522_3741.N1'\n",
    "            # _dir = '/nfs1/store/satellite/asar/2010/270'\n",
    "            # fileName = 'ASA_WSM_1PNPDK20100927_195408_000000862093_00200_44843_3688.N1'\n",
    "            input_filename = os.path.join(_dir, fileName)\n",
    "            dt = datetime.datetime.strptime(\n",
    "                fileName[14:22], '%Y%m%d'\n",
    "            ).timetuple()\n",
    "            year = str(dt.tm_year)\n",
    "            day = str(dt.tm_yday)\n",
    "\n",
    "            if len(day) == 1:\n",
    "                day = '00' + day\n",
    "            elif len(day) == 2:\n",
    "                day = '0' + day\n",
    "            print year, day\n",
    "\n",
    "            # _dir = '/nfs1/store/satellite/asar/%s/%s' % (year, day)\n",
    "            oPath_4326_r = os.path.join(out_path_r, pp_names[0], 'epsg_4326',\n",
    "                                        year, day, fileName)\n",
    "            oPath_3413_r = os.path.join(out_path_r, pp_names[0], 'epsg_3413',\n",
    "                                        year, day, fileName)\n",
    "            oPath_4326_w = os.path.join(out_path_w, pp_names[1], 'epsg_4326',\n",
    "                                        year, day, fileName)\n",
    "            oPath_3413_w = os.path.join(out_path_w, pp_names[1], 'epsg_3413',\n",
    "                                        year, day, fileName)\n",
    "\n",
    "            print \"Start granule: %s\" % fileName\n",
    "\n",
    "            # create dirs\n",
    "#            mkdirs(oPath_4326_r)\n",
    "#            mkdirs(oPath_3413_r)\n",
    "#            mkdirs(oPath_4326_w)\n",
    "#            mkdirs(oPath_3413_w)\n",
    "\n",
    "            # check png file\n",
    "            png_4326_r_filename = os.path.join(oPath_4326_r, fileName+'.png')\n",
    "            png_3413_r_filename = os.path.join(oPath_3413_r, fileName+'.png')\n",
    "            png_4326_w_filename = os.path.join(oPath_4326_w, fileName+'.png')\n",
    "            png_3413_w_filename = os.path.join(oPath_3413_w, fileName+'.png')\n",
    "\n",
    "#            if roughness_flag:\n",
    "#                oPaths = [(oPath_4326_r, None),\n",
    "#                          (oPath_3413_r, None)]\n",
    "#            else:\n",
    "#                oPaths = [(None, oPath_4326_w),\n",
    "#                          (None, oPath_3413_w)]\n",
    "            oPaths = [(oPath_4326_r, oPath_4326_w),\n",
    "                      (oPath_3413_r, oPath_3413_w)]\n",
    "            pngPaths = [(png_4326_r_filename, png_4326_w_filename),\n",
    "                        (png_3413_r_filename, png_3413_w_filename)]\n",
    "\n",
    "#            if roughness_flag:\n",
    "#                if not os.path.isfile(png_4326_r_filename) or not os.path.isfile(png_3413_r_filename):\n",
    "#                    if not create_asar_image(_dir, oPaths, fileName):\n",
    "#                        continue\n",
    "#            else:\n",
    "#               if not os.path.isfile(png_4326_w_filename) or not os.path.isfile(png_3413_w_filename):\n",
    "#                   if not create_asar_image(_dir, oPaths, fileName, roughness_flag):\n",
    "#                       continue\n",
    "\n",
    "            if not os.path.isfile(png_4326_r_filename) or \\\n",
    "               not os.path.isfile(png_3413_r_filename) or \\\n",
    "               not os.path.isfile(png_4326_w_filename) or \\\n",
    "               not os.path.isfile(png_3413_w_filename):\n",
    "                print \"Start create image for %s\" % fileName\n",
    "                if not create_asar_image(_dir, oPaths, fileName):\n",
    "                    continue\n",
    "\n",
    "#            resize_image(png_3413_r_filename, 1024, os.path.join(oPath_3413_r, fileName+'_1024.png'))\n",
    "#            resize_image(png_3413_r_filename, 263, os.path.join(oPath_3413_r, fileName+'_263.png'))\n",
    "            # create thumbs\n",
    "            for num in range(len(oPaths)):\n",
    "                resize_image(pngPaths[num][0], 1024,\n",
    "                             os.path.join(oPaths[num][0],\n",
    "                             fileName+'_1024.png'))\n",
    "                resize_image(pngPaths[num][0], 263,\n",
    "                             os.path.join(oPaths[num][0],\n",
    "                             fileName+'_263.png'))\n",
    "                resize_image(pngPaths[num][1], 1024,\n",
    "                             os.path.join(oPaths[num][1],\n",
    "                             fileName+'_1024.png'))\n",
    "                resize_image(pngPaths[num][1], 263,\n",
    "                             os.path.join(oPaths[num][1],\n",
    "                             fileName+'_263.png'))\n",
    "\n",
    "            # check tiles\n",
    "            tiles_4326_r_output_dir = os.path.join(oPath_4326_r, 'tiles')\n",
    "            tiles_3413_r_output_dir = os.path.join(oPath_3413_r, 'tiles')\n",
    "            if not os.path.isdir(tiles_4326_r_output_dir):\n",
    "                print \"start create tiles for %s\" % tiles_4326_r_output_dir\n",
    "                create_asar_tiles(png_4326_r_filename,\n",
    "                                  tiles_4326_r_output_dir, 'EPSG:4326')\n",
    "                kml_file_4326 = os.path.join(oPath_4326_r, fileName+'.kml')\n",
    "                send_redis_message(input_filename, tiles_4326_r_output_dir, kml_file_4326,\n",
    "                                   png_4326_r_filename, r)\n",
    "            if not os.path.isdir(tiles_3413_r_output_dir):\n",
    "                print \"start create tiles for %s\" % tiles_3413_r_output_dir\n",
    "                create_asar_tiles(png_3413_r_filename,\n",
    "                                  tiles_3413_r_output_dir, 'EPSG:3413')\n",
    "                kml_file_3413 = os.path.join(oPath_3413_r, fileName+'.kml')\n",
    "                send_redis_message(input_filename, tiles_3413_r_output_dir, kml_file_3413,\n",
    "                                   png_3413_r_filename, r)\n",
    "\n",
    "            tiles_4326_w_output_dir = os.path.join(oPath_4326_w, 'tiles')\n",
    "            tiles_3413_w_output_dir = os.path.join(oPath_3413_w, 'tiles')\n",
    "\n",
    "            if not os.path.isdir(tiles_4326_w_output_dir):\n",
    "                print \"start create tiles for %s\" % tiles_4326_w_output_dir\n",
    "                create_asar_tiles(png_4326_w_filename,\n",
    "                                  tiles_4326_w_output_dir, 'EPSG:4326')\n",
    "                kml_file_4326 = os.path.join(oPath_4326_w, fileName+'.kml')\n",
    "                send_redis_message(input_filename, tiles_4326_w_output_dir,\n",
    "                                   kml_file_4326, png_4326_w_filename, r)\n",
    "            if not os.path.isdir(tiles_3413_w_output_dir):\n",
    "                print \"start create tiles for %s\" % tiles_3413_w_output_dir\n",
    "                create_asar_tiles(png_3413_w_filename,\n",
    "                                  tiles_3413_w_output_dir, 'EPSG:3413')\n",
    "                kml_file_3413 = os.path.join(oPath_3413_w, fileName+'.kml')\n",
    "                send_redis_message(input_filename, tiles_3413_w_output_dir,\n",
    "                                   kml_file_3413, png_3413_w_filename, r)\n",
    "\n",
    "            gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
