{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import os, sys\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "import re\n",
    "import epr\n",
    "\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "from numpy import linspace, arange, row_stack, delete\n",
    "from math import atan\n",
    "\n",
    "from createMapsEtopo1 import findSubsetIndices\n",
    "import pygrib\n",
    "\n",
    "import pyresample as pr\n",
    "from pyproj import Proj\n",
    "import distancelib\n",
    "import gshhs_rasterize\n",
    "\n",
    "from pylab import *\n",
    "\n",
    "import simplekml\n",
    "\n",
    "\n",
    "import ConfigParser\n",
    "import redis\n",
    "\n",
    "# sys.path.append(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath('__file__'))), 'cmod'))\n",
    "# sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath('__file__'))))\n",
    "\n",
    "__author__ = 'Alexander Myasoedov and Denis Spiridonov'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set the number of CPUs\n",
    "numProcs = cpu_count()-2\n",
    "\n",
    "# redis_conf = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath('__file__'))), 'redis.conf')\n",
    "redis_conf = os.path.join('/home/mag/Documents/repos/solab/posada/', 'redis.conf')\n",
    "\n",
    "config = ConfigParser.RawConfigParser()\n",
    "config.read(redis_conf)\n",
    "redis_host = config.get('AUTH', 'HOSTNAME')\n",
    "redis_passwd = config.get('AUTH', 'PASSWORD')\n",
    "\n",
    "r = redis.Redis(host=redis_host, password=redis_passwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Func Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def windDirection(u, v):\n",
    "    U = u.ravel()\n",
    "    V = v.ravel()\n",
    "    direction = zeros(size(U))\n",
    "    for i in range(0, len(U)):\n",
    "        if U[i] >= 0 and V[i] > 0: direction[i] = ((180 / pi) * atan(abs(U[i] / V[i])) + 180)\n",
    "        if U[i] < 0 and V[i] > 0: direction[i] = (-(180 / pi) * atan(abs(U[i] / V[i])) + 180)\n",
    "        if U[i] >= 0 and V[i] < 0: direction[i] = (-(180 / pi) * atan(abs(U[i] / V[i])) + 360)\n",
    "        if U[i] < 0 and V[i] < 0: direction[i] = ((180 / pi) * atan(abs(U[i] / V[i])))\n",
    "        if V[i] == 0 and U[i] > 0: direction[i] = 270\n",
    "        if V[i] == 0 and U[i] < 0: direction[i] = 90\n",
    "        if V[i] == 0 and U[i] == 0: direction[i] = 0\n",
    "    return reshape(direction, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PR_Mouche(theta, phi):\n",
    "    A_0 = 0.00650704\n",
    "    B_0 = 0.128983\n",
    "    C_0 = 0.992839\n",
    "    A_HALF_PI = 0.00782194\n",
    "    B_HALF_PI = 0.121405\n",
    "    C_HALF_PI = 0.992839\n",
    "    A_PI = 0.00598416\n",
    "    B_PI = 0.140952\n",
    "    C_PI = 0.992885\n",
    "\n",
    "    P_0 = A_0 * exp(B_0 * theta) + C_0\n",
    "    P_HALF_PI = A_HALF_PI * exp(B_HALF_PI * theta) + C_HALF_PI\n",
    "    P_PI = A_PI * exp(B_PI * theta) + C_PI\n",
    "\n",
    "    C0 = (P_0 + P_PI + 2 * P_HALF_PI) / 4\n",
    "    C1 = (P_0 - P_PI) / 2\n",
    "    C2 = (P_0 + P_PI - 2 * P_HALF_PI) / 4\n",
    "\n",
    "    P = C0 + C1 * cos(radians(phi)) + C2 * cos(radians(2 * phi))\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ncepGFSmodel(startTime, lats_2, lons_2):\n",
    "    \"\"\"\n",
    "    NCEP GFS model wind for givven time, lat/lon crop\n",
    "    \"\"\"\n",
    "    ncepGFSmodel = {} # empty dict for ncepGFSmodel\n",
    "\n",
    "#     iPath_wind = '/nfs1/store/model/ncep/gfs/'\n",
    "    iPath_wind = '/media/SOLabNFS2/store/model/ncep/gfs/'\n",
    "\n",
    "    # find the ncep gfs filename to open from ASAR filename\n",
    "    baseHour = floor((startTime.hour+3/2)/6)*6\n",
    "    baseHour = min(18, baseHour)\n",
    "    if startTime.hour-baseHour>1.5:\n",
    "        forecastHour = 3\n",
    "    else:\n",
    "        forecastHour = 0\n",
    "\n",
    "    if startTime <= datetime.datetime(2014, 8, 19):\n",
    "        ncepFileName = 'gfs' + startTime.strftime(\"%Y%m%d\") + '/gfs.t' + '%.2d' %(baseHour) + 'z.master.grbf' + '%.2d' %(forecastHour)\n",
    "\n",
    "        grbs = pygrib.open(iPath_wind + ncepFileName)\n",
    "\n",
    "        u_wind = None\n",
    "        v_wind = None\n",
    "\n",
    "        # wind contains u=u_wind.values[:], Lats=u_wind.latlons()[0], Lons=u_wind.latlons()[1]\n",
    "        for idx, msg_info in enumerate(grbs.select()):\n",
    "            if msg_info['short_name'] == '10u':\n",
    "                u_wind = grbs.message(idx + 1)\n",
    "            elif msg_info['short_name'] == '10v':\n",
    "                v_wind = grbs.message(idx + 1)\n",
    "\n",
    "        u = u_wind.values[:]\n",
    "        v = v_wind.values[:]\n",
    "        lats_wind = u_wind.latlons()[0]\n",
    "        lons_wind = u_wind.latlons()[1]\n",
    "    else:\n",
    "        try:\n",
    "            ncepFileName = 'gfs.' + startTime.strftime(\"%Y%m%d\") + '%.2d' %(baseHour) + '/gfs.t' + '%.2d' %(baseHour) + 'z.master.grbf' + '%.2d' %(forecastHour) + '.10m.uv.grib2'\n",
    "\n",
    "            grbs = pygrib.open(iPath_wind + ncepFileName)\n",
    "\n",
    "            u_wind = grbs.message(1)\n",
    "            v_wind = grbs.message(2)\n",
    "            u = u_wind['values']\n",
    "            v = v_wind['values']\n",
    "            lats_wind = u_wind['latitudes']\n",
    "            lons_wind = u_wind['longitudes']\n",
    "            lons_wind = reshape(lons_wind, (lons_wind.shape[0]/720, 720))\n",
    "            lats_wind = reshape(lats_wind, (lats_wind.shape[0]/720, 720))\n",
    "        except Exception:\n",
    "            ncepFileName = 'gfs.' + startTime.strftime(\"%Y%m%d\") + '%.2d' %(baseHour) + '/gfs.t' + '%.2d' %(baseHour) + 'z.pgrb2.0p25.f' + '%.3d' %(forecastHour)\n",
    "\n",
    "            grbs = pygrib.open(iPath_wind + ncepFileName)\n",
    "\n",
    "            u_wind = grbs.message(1)\n",
    "            v_wind = grbs.message(2)\n",
    "            u = u_wind['values']\n",
    "            v = v_wind['values']\n",
    "            lats_wind = u_wind['latitudes']\n",
    "            lons_wind = u_wind['longitudes']\n",
    "            lons_wind = reshape(lons_wind, (lons_wind.shape[0]/1440, 1440))\n",
    "            lats_wind = reshape(lats_wind, (lats_wind.shape[0]/1440, 1440))\n",
    "\n",
    "    #Make sure the longitude is between -180.00 .. 179.9\n",
    "    lons_wind = map(lambda x : (lons_wind.ravel()[x]+180)-int((lons_wind.ravel()[x]+180)/360)*360-180, range(0,lons_wind.size))\n",
    "    lons_wind = reshape(lons_wind, lats_wind.shape)\n",
    "    # plt.close('all')\n",
    "    # plt.imshow(lons_wind)\n",
    "    # plt.colorbar()\n",
    "\n",
    "#     #Make sure the latitudes is between -90.00 .. 89.9, starting from North - positive\n",
    "#     lats_wind = map(lambda x : (lats_wind.ravel()[x]+90)-int((lats_wind.ravel()[x]+90)/180)*180-90, xrange(0,lats_wind.size))\n",
    "#     lats_wind = reshape(lats_wind, lons_wind.shape)\n",
    "#     if lats_wind[0,0] < lats_wind[-1,-1]:\n",
    "#         lats_wind = flipud(lats_wind)\n",
    "#         u = flipud(u)\n",
    "#         v = flipud(v)\n",
    "#     plt.close('all')\n",
    "#     plt.imshow(lats_wind)\n",
    "#     plt.colorbar()\n",
    "\n",
    "\n",
    "    # find subset\n",
    "    res = findSubsetIndices(lats_2.min(),lats_2.max(),lons_2.min(),lons_2.max(),lats_wind[:,0],lons_wind[0,:])\n",
    "    # expand subset by 1 pixel for better further pyresample\n",
    "    res[0]=res[0]-2\n",
    "    res[1]=res[1]+2\n",
    "    res[2]=res[2]-2\n",
    "    res[3]=res[3]+2\n",
    "\n",
    "    # crop the data\n",
    "    u = u[int(res[2]):int(res[3]),int(res[0]):int(res[1])]\n",
    "    v = v[int(res[2]):int(res[3]),int(res[0]):int(res[1])]\n",
    "    ncepGFSmodel['lats_wind'] = lats_wind[int(res[2]):int(res[3]),int(res[0]):int(res[1])]\n",
    "    ncepGFSmodel['lons_wind'] = lons_wind[int(res[2]):int(res[3]),int(res[0]):int(res[1])]\n",
    "\n",
    "    ncepGFSmodel['wind_dir'] = windDirection(u,v)\n",
    "    ncepGFSmodel['wind_speed'] = sqrt(u**2 + v**2)\n",
    "    ncepGFSmodel['u'] = u\n",
    "    ncepGFSmodel['v'] = v\n",
    "    ncepGFSmodel['baseHour'] = baseHour\n",
    "    ncepGFSmodel['forecastHour'] = forecastHour\n",
    "#     del u_wind, v_wind\n",
    "    return ncepGFSmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_KML(area_extent, savepath):\n",
    "    kml = simplekml.Kml()\n",
    "\n",
    "    pol = kml.newpolygon(name='area_extent', visibility=1)\n",
    "    pol.tessellate = 1\n",
    "\n",
    "    pol.altitudemode = 'clampToGround'\n",
    "    # minx, miny, maxx, maxy\n",
    "    pol.outerboundaryis.coords = [(min(area_extent[0], area_extent[2]),\n",
    "                                   min(area_extent[1], area_extent[3])),\n",
    "                                  (max(area_extent[0], area_extent[2]),\n",
    "                                   max(area_extent[1], area_extent[3]))]\n",
    "    if type(savepath) == list:\n",
    "        for _savepath in savepath:\n",
    "            kml.save(_savepath)\n",
    "    else:\n",
    "        kml.save(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def swath_area_def(name='Temporal SWATH EPSG Projection 4326', proj='eqc', lonlim=(-180,180), latlim=(-90,90), ellps=\"WGS84\", res=111.2e3, lat_ts=None, lat_0=None, lon_0=None):\n",
    "    \"\"\"\n",
    "    Convert given swath coordinates to pyresample area definition.\n",
    "    The arguments are standard for Proj:\n",
    "    name\n",
    "    proj\n",
    "    lonlim\n",
    "    latlim\n",
    "    ellipsoid\n",
    "    resolution(meters)\n",
    "    lat_ts (latitude of true scale)\n",
    "    lat_0,lon_0 is central point\n",
    "    EXAMPLE:\n",
    "\n",
    "    epsg3426 is the default one\n",
    "    for epsg3413:\n",
    "    swath_area_def(name='Temporal SWATH EPSG Projection 3413', proj='stere', lonlim=(-180,180), latlim=(30,90), ellps=\"WGS84\", res=111.2e3, lat_ts=70, lat_0=90, lon_0=-45)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    up    = max(latlim)\n",
    "    down  = min(latlim)\n",
    "    left  = min(lonlim)\n",
    "    right = max(lonlim)\n",
    "\n",
    "    print 'up, down, left, right: ', round(up), round(down), round(left), round(right)\n",
    "\n",
    "    area_id = name.replace(\" \", \"_\").lower()\n",
    "    proj_id = area_id\n",
    "\n",
    "    if proj == 'eqc':\n",
    "        p = Proj(proj=proj, llcrnrlat=up, urcrnrlat=down, llcrnrlon=left, urcrnrlon=right, ellps=ellps)\n",
    "        proj4_args = '+proj=' + str(proj) + ' ' + \\\n",
    "             '+llcrnrlat=' + str(up) + ' ' + \\\n",
    "             '+urcrnrlat=' + str(down) + ' ' + \\\n",
    "             '+llcrnrlon=' + str(left) + ' ' + \\\n",
    "             '+urcrnrlon=' + str(right) + ' ' + \\\n",
    "             '+ellps=' + str(ellps)\n",
    "    elif lat_ts!=None and lat_0!=None:\n",
    "        # lat_ts is latitude of true scale.\n",
    "        # lon_0,lat_0 is central point.\n",
    "        p = Proj(proj=proj, lat_0=lat_0, lon_0=lon_0, lat_ts=lat_ts, ellps=ellps)\n",
    "        proj4_args = '+proj=' + str(proj) + ' ' + \\\n",
    "             '+lat_0=' + str(lat_0) + ' ' + \\\n",
    "             '+lon_0=' + str(lon_0) + ' ' + \\\n",
    "             '+lat_ts=' + str(lat_ts) + ' ' + \\\n",
    "             '+ellps=' + str(ellps)\n",
    "    elif lon_0!=None and lat_0!=None and lat_ts==None:\n",
    "        # lon_0,lat_0 is central point.\n",
    "        p = Proj(proj=proj, lat_0=lat_0, lon_0=lon_0, ellps=ellps)\n",
    "        proj4_args = '+proj=' + str(proj) + ' ' + \\\n",
    "             '+lat_0=' + str(lat_0) + ' ' + \\\n",
    "             '+lon_0=' + str(lon_0) + ' ' + \\\n",
    "             '+ellps=' + str(ellps)\n",
    "    elif lon_0==None and lat_0==None and lat_ts==None:\n",
    "        # lon_0,lat_0 is central point.\n",
    "        lat_0 = (up + down) / 2\n",
    "        lon_0 = (right + left) / 2\n",
    "        p = Proj(proj=proj, lat_0=lat_0, lon_0=lon_0, ellps=ellps)\n",
    "        proj4_args = '+proj=' + str(proj) + ' ' + \\\n",
    "             '+lat_0=' + str(lat_0) + ' ' + \\\n",
    "             '+lon_0=' + str(lon_0) + ' ' + \\\n",
    "             '+ellps=' + str(ellps)\n",
    "\n",
    "    left_ex1, up_ex1 = p(left, up)\n",
    "    right_ex1, up_ex2 = p(right, up)\n",
    "    left_ex2, down_ex1 = p(left, down)\n",
    "    right_ex2, down_ex2 = p(right, down)\n",
    "\n",
    "    if proj == 'stere':\n",
    "        lon = (left+right)/2.0\n",
    "        if (lon >=0 and lon <90) or (lon >=-360 and lon < -270):\n",
    "            print 11111111111\n",
    "            area_extent = (\n",
    "                           min(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                           min(down_ex1, down_ex2, up_ex1, up_ex2),\n",
    "                           max(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                           max(down_ex1, down_ex2, up_ex1, up_ex2)\n",
    "                        )\n",
    "        elif (lon >=90 and lon <180) or (lon >=-270 and lon < -180):\n",
    "            print 2222222222222\n",
    "            area_extent = (\n",
    "                           max(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                           max(down_ex1, down_ex2, up_ex1, up_ex2),\n",
    "                           min(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                           min(down_ex1, down_ex2, up_ex1, up_ex2)\n",
    "                        )\n",
    "        elif (lon >= 180 and lon < 270) or (lon >= -180 and lon < -90):\n",
    "            print 333333333333\n",
    "            area_extent = (\n",
    "                           min(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                           min(down_ex1, down_ex2, up_ex1, up_ex2),\n",
    "                           max(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                           max(down_ex1, down_ex2, up_ex1, up_ex2)\n",
    "                        )\n",
    "        else:\n",
    "            print 44444444444444444\n",
    "            area_extent = (\n",
    "                           min(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                           min(down_ex1, down_ex2, up_ex1, up_ex2),\n",
    "                           max(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                           max(down_ex1, down_ex2, up_ex1, up_ex2)\n",
    "                        )\n",
    "    else:\n",
    "        # минимум из всех координат X, Y, максимум из всех координат X, Y\n",
    "        # Такой результат даёт правильный area_extent для 3413\n",
    "        # При этом для 4326 area_extent остаётся неизменным\n",
    "        # area_def_3413 = swath_area_def(name='Temporal SWATH EPSG Projection 3413', proj='stere', \\\n",
    "        #                                lonlim=(-180,180), latlim=(30,90), ellps=\"WGS84\", res=1500, \\\n",
    "        #                                lat_ts=70, lat_0=90, lon_0=-45)\n",
    "        # Area extent: (-5050747.263141337, 0.0, 0.0, 5050747.263141336)\n",
    "        area_extent = (\n",
    "                        min(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                        min(up_ex1, up_ex2, down_ex1, down_ex2),\n",
    "                        max(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                        max(up_ex1, up_ex2, down_ex1, down_ex2)\n",
    "                    )\n",
    "\n",
    "    #~ print 'left: ', left_ex1, left_ex2\n",
    "    #~ print 'right: ', right_ex1, right_ex2\n",
    "    #~ print 'up: ', up_ex1, up_ex2\n",
    "    #~ print 'down: ', down_ex1, down_ex2\n",
    "\n",
    "#     Using abs() to avoid negative numbers of coloumns/rows as for epsg3413 for example\n",
    "    xsize = abs(int((area_extent[2] - area_extent[0]) / res[0]))\n",
    "    ysize = abs(int((area_extent[3] - area_extent[1]) / res[1]))\n",
    "\n",
    "    swath_area_def = pr.utils.get_area_def(area_id, name, proj_id, proj4_args, xsize, ysize, area_extent)\n",
    "\n",
    "#     print swath_area_def\n",
    "\n",
    "    return swath_area_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def imresize(image, size):\n",
    "    \"\"\"\n",
    "    Resizes coefficient arrays using bivariate spline approximation.\n",
    "    \"\"\"\n",
    "    m, n = image.shape\n",
    "    X = linspace(0, m - 1, size[0])\n",
    "    Y = linspace(0, n - 1, size[1])\n",
    "    kx, ky = min([m - 1, 3]), min([n - 1, 3])\n",
    "    interp = RectBivariateSpline(\n",
    "        arange(m), arange(n), image, kx=kx, ky=ky)\n",
    "    resized = interp(X, Y)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_sigma0(iPath, fileName):\n",
    "\n",
    "    print os.path.join(iPath, fileName)\n",
    "    try:\n",
    "        product = epr.Product(os.path.join(iPath, fileName))\n",
    "    except:\n",
    "        print 'unable to read file'\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        band = product.get_band('proc_data')\n",
    "    except epr.EPRValueError:\n",
    "        print 'unable to get band \"proc_data\": epr_get_band_id: band not found'\n",
    "        return False\n",
    "\n",
    "    sc_w = product.get_scene_width()\n",
    "    sc_h = product.get_scene_height()\n",
    "\n",
    "    print 'sc_w*sc_h = ', sc_w * sc_h\n",
    "    if sc_w*sc_h > 60000000:\n",
    "#     if sc_w*sc_h > 30000000:\n",
    "        print \"ASAR Image too large, skipping\"\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        raw_counts = band.read_as_array(sc_w, sc_h)  # , xstep=4, ystep=4)\n",
    "\n",
    "        incident_angle = product.get_band('incident_angle').read_as_array(sc_w,\n",
    "                                                                          sc_h)\n",
    "        # , xstep=4, ystep=4)\n",
    "    except epr.EPRValueError:\n",
    "        print \"EPRValueError\"\n",
    "        return False\n",
    "\n",
    "    # Get lat/lon from geolocation grid\n",
    "    dataset = product.get_dataset('GEOLOCATION_GRID_ADS')\n",
    "    fltp_lats = map(\n",
    "        lambda x:\n",
    "        dataset.read_record(x).get_field('first_line_tie_points.lats').get_elems(),\n",
    "        range(dataset.get_num_records())\n",
    "    )\n",
    "    lltp_lats = map(\n",
    "        lambda x:\n",
    "        dataset.read_record(x).get_field('last_line_tie_points.lats').get_elems(),\n",
    "        range(dataset.get_num_records())\n",
    "    )\n",
    "    fltp_lons = map(\n",
    "        lambda x:\n",
    "        dataset.read_record(x).get_field('first_line_tie_points.longs').get_elems(),\n",
    "        range(dataset.get_num_records())\n",
    "    )\n",
    "    lltp_lons = map(\n",
    "        lambda x:\n",
    "        dataset.read_record(x).get_field('last_line_tie_points.longs').get_elems(),\n",
    "        range(dataset.get_num_records())\n",
    "    )\n",
    "\n",
    "    fltp_lats = asarray(double(fltp_lats))/1e6\n",
    "    lltp_lats = asarray(double(lltp_lats))/1e6\n",
    "    fltp_lons = asarray(double(fltp_lons))/1e6\n",
    "    lltp_lons = asarray(double(lltp_lons))/1e6\n",
    "\n",
    "    lats = row_stack((fltp_lats, lltp_lats[-1, :]))\n",
    "    lons = row_stack((fltp_lons, lltp_lons[-1, :]))\n",
    "\n",
    "    lats = fliplr(lats)\n",
    "    lons = fliplr(lons)\n",
    "\n",
    "    lats_2 = imresize(lats, raw_counts.shape)\n",
    "    lons_2 = imresize(lons, raw_counts.shape)\n",
    "\n",
    "    if lats.max() <= 35:\n",
    "        print \"skipping no area overlap\"\n",
    "        return False\n",
    "\n",
    "    # Trimming the array by removing zero values from rows and cols\n",
    "    msk = []\n",
    "    for m in range(raw_counts.shape[0]):\n",
    "        if raw_counts[m, :].sum() == 0:\n",
    "            msk.append(m)\n",
    "    raw_counts = delete(raw_counts, msk, axis=0)\n",
    "    lats_2 = delete(lats_2, msk, axis=0)\n",
    "    lons_2 = delete(lons_2, msk, axis=0)\n",
    "    incident_angle = delete(incident_angle, msk, axis=0)\n",
    "    pol = product.get_sph().get_field('MDS1_TX_RX_POLAR').get_elem()\n",
    "\n",
    "    msk = []\n",
    "    for n in range(raw_counts.shape[1]):\n",
    "        if raw_counts[:, n].sum() == 0:\n",
    "            msk.append(n)\n",
    "    raw_counts = delete(raw_counts, msk, axis=1)\n",
    "    lats_2 = delete(lats_2, msk, axis=1)\n",
    "    lons_2 = delete(lons_2, msk, axis=1)\n",
    "    incident_angle = delete(incident_angle, msk, axis=1)\n",
    "\n",
    "    # Adding Sigma_0\n",
    "    calibration_constant = \\\n",
    "    product.get_dataset('MAIN_PROCESSING_PARAMS_ADS').read_record(0).get_field('calibration_factors.1.ext_cal_fact').get_elems()\n",
    "    # sigma0 = 10*log10( raw_counts**2*sin(incident_angle*pi/180)/calibration_constant )\n",
    "    sigma0 = raw_counts**2*sin(incident_angle*pi/180)/calibration_constant\n",
    "    return sigma0, lats_2, lons_2, incident_angle, pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_roughness(sigma0, incident_angle, pol):\n",
    "    \"\"\"Compute sea surface roughness.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma0 : ndarray\n",
    "        NRCS backscatter.\n",
    "    incidence : ndarray\n",
    "        Incidence angle in degrees.\n",
    "    polarisation : str\n",
    "        'VV' or 'HH' or 'VH' or 'HV'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    roughness: ndarray\n",
    "    \"\"\"\n",
    "    \n",
    "    # Lee-Wiener filtering blures to much the ASAR scenes, so we use it only for wind field\n",
    "    # from scipy.signal import wiener\n",
    "    # sigma0w = wiener(sigma0, mysize=(3,3), noise=None)\n",
    "    # sigma0w = sigma0\n",
    "\n",
    "    # # Earlier form Fabrice - simplyfied\n",
    "    # pol = product.get_sph().get_field('MDS1_TX_RX_POLAR').get_elem()\n",
    "    # if pol == 'H/H':\n",
    "    #     ph = (2.20495, -14.3561e-2, 11.28e-4)\n",
    "    #     sigma0_hh_ref = exp( ( ph[0]+incident_angle*ph[1]+incident_angle**2*ph[2])*log(10) )\n",
    "    #     roughness = sigma0w/sigma0_hh_ref\n",
    "    # elif pol == 'V/V':\n",
    "    #     pv = (2.29373, -15.393e-2, 15.1762e-4)\n",
    "    #     sigma0_vv_ref = exp( ( pv[0]+incident_angle*pv[1]+incident_angle**2*pv[2])*log(10) )\n",
    "    #     roughness = sigma0w/sigma0_vv_ref\n",
    "\n",
    "    # From sar/cerbere\n",
    "    from cmod_vect import cmod5n_forward as cmod5\n",
    "    if polarisation == 'VV' or polarisation == 'V/V': # Use cmod5\n",
    "        sigma0_vv = cmod5(10, 45, incidence)\n",
    "        return sigma0/sigma0_vv\n",
    "    elif polarisation == 'HH' or polarisation == 'H/H': # Use cmod5 and Thompson polarisation ratio\n",
    "        sigma0_vv = cmod5(10, 45, incidence)\n",
    "        alpha = 0.7\n",
    "        polrat = (1 + 2*tan(incidence*pi/180)**2)**2 / \\\n",
    "                 (1 + alpha*tan(incidence*pi/180)**2)**2\n",
    "        return sigma0/sigma0_vv*polrat\n",
    "    elif polarisation == 'VH' or polarisation == 'HV' \\\n",
    "      or polarisation == 'V/H' or polarisation == 'H/V': # Use simple model\n",
    "        # nrcs_vh_db = 0.580*wsp - 35.652\n",
    "        # nrcs_vh_lin = 10^(nrcs_vh_db/10.)\n",
    "        sigma0_cross = 10**((0.58*10-35.652)/10)\n",
    "        return sigma0/sigma0_cross\n",
    "    else:\n",
    "        raise Exception('Unknown polarisation : '+polarisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_wind(fileName, sigma0w, lats_2, lons_2, incident_angle):\n",
    "    # Adding Model wind\n",
    "    startTime = datetime.datetime.strptime(fileName[14:29], \"%Y%m%d_%H%M%S\")\n",
    "    ncepGFSmodelWind = ncepGFSmodel(startTime, lats_2, lons_2)\n",
    "    if not ncepGFSmodelWind:\n",
    "        return False\n",
    "\n",
    "    # Reprojecting data\n",
    "\n",
    "    # Pixel resolution\n",
    "    # we use pxlResWind/pxlResSAR for further pyresample radius_of_influence and sigmas\n",
    "    try:\n",
    "        pxlResWind = asarray(\n",
    "            distancelib.getPixelResolution(ncepGFSmodelWind['lats_wind'],\n",
    "                                           ncepGFSmodelWind['lons_wind'],\n",
    "                                           ncepGFSmodelWind['lats_wind'].shape,\n",
    "                                           'km')\n",
    "        )\n",
    "    except IndexError:\n",
    "        return False\n",
    "    pxlResSAR = asarray(\n",
    "        distancelib.getPixelResolution(lats_2, lons_2, lons_2.shape, 'km')\n",
    "    )*1e3\n",
    "    # Note pxlResWind is in KM, multiply by 1e3 for meters\n",
    "#    print \"ASAR cell resolution, %s m\"  % pxlResSAR\n",
    "#    print \"Wind cell resolution, %s km\" % pxlResWind\n",
    "\n",
    "    # reproject NCEP onto ASAR grid before calculations\n",
    "    # Try both BivariateSpline, griddata and pyresample\n",
    "\n",
    "    ncep_def = pr.geometry.GridDefinition(lons=ncepGFSmodelWind['lons_wind'],\n",
    "                                          lats=ncepGFSmodelWind['lats_wind'])\n",
    "    swath_def = pr.geometry.SwathDefinition(lons=lons_2, lats=lats_2)\n",
    "\n",
    "    # wind_speed_model_swath = pr.kd_tree.resample_gauss(\n",
    "    #     ncep_def, ncepGFSmodelWind['wind_speed'].ravel(), swath_def,\n",
    "    #     radius_of_influence=2*pxlResWind.max()*1e3, neighbours=12,\n",
    "    #     sigmas=pxlResWind.max()*1e3, fill_value=None, nprocs=numProcs\n",
    "    # )\n",
    "    wind_dir_model_swath = pr.kd_tree.resample_gauss(\n",
    "        ncep_def, ncepGFSmodelWind['wind_dir'].ravel(), swath_def,\n",
    "        radius_of_influence=2*pxlResWind.max()*1e3, neighbours=12,\n",
    "        sigmas=pxlResWind.max()*1e3, fill_value=None, nprocs=numProcs\n",
    "    )\n",
    "\n",
    "    # calculate bearing from initial lats/lons for further wind calculation\n",
    "    bearing = zeros((lons.shape[0]-1, lons.shape[1]))\n",
    "\n",
    "    for n in range(0, lons.shape[1]):\n",
    "        col = ([lats[:-1, n], lons[:-1, n]], [lats[1:, n], lons[1:, n]])\n",
    "        for m in range(0, lons.shape[0]-1):\n",
    "            bearing[m][n] = distancelib.bearing(asarray(col[0])[:, m],\n",
    "                                                asarray(col[1])[:, m])\n",
    "\n",
    "    # interpolate to raw_counts.shape\n",
    "    bearing_2 = imresize(bearing, raw_counts.shape)\n",
    "\n",
    "    # NB! WINDDIR = 0 WHEN WIND BLOWS TOWARDS RADAR!\n",
    "    wind_dir_model_swath_rel = 90 + bearing_2 - wind_dir_model_swath\n",
    "\n",
    "    if pol == 'H/H':\n",
    "        PR = PR_Mouche(incident_angle, wind_dir_model_swath_rel)\n",
    "        try:\n",
    "            from cmod_gpu import rcs2windOpenCl\n",
    "            wind_speed_asar = rcs2windOpenCl(sar=sigma0w*PR,\n",
    "                                             windir=wind_dir_model_swath_rel,\n",
    "                                             theta=incident_angle)\n",
    "        except Exception:\n",
    "            from cmod_vect import rcs2windPar\n",
    "            wind_speed_asar = rcs2windPar(sigma0w*PR, cmdv=5,\n",
    "                                          windir=wind_dir_model_swath_rel,\n",
    "                                          theta=incident_angle,\n",
    "                                          nprocs=numProcs)\n",
    "    elif pol == 'V/V':\n",
    "        try:\n",
    "            from cmod_gpu import rcs2windOpenCl\n",
    "            wind_speed_asar = rcs2windOpenCl(sar=sigma0w,\n",
    "                                             windir=wind_dir_model_swath_rel,\n",
    "                                             theta=incident_angle)\n",
    "        except Exception:\n",
    "            from cmod_vect import rcs2windPar\n",
    "            wind_speed_asar = rcs2windPar(sigma0w, cmdv=5,\n",
    "                                          windir=wind_dir_model_swath_rel,\n",
    "                                          theta=incident_angle,\n",
    "                                          nprocs=numProcs)\n",
    "    \n",
    "    return wind_speed_asar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year: 2010 / Day: 270\n"
     ]
    }
   ],
   "source": [
    "asar_path = '/nfs1/store/satellite/asar/'\n",
    "_dir = '/nfs1/store/satellite/asar/2010/270'\n",
    "fileName = 'ASA_WSM_1PNPDK20100927_195408_000000862093_00200_44843_3688.N1'\n",
    "\n",
    "input_filename = os.path.join(_dir, fileName)\n",
    "dt = datetime.datetime.strptime(\n",
    "    fileName[14:22], '%Y%m%d'\n",
    ").timetuple()\n",
    "year = str(dt.tm_year)\n",
    "day = str(dt.tm_yday)\n",
    "\n",
    "if len(day) == 1:\n",
    "    day = '00' + day\n",
    "elif len(day) == 2:\n",
    "    day = '0' + day\n",
    "print \"Year: %s / Day: %s\"  % (year, day)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs1/store/satellite/asar/2010/270/ASA_WSM_1PNPDK20100927_195408_000000862093_00200_44843_3688.N1\n",
      "sc_w*sc_h =  42706440\n"
     ]
    }
   ],
   "source": [
    "sigma0, lats_2, lons_2, incident_angle, pol = compute_sigma0(_dir, fileName)\n",
    "# roughness = compute_roughness(sigma0, incident_angle, pol)\n",
    "# wind_speed_asar = compute_wind(fileName, sigma0, lats_2, lons_2, incident_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:1: RuntimeWarning: divide by zero encountered in log10\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "imshow(10*log10(sigma0), vmin=-20, vmax=5)\n",
    "colorbar()\n",
    "gray()\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reprojecting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_asar_nc(inpath, fn, out_dir, scale=1):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLD VERSION with big_image png tiles"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from big_image import save_big_image\n",
    "__author__ = 'Alexander Myasoedov and Denis Spiridonov'\n",
    "\n",
    "# set the number of CPUs\n",
    "numProcs = cpu_count()-2\n",
    "\n",
    "redis_conf = os.path.join(\n",
    "    os.path.dirname(\n",
    "        os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "    ),\n",
    "    'redis.conf'\n",
    ")\n",
    "\n",
    "config = ConfigParser.RawConfigParser()\n",
    "config.read(redis_conf)\n",
    "redis_host = config.get('AUTH', 'HOSTNAME')\n",
    "redis_passwd = config.get('AUTH', 'PASSWORD')\n",
    "\n",
    "r = redis.Redis(host=redis_host, password=redis_passwd)\n",
    "\n",
    "\n",
    "def windDirection(u, v):\n",
    "    U = u.ravel()\n",
    "    V = v.ravel()\n",
    "    direction = zeros(size(U))\n",
    "    for i in range(0, len(U)):\n",
    "        if U[i] >= 0 and V[i] > 0:\n",
    "            direction[i] = ((180 / pi) * atan(abs(U[i] / V[i])) + 180)\n",
    "        if U[i] < 0 and V[i] > 0:\n",
    "            direction[i] = (-(180 / pi) * atan(abs(U[i] / V[i])) + 180)\n",
    "        if U[i] >= 0 and V[i] < 0:\n",
    "            direction[i] = (-(180 / pi) * atan(abs(U[i] / V[i])) + 360)\n",
    "        if U[i] < 0 and V[i] < 0:\n",
    "            direction[i] = ((180 / pi) * atan(abs(U[i] / V[i])))\n",
    "        if V[i] == 0 and U[i] > 0:\n",
    "            direction[i] = 270\n",
    "        if V[i] == 0 and U[i] < 0:\n",
    "            direction[i] = 90\n",
    "        if V[i] == 0 and U[i] == 0:\n",
    "            direction[i] = 0\n",
    "    return reshape(direction, v.shape)\n",
    "\n",
    "\n",
    "def PR_Mouche(theta, phi):\n",
    "    A_0 = 0.00650704\n",
    "    B_0 = 0.128983\n",
    "    C_0 = 0.992839\n",
    "    A_HALF_PI = 0.00782194\n",
    "    B_HALF_PI = 0.121405\n",
    "    C_HALF_PI = 0.992839\n",
    "    A_PI = 0.00598416\n",
    "    B_PI = 0.140952\n",
    "    C_PI = 0.992885\n",
    "\n",
    "    P_0 = A_0 * exp(B_0 * theta) + C_0\n",
    "    P_HALF_PI = A_HALF_PI * exp(B_HALF_PI * theta) + C_HALF_PI\n",
    "    P_PI = A_PI * exp(B_PI * theta) + C_PI\n",
    "\n",
    "    C0 = (P_0 + P_PI + 2 * P_HALF_PI) / 4\n",
    "    C1 = (P_0 - P_PI) / 2\n",
    "    C2 = (P_0 + P_PI - 2 * P_HALF_PI) / 4\n",
    "\n",
    "    P = C0 + C1 * cos(radians(phi)) + C2 * cos(radians(2 * phi))\n",
    "    return P\n",
    "\n",
    "\n",
    "def ncepGFSmodel(startTime, lats_2, lons_2):\n",
    "    \"\"\"NCEP GFS model wind for givven time, lat/lon crop\n",
    "\n",
    "    \"\"\"\n",
    "    ncepGFSmodel = {}  # empty dict for ncepGFSmodel\n",
    "\n",
    "    iPath_wind = '/media/SOLabNFS2/store/model/ncep/gfs/'\n",
    "\n",
    "    # find the ncep gfs filename to open from ASAR filename\n",
    "    baseHour = floor((startTime.hour+3/2)/6)*6\n",
    "    baseHour = min(18, baseHour)\n",
    "    if startTime.hour-baseHour > 1.5:\n",
    "        forecastHour = 3\n",
    "    else:\n",
    "        forecastHour = 0\n",
    "\n",
    "    if startTime <= datetime.datetime(2014, 8, 19):\n",
    "        ncepFileName = 'gfs' + startTime.strftime(\"%Y%m%d\") + '/gfs.t' +\\\n",
    "                       '%.2d' % (baseHour) + 'z.master.grbf' +\\\n",
    "                       '%.2d' % (forecastHour)\n",
    "\n",
    "        try:\n",
    "            grbs = pygrib.open(iPath_wind + ncepFileName)\n",
    "        except:\n",
    "            print \"File not found %s\" % (iPath_wind + ncepFileName)\n",
    "            return False\n",
    "\n",
    "        u_wind = None\n",
    "        v_wind = None\n",
    "\n",
    "        # wind contains u=u_wind.values[:], Lats=u_wind.latlons()[0], Lons=u_wind.latlons()[1]\n",
    "        for idx, msg_info in enumerate(grbs.select()):\n",
    "            if msg_info['short_name'] == '10u':\n",
    "                u_wind = grbs.message(idx + 1)\n",
    "            elif msg_info['short_name'] == '10v':\n",
    "                v_wind = grbs.message(idx + 1)\n",
    "\n",
    "        u = u_wind.values[:]\n",
    "        v = v_wind.values[:]\n",
    "        lats_wind = u_wind.latlons()[0]\n",
    "        lons_wind = u_wind.latlons()[1]\n",
    "    else:\n",
    "        ncepFileName = 'gfs.' + startTime.strftime(\"%Y%m%d\") +\\\n",
    "                       '%.2d' % (baseHour) + '/gfs.t' + '%.2d' % (baseHour) +\\\n",
    "                       'z.master.grbf' + '%.2d' % (forecastHour) +\\\n",
    "                       '.10m.uv.grib2'\n",
    "\n",
    "        grbs = pygrib.open(iPath_wind + ncepFileName)\n",
    "\n",
    "        u_wind = grbs.message(1)\n",
    "        v_wind = grbs.message(2)\n",
    "        u = u_wind['values']\n",
    "        v = v_wind['values']\n",
    "        lats_wind = u_wind['latitudes']\n",
    "        lons_wind = u_wind['longitudes']\n",
    "        lons_wind = reshape(lons_wind, (lons_wind.shape[0]/720, 720))\n",
    "        lats_wind = reshape(lats_wind, (lats_wind.shape[0]/720, 720))\n",
    "\n",
    "    # Make sure the longitude is between -180.00 .. 179.9\n",
    "    lons_wind = map(\n",
    "        lambda x:\n",
    "        (lons_wind.ravel()[x]+180)-int((lons_wind.ravel()[x]+180)/360)*360-180,\n",
    "        range(0, lons_wind.size)\n",
    "    )\n",
    "    lons_wind = reshape(lons_wind, lats_wind.shape)\n",
    "    # plt.close('all')\n",
    "    # plt.imshow(lons_wind)\n",
    "    # plt.colorbar()\n",
    "\n",
    "#     #Make sure the latitudes is between -90.00 .. 89.9, starting from North - positive\n",
    "#     lats_wind = map(lambda x : (lats_wind.ravel()[x]+90)-int((lats_wind.ravel()[x]+90)/180)*180-90, xrange(0,lats_wind.size))\n",
    "#     lats_wind = reshape(lats_wind, lons_wind.shape)\n",
    "#     if lats_wind[0,0] < lats_wind[-1,-1]:\n",
    "#         lats_wind = flipud(lats_wind)\n",
    "#         u = flipud(u)\n",
    "#         v = flipud(v)\n",
    "#     plt.close('all')\n",
    "#     plt.imshow(lats_wind)\n",
    "#     plt.colorbar()\n",
    "\n",
    "    # find subset\n",
    "    res = findSubsetIndices(lats_2.min(), lats_2.max(), lons_2.min(),\n",
    "                            lons_2.max(), lats_wind[:, 0], lons_wind[0, :])\n",
    "    # expand subset by 1 pixel for better further pyresample\n",
    "    res[0] = res[0]-2\n",
    "    res[1] = res[1]+2\n",
    "    res[2] = res[2]-2\n",
    "    res[3] = res[3]+2\n",
    "\n",
    "    # crop the data\n",
    "    u = u[int(res[2]):int(res[3]), int(res[0]):int(res[1])]\n",
    "    v = v[int(res[2]):int(res[3]), int(res[0]):int(res[1])]\n",
    "    ncepGFSmodel['lats_wind'] = lats_wind[int(res[2]):int(res[3]),\n",
    "                                          int(res[0]):int(res[1])]\n",
    "    ncepGFSmodel['lons_wind'] = lons_wind[int(res[2]):int(res[3]),\n",
    "                                          int(res[0]):int(res[1])]\n",
    "\n",
    "    ncepGFSmodel['wind_dir'] = windDirection(u, v)\n",
    "    ncepGFSmodel['wind_speed'] = sqrt(u**2 + v**2)\n",
    "\n",
    "#     del u_wind, v_wind\n",
    "    return ncepGFSmodel\n",
    "\n",
    "\n",
    "def create_KML_asar(area_extent, savepath):\n",
    "    kml = simplekml.Kml()\n",
    "\n",
    "    pol = kml.newpolygon(name='area_extent', visibility=1)\n",
    "    pol.tessellate = 1\n",
    "\n",
    "    pol.altitudemode = 'clampToGround'\n",
    "    pol.outerboundaryis.coords = [(min(area_extent[0], area_extent[2]),\n",
    "                                   min(area_extent[1], area_extent[3])),\n",
    "                                  (max(area_extent[0], area_extent[2]),\n",
    "                                   max(area_extent[1], area_extent[3]))]\n",
    "    if type(savepath) == list:\n",
    "        for _savepath in savepath:\n",
    "            kml.save(_savepath)\n",
    "    else:\n",
    "        kml.save(savepath)\n",
    "\n",
    "\n",
    "def swath_area_def(name='Temporal SWATH EPSG Projection 4326', proj='eqc',\n",
    "                   lonlim=(-180, 180), latlim=(-90, 90), ellps=\"WGS84\",\n",
    "                   res=111.2e3, lat_ts=None, lat_0=None, lon_0=None):\n",
    "    \"\"\"\n",
    "    Convert given swath coordinates to pyresample area definition.\n",
    "    The arguments are standard for Proj:\n",
    "    name\n",
    "    proj\n",
    "    lonlim\n",
    "    latlim\n",
    "    ellipsoid\n",
    "    resolution(meters)\n",
    "    lat_ts (latitude of true scale)\n",
    "    lat_0,lon_0 is central point\n",
    "    EXAMPLE:\n",
    "\n",
    "    epsg3426 is the default one\n",
    "    for epsg3413:\n",
    "    swath_area_def(name='Temporal SWATH EPSG Projection 3413',\n",
    "                   proj='stere', lonlim=(-180,180), latlim=(30,90),\n",
    "                   ellps=\"WGS84\", res=111.2e3, lat_ts=70, lat_0=90, lon_0=-45)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    up = max(latlim)\n",
    "    down = min(latlim)\n",
    "    left = min(lonlim)\n",
    "    right = max(lonlim)\n",
    "\n",
    "    print 'up, down, left, right: ', up, down, left, right\n",
    "\n",
    "    area_id = name.replace(\" \", \"_\").lower()\n",
    "    proj_id = area_id\n",
    "\n",
    "    if proj == 'eqc':\n",
    "        p = Proj(proj=proj, llcrnrlat=up, urcrnrlat=down, llcrnrlon=left,\n",
    "                 urcrnrlon=right, ellps=ellps)\n",
    "        proj4_args = '+proj=' + str(proj) + ' ' + \\\n",
    "                     '+llcrnrlat=' + str(up) + ' ' + \\\n",
    "                     '+urcrnrlat=' + str(down) + ' ' + \\\n",
    "                     '+llcrnrlon=' + str(left) + ' ' + \\\n",
    "                     '+urcrnrlon=' + str(right) + ' ' + \\\n",
    "                     '+ellps=' + str(ellps)\n",
    "    elif lat_ts is not None and lat_0 is not None:\n",
    "        # lat_ts is latitude of true scale.\n",
    "        # lon_0,lat_0 is central point.\n",
    "        p = Proj(proj=proj, lat_0=lat_0, lon_0=lon_0,\n",
    "                 lat_ts=lat_ts, ellps=ellps)\n",
    "        proj4_args = '+proj=' + str(proj) + ' ' + \\\n",
    "                     '+lat_0=' + str(lat_0) + ' ' + \\\n",
    "                     '+lon_0=' + str(lon_0) + ' ' + \\\n",
    "                     '+lat_ts=' + str(lat_ts) + ' ' + \\\n",
    "                     '+ellps=' + str(ellps)\n",
    "    elif lon_0 is not None and lat_0 is not None and lat_ts is None:\n",
    "        # lon_0,lat_0 is central point.\n",
    "        p = Proj(proj=proj, lat_0=lat_0, lon_0=lon_0, ellps=ellps)\n",
    "        proj4_args = '+proj=' + str(proj) + ' ' + \\\n",
    "                     '+lat_0=' + str(lat_0) + ' ' + \\\n",
    "                     '+lon_0=' + str(lon_0) + ' ' + \\\n",
    "                     '+ellps=' + str(ellps)\n",
    "    elif lon_0 is None and lat_0 is None and lat_ts is None:\n",
    "        # lon_0,lat_0 is central point.\n",
    "        lat_0 = (up + down) / 2\n",
    "        lon_0 = (right + left) / 2\n",
    "        p = Proj(proj=proj, lat_0=lat_0, lon_0=lon_0, ellps=ellps)\n",
    "        proj4_args = '+proj=' + str(proj) + ' ' + \\\n",
    "                     '+lat_0=' + str(lat_0) + ' ' + \\\n",
    "                     '+lon_0=' + str(lon_0) + ' ' + \\\n",
    "                     '+ellps=' + str(ellps)\n",
    "\n",
    "    left_ex1, up_ex1 = p(left, up)\n",
    "    right_ex1, up_ex2 = p(right, up)\n",
    "    left_ex2, down_ex1 = p(left, down)\n",
    "    right_ex2, down_ex2 = p(right, down)\n",
    "\n",
    "    if proj == 'stere':\n",
    "        lon = (left+right)/2.0\n",
    "        if (lon >= 0 and lon < 90) or (lon >= -360 and lon < -270):\n",
    "            print 11111111111\n",
    "            area_extent = (\n",
    "                           min(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                           min(down_ex1, down_ex2, up_ex1, up_ex2),\n",
    "                           max(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                           max(down_ex1, down_ex2, up_ex1, up_ex2)\n",
    "                          )\n",
    "        elif (lon >= 90 and lon < 180) or (lon >= -270 and lon < -180):\n",
    "            print 2222222222222\n",
    "            area_extent = (\n",
    "                       max(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                       max(down_ex1, down_ex2, up_ex1, up_ex2),\n",
    "                       min(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                       min(down_ex1, down_ex2, up_ex1, up_ex2)\n",
    "                       )\n",
    "        elif (lon >= 180 and lon < 270) or (lon >= -180 and lon < -90):\n",
    "            print 333333333333\n",
    "            area_extent = (\n",
    "                       min(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                       min(down_ex1, down_ex2, up_ex1, up_ex2),\n",
    "                       max(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                       max(down_ex1, down_ex2, up_ex1, up_ex2)\n",
    "                      )\n",
    "        else:\n",
    "            print 44444444444444444\n",
    "            area_extent = (\n",
    "                       min(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                       min(down_ex1, down_ex2, up_ex1, up_ex2),\n",
    "                       max(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                       max(down_ex1, down_ex2, up_ex1, up_ex2)\n",
    "                      )\n",
    "    else:\n",
    "        # минимум из всех координат X, Y, максимум из всех координат X, Y\n",
    "        # Такой результат даёт правильный area_extent для 3413\n",
    "        # При этом для 4326 area_extent остаётся неизменным\n",
    "        # area_def_3413 = swath_area_def(name='Temporal SWATH EPSG\n",
    "        # Projection 3413', proj='stere', \\\n",
    "        #         lonlim=(-180,180), latlim=(30,90), ellps=\"WGS84\", res=1500, \\\n",
    "        #         lat_ts=70, lat_0=90, lon_0=-45)\n",
    "        # Area extent: (-5050747.263141337, 0.0, 0.0, 5050747.263141336)\n",
    "        area_extent = (\n",
    "                min(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                min(up_ex1, up_ex2, down_ex1, down_ex2),\n",
    "                max(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                max(up_ex1, up_ex2, down_ex1, down_ex2)\n",
    "        )\n",
    "\n",
    "    print 'left: ', left_ex1, left_ex2\n",
    "    print 'right: ', right_ex1, right_ex2\n",
    "    print 'up: ', up_ex1, up_ex2\n",
    "    print 'down: ', down_ex1, down_ex2\n",
    "\n",
    "    # Using abs() to avoid negative numbers of coloumns/rows\n",
    "    # as for epsg3413 for example\n",
    "    xsize = abs(int((area_extent[2] - area_extent[0]) / res))\n",
    "    ysize = abs(int((area_extent[3] - area_extent[1]) / res))\n",
    "\n",
    "    swath_area_def = pr.utils.get_area_def(area_id, name, proj_id, proj4_args,\n",
    "                                           xsize, ysize, area_extent)\n",
    "\n",
    "#     print swath_area_def\n",
    "\n",
    "    return swath_area_def\n",
    "\n",
    "\n",
    "def imresize(image, size):\n",
    "    \"\"\"\n",
    "    Resizes coefficient arrays using bivariate spline approximation.\n",
    "    \"\"\"\n",
    "    m, n = image.shape\n",
    "    X = linspace(0, m - 1, size[0])\n",
    "    Y = linspace(0, n - 1, size[1])\n",
    "    kx, ky = min([m - 1, 3]), min([n - 1, 3])\n",
    "    interp = RectBivariateSpline(\n",
    "        arange(m), arange(n), image, kx=kx, ky=ky)\n",
    "    resized = interp(X, Y)\n",
    "    return resized\n",
    "\n",
    "\n",
    "def create_asar_image(iPath, oPaths, fileName):\n",
    "    oPath_4326, oPath_3413 = oPaths\n",
    "\n",
    "    print os.path.join(iPath, fileName)\n",
    "    try:\n",
    "        product = epr.Product(os.path.join(iPath, fileName))\n",
    "    except:\n",
    "        print 'unable to read file'\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        band = product.get_band('proc_data')\n",
    "    except epr.EPRValueError:\n",
    "        print 'unable to get band \"proc_data\": epr_get_band_id: band not found'\n",
    "        return False\n",
    "\n",
    "    sc_w = product.get_scene_width()\n",
    "    sc_h = product.get_scene_height()\n",
    "\n",
    "    print 'sc_w*sc_h = ', sc_w * sc_h\n",
    "    if sc_w*sc_h > 60000000:\n",
    "#    if sc_w*sc_h > 24000000:\n",
    "        print \"ASAR Image too large, skipping\"\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        raw_counts = band.read_as_array(sc_w, sc_h)  # , xstep=4, ystep=4)\n",
    "\n",
    "        incident_angle = product.get_band('incident_angle').read_as_array(sc_w,\n",
    "                                                                          sc_h)\n",
    "        # , xstep=4, ystep=4)\n",
    "    except epr.EPRValueError:\n",
    "        print \"EPRValueError\"\n",
    "        return False\n",
    "\n",
    "    # Get lat/lon from geolocation grid\n",
    "    dataset = product.get_dataset('GEOLOCATION_GRID_ADS')\n",
    "    fltp_lats = map(\n",
    "        lambda x:\n",
    "        dataset.read_record(x).get_field('first_line_tie_points.lats').get_elems(),\n",
    "        range(dataset.get_num_records())\n",
    "    )\n",
    "    lltp_lats = map(\n",
    "        lambda x:\n",
    "        dataset.read_record(x).get_field('last_line_tie_points.lats').get_elems(),\n",
    "        range(dataset.get_num_records())\n",
    "    )\n",
    "    fltp_lons = map(\n",
    "        lambda x:\n",
    "        dataset.read_record(x).get_field('first_line_tie_points.longs').get_elems(),\n",
    "        range(dataset.get_num_records())\n",
    "    )\n",
    "    lltp_lons = map(\n",
    "        lambda x:\n",
    "        dataset.read_record(x).get_field('last_line_tie_points.longs').get_elems(),\n",
    "        range(dataset.get_num_records())\n",
    "    )\n",
    "\n",
    "    fltp_lats = asarray(double(fltp_lats))/1e6\n",
    "    lltp_lats = asarray(double(lltp_lats))/1e6\n",
    "    fltp_lons = asarray(double(fltp_lons))/1e6\n",
    "    lltp_lons = asarray(double(lltp_lons))/1e6\n",
    "\n",
    "    lats = row_stack((fltp_lats, lltp_lats[-1, :]))\n",
    "    lons = row_stack((fltp_lons, lltp_lons[-1, :]))\n",
    "\n",
    "    lats = fliplr(lats)\n",
    "    lons = fliplr(lons)\n",
    "\n",
    "    lats_2 = imresize(lats, raw_counts.shape)\n",
    "    lons_2 = imresize(lons, raw_counts.shape)\n",
    "\n",
    "    if lats.max() <= 35:\n",
    "        print \"skipping no area overlap\"\n",
    "        return False\n",
    "\n",
    "    for p in oPaths:\n",
    "        for sp in p:\n",
    "            mkdirs(sp)\n",
    "\n",
    "    # Trimming the array by removing zero values from rows and cols\n",
    "    msk = []\n",
    "    for m in range(raw_counts.shape[0]):\n",
    "        if raw_counts[m, :].sum() == 0:\n",
    "            msk.append(m)\n",
    "    raw_counts = delete(raw_counts, msk, axis=0)\n",
    "    lats_2 = delete(lats_2, msk, axis=0)\n",
    "    lons_2 = delete(lons_2, msk, axis=0)\n",
    "    incident_angle = delete(incident_angle, msk, axis=0)\n",
    "\n",
    "    msk = []\n",
    "    for n in range(raw_counts.shape[1]):\n",
    "        if raw_counts[:, n].sum() == 0:\n",
    "            msk.append(n)\n",
    "    raw_counts = delete(raw_counts, msk, axis=1)\n",
    "    lats_2 = delete(lats_2, msk, axis=1)\n",
    "    lons_2 = delete(lons_2, msk, axis=1)\n",
    "    incident_angle = delete(incident_angle, msk, axis=1)\n",
    "\n",
    "    # Adding Sigma_0\n",
    "    calibration_constant = \\\n",
    "    product.get_dataset('MAIN_PROCESSING_PARAMS_ADS').read_record(0).get_field('calibration_factors.1.ext_cal_fact').get_elems()\n",
    "    # sigma0 = 10*log10( raw_counts**2*sin(incident_angle*pi/180)/calibration_constant )\n",
    "    sigma0 = raw_counts**2*sin(incident_angle*pi/180)/calibration_constant\n",
    "\n",
    "\tfrom scipy.signal import wiener\n",
    "\tsigma0w = wiener(sigma0, mysize=(3,3), noise=None)\n",
    "\t# Lee-Wiener filtering blures to much the ASAR scenes, so we use it only for wind field\n",
    "\t# sigma0w = sigma0\n",
    "\n",
    "\t# # Earlier form Fabrice - simplyfied\n",
    "\t# pol = product.get_sph().get_field('MDS1_TX_RX_POLAR').get_elem()\n",
    "\t# if pol == 'H/H':\n",
    "\t#     ph = (2.20495, -14.3561e-2, 11.28e-4)\n",
    "\t#     sigma0_hh_ref = exp( ( ph[0]+incident_angle*ph[1]+incident_angle**2*ph[2])*log(10) )\n",
    "\t#     roughness = sigma0w/sigma0_hh_ref\n",
    "\t# elif pol == 'V/V':\n",
    "\t#     pv = (2.29373, -15.393e-2, 15.1762e-4)\n",
    "\t#     sigma0_vv_ref = exp( ( pv[0]+incident_angle*pv[1]+incident_angle**2*pv[2])*log(10) )\n",
    "\t#     roughness = sigma0w/sigma0_vv_ref\n",
    "\n",
    "\t# From sar/cerbere\n",
    "\tfrom cmod_vect import cmod5n_forward as cmod5\n",
    "\tpol = product.get_sph().get_field('MDS1_TX_RX_POLAR').get_elem()\n",
    "\tdef compute_roughness(sigma0, incidence, polarisation):\n",
    "\t    \"\"\"Compute sea surface roughness.\n",
    "\n",
    "\t    Parameters\n",
    "\t    ----------\n",
    "\t    sigma0 : ndarray\n",
    "\t        NRCS backscatter.\n",
    "\t    incidence : ndarray\n",
    "\t        Incidence angle in degrees.\n",
    "\t    polarisation : str\n",
    "\t        'VV' or 'HH' or 'VH' or 'HV'\n",
    "\n",
    "\t    Returns\n",
    "\t    -------\n",
    "\t    ndarray\n",
    "\t    \"\"\"\n",
    "\t    if polarisation == 'VV' or polarisation == 'V/V': # Use cmod5\n",
    "\t        sigma0_vv = cmod5(10, 45, incidence)\n",
    "\t        return sigma0/sigma0_vv\n",
    "\t    elif polarisation == 'HH' or polarisation == 'H/H': # Use cmod5 and Thompson polarisation ratio\n",
    "\t        sigma0_vv = cmod5(10, 45, incidence)\n",
    "\t        alpha = 0.7\n",
    "\t        polrat = (1 + 2*tan(incidence*pi/180)**2)**2 / \\\n",
    "\t                 (1 + alpha*tan(incidence*pi/180)**2)**2\n",
    "\t        return sigma0/sigma0_vv*polrat\n",
    "\t    elif polarisation == 'VH' or polarisation == 'HV' \\\n",
    "\t      or polarisation == 'V/H' or polarisation == 'H/V': # Use simple model\n",
    "\t        # nrcs_vh_db = 0.580*wsp - 35.652\n",
    "\t        # nrcs_vh_lin = 10^(nrcs_vh_db/10.)\n",
    "\t        sigma0_cross = 10**((0.58*10-35.652)/10)\n",
    "\t        return sigma0/sigma0_cross\n",
    "\t    else:\n",
    "\t        raise Exception('Unknown polarisation : '+polarisation)\n",
    "\n",
    "\troughness = compute_roughness(sigma0, incident_angle, pol)\n",
    "\n",
    "    # Adding Model wind\n",
    "    startTime = datetime.datetime.strptime(fileName[14:29], \"%Y%m%d_%H%M%S\")\n",
    "    ncepGFSmodelWind = ncepGFSmodel(startTime, lats_2, lons_2)\n",
    "    if not ncepGFSmodelWind:\n",
    "        return False\n",
    "\n",
    "    # Reprojecting data\n",
    "\n",
    "    # Pixel resolution\n",
    "    # we use pxlResWind/pxlResSAR for further pyresample radius_of_influence and sigmas\n",
    "    try:\n",
    "        pxlResWind = asarray(\n",
    "            distancelib.getPixelResolution(ncepGFSmodelWind['lats_wind'],\n",
    "                                           ncepGFSmodelWind['lons_wind'],\n",
    "                                           ncepGFSmodelWind['lats_wind'].shape,\n",
    "                                           'km')\n",
    "        )\n",
    "    except IndexError:\n",
    "        return False\n",
    "    pxlResSAR = asarray(\n",
    "        distancelib.getPixelResolution(lats_2, lons_2, lons_2.shape, 'km')\n",
    "    )*1e3\n",
    "    # Note pxlResWind is in KM, multiply by 1e3 for meters\n",
    "#    print \"ASAR cell resolution, %s m\"  % pxlResSAR\n",
    "#    print \"Wind cell resolution, %s km\" % pxlResWind\n",
    "\n",
    "    # reproject NCEP onto ASAR grid before calculations\n",
    "    # Try both BivariateSpline, griddata and pyresample\n",
    "\n",
    "    ncep_def = pr.geometry.GridDefinition(lons=ncepGFSmodelWind['lons_wind'],\n",
    "                                          lats=ncepGFSmodelWind['lats_wind'])\n",
    "    swath_def = pr.geometry.SwathDefinition(lons=lons_2, lats=lats_2)\n",
    "\n",
    "    # wind_speed_model_swath = pr.kd_tree.resample_gauss(\n",
    "    #     ncep_def, ncepGFSmodelWind['wind_speed'].ravel(), swath_def,\n",
    "    #     radius_of_influence=2*pxlResWind.max()*1e3, neighbours=12,\n",
    "    #     sigmas=pxlResWind.max()*1e3, fill_value=None, nprocs=numProcs\n",
    "    # )\n",
    "    wind_dir_model_swath = pr.kd_tree.resample_gauss(\n",
    "        ncep_def, ncepGFSmodelWind['wind_dir'].ravel(), swath_def,\n",
    "        radius_of_influence=2*pxlResWind.max()*1e3, neighbours=12,\n",
    "        sigmas=pxlResWind.max()*1e3, fill_value=None, nprocs=numProcs\n",
    "    )\n",
    "\n",
    "    # calculate bearing from initial lats/lons for further wind calculation\n",
    "    bearing = zeros((lons.shape[0]-1, lons.shape[1]))\n",
    "\n",
    "    for n in range(0, lons.shape[1]):\n",
    "        col = ([lats[:-1, n], lons[:-1, n]], [lats[1:, n], lons[1:, n]])\n",
    "        for m in range(0, lons.shape[0]-1):\n",
    "            bearing[m][n] = distancelib.bearing(asarray(col[0])[:, m],\n",
    "                                                asarray(col[1])[:, m])\n",
    "\n",
    "    # interpolate to raw_counts.shape\n",
    "    bearing_2 = imresize(bearing, raw_counts.shape)\n",
    "\n",
    "    # NB! WINDDIR = 0 WHEN WIND BLOWS TOWARDS RADAR!\n",
    "    wind_dir_model_swath_rel = 90 + bearing_2 - wind_dir_model_swath\n",
    "\n",
    "    if pol == 'H/H':\n",
    "        PR = PR_Mouche(incident_angle, wind_dir_model_swath_rel)\n",
    "        try:\n",
    "            from cmod_gpu import rcs2windOpenCl\n",
    "            wind_speed_asar = rcs2windOpenCl(sar=sigma0w*PR,\n",
    "                                             windir=wind_dir_model_swath_rel,\n",
    "                                             theta=incident_angle)\n",
    "        except Exception:\n",
    "            from cmod_vect import rcs2windPar\n",
    "            wind_speed_asar = rcs2windPar(sigma0w*PR, cmdv=5,\n",
    "                                          windir=wind_dir_model_swath_rel,\n",
    "                                          theta=incident_angle,\n",
    "                                          nprocs=numProcs)\n",
    "    elif pol == 'V/V':\n",
    "        try:\n",
    "            from cmod_gpu import rcs2windOpenCl\n",
    "            wind_speed_asar = rcs2windOpenCl(sar=sigma0w,\n",
    "                                             windir=wind_dir_model_swath_rel,\n",
    "                                             theta=incident_angle)\n",
    "        except Exception:\n",
    "            from cmod_vect import rcs2windPar\n",
    "            wind_speed_asar = rcs2windPar(sigma0w, cmdv=5,\n",
    "                                          windir=wind_dir_model_swath_rel,\n",
    "                                          theta=incident_angle,\n",
    "                                          nprocs=numProcs)\n",
    "\n",
    "    del lats, lons\n",
    "    del sigma0, raw_counts\n",
    "    del bearing\n",
    "    del ncepGFSmodelWind\n",
    "    gc.collect()\n",
    "\n",
    "    for proj in ['EPSG:4326', 'EPSG:3413']:\n",
    "        # for proj in ['EPSG:4326']:\n",
    "        print \"    start projection %s\" % proj\n",
    "        if proj == 'EPSG:4326':\n",
    "            oPath = oPath_4326\n",
    "            for outpath in oPath:\n",
    "                mkdirs(outpath)\n",
    "            area_def = swath_area_def(\n",
    "                name='Temporal SWATH EPSG Projection 4326', proj='eqc',\n",
    "                lonlim=(lons_2.min(), lons_2.max()),\n",
    "                latlim=(lats_2.min(), lats_2.max()),\n",
    "                ellps=\"WGS84\", res=pxlResSAR.max()\n",
    "            )\n",
    "            # Set the parameters for GSHHS masking\n",
    "            proj_ = '4326'\n",
    "            proj_name = None\n",
    "            units = 'deg'\n",
    "        elif proj == 'EPSG:3413':\n",
    "            oPath = oPath_3413\n",
    "            for outpath in oPath:\n",
    "                mkdirs(outpath)\n",
    "            area_def = swath_area_def(\n",
    "                name='Temporal SWATH EPSG Projection 3413', proj='stere',\n",
    "                lonlim=(lons_2.min(), lons_2.max()),\n",
    "                latlim=(lats_2.min(), lats_2.max()),\n",
    "                ellps=\"WGS84\", res=pxlResSAR.max(),\n",
    "                lat_ts=70, lat_0=90, lon_0=-45\n",
    "            )\n",
    "            # Set the parameters for GSHHS masking\n",
    "            proj_ = '+units=m +ellps=WGS84 +lon_0=-45 +proj=stere +lat_ts=70 +lat_0=90'\n",
    "            proj_name = '3413'\n",
    "            units = 'm'\n",
    "\n",
    "        print area_def\n",
    "        print \"roughness.shape = \", roughness.shape\n",
    "\n",
    "        roughness_res = pr.kd_tree.resample_nearest(\n",
    "            swath_def, roughness.ravel(), area_def,\n",
    "            radius_of_influence=pxlResSAR.max(),\n",
    "            epsilon=0.5, nprocs=numProcs, fill_value=None\n",
    "        )\n",
    "        print \"resample_nearest done\"\n",
    "\n",
    "#        shapefile = '/media/SOLabNFS/store/auxdata/coastline/GSHHS_shp/f/GSHHS_f_L1.shp'\n",
    "#        lonlim=(lons_2.min(),lons_2.max())\n",
    "#        latlim=(lats_2.min(),lats_2.max())\n",
    "#        lakes = True\n",
    "#\n",
    "#        mask_arr = gshhs_rasterize.gshhs_rasterize(lonlim, latlim, units, roughness_res.shape,\n",
    "#                                                   proj_, proj_name, lakes, shapefile)\n",
    "#        roughness_masked = ma.masked_where(mask_arr, roughness_res)\n",
    "        roughness_masked = roughness_res\n",
    "\n",
    "        oFileName = os.path.join(oPath[0], fileName+'.png')\n",
    "        gray()\n",
    "        print 'save roughness_masked image, %s' % oFileName\n",
    "        del roughness_res\n",
    "        gc.collect()\n",
    "        print '=>>', roughness_masked.shape\n",
    "        #imsave(oFileName, roughness_masked, vmin=0, vmax=2)\n",
    "        save_big_image(oFileName, roughness_masked, vmin=0, vmax=2,\n",
    "                       temp_dir='/tmp/save_image/'+fileName)\n",
    "        del roughness_masked\n",
    "        gc.collect()\n",
    "   #     del roughness_masked, roughness_res, roughness\n",
    "\n",
    "        print \"roughness_res done\"\n",
    "        print \"wind_speed_asar.shape = \", wind_speed_asar.shape\n",
    "        wind_speed_asar_res = pr.kd_tree.resample_nearest(\n",
    "            swath_def, wind_speed_asar.ravel(), area_def,\n",
    "            radius_of_influence=pxlResSAR.max(),\n",
    "            epsilon=0.5, nprocs=numProcs, fill_value=None\n",
    "        )\n",
    "        print \"wind_speed_asar_res done\"\n",
    "\n",
    "        # Apply Mask from GSHHS\n",
    "        # ESRI shapefile containing land polygons\n",
    "#        shapefile = '/media/SOLabNFS/store/auxdata/coastline/GSHHS_shp/f/GSHHS_f_L1.shp'\n",
    "#        lonlim=(lons_2.min(),lons_2.max())\n",
    "#        latlim=(lats_2.min(),lats_2.max())\n",
    "#        lakes = True\n",
    "\n",
    "#        mask_arr = gshhs_rasterize.gshhs_rasterize(lonlim, latlim, units, roughness_res.shape,\n",
    "#                                                   proj_, proj_name, lakes, shapefile)\n",
    "#        roughness_masked = ma.masked_where(mask_arr, roughness_res)\n",
    "#        wind_speed_asar_masked = ma.masked_where(mask_arr, wind_speed_asar_res)\n",
    "        wind_speed_asar_masked = wind_speed_asar_res\n",
    "\n",
    "#        oFileName = os.path.join(oPath[0], fileName+'.png')\n",
    "#        gray()\n",
    "#        imsave(oFileName, roughness_masked, vmin=0, vmax=2)\n",
    "\n",
    "        oFileNameWind = os.path.join(oPath[1], fileName+'.png')\n",
    "        jet()\n",
    "        print 'save wind_speed_asar_masked, image, %s' % oFileNameWind\n",
    "#        del wind_speed_asar_res\n",
    "        gc.collect()\n",
    "        # imsave(oFileNameWind, wind_speed_asar_masked, vmin=0, vmax=20)\n",
    "        save_big_image(oFileNameWind, wind_speed_asar_masked, vmin=0, vmax=20,\n",
    "                       temp_dir='/tmp/save_image/'+fileName)\n",
    "#        del wind_speed_asar_masked\n",
    "        gc.collect()\n",
    "    #    del wind_speed_asar_masked, wind_speed_asar_res, wind_speed_asar\n",
    "\n",
    "        for _path in oPath:\n",
    "            create_KML_asar(area_def.area_extent,\n",
    "                            os.path.join(_path, fileName+'.kml'))\n",
    "    del roughness  # , roughness_res\n",
    "    del wind_speed_asar_masked, wind_speed_asar  # , wind_speed_asar_res\n",
    "    product.close()\n",
    "    gc.collect()\n",
    "    return True\n",
    "    # gray()\n",
    "    # pr.plot.show_quicklook(area_def, result, vmin=0, vmax=2,\n",
    "    #  label='Test', num_meridians=45, num_parallels=10, coast_res='l')\n",
    "\n",
    "import gdal\n",
    "sys.path.append('/usr/bin')\n",
    "from gdal2tiles import GDAL2Tiles\n",
    "\n",
    "\n",
    "def create_asar_tiles(png_filename, tiles_output_dir, proj):\n",
    "    local_argv = ['/usr/bin/gdal2tiles.py', '-p', 'raster', '-r', 'cubic',\n",
    "                  '-s', proj, png_filename, tiles_output_dir]\n",
    "    argv = gdal.GeneralCmdLineProcessor(local_argv)\n",
    "    if argv:\n",
    "        gdal2tiles = GDAL2Tiles(argv[1:])\n",
    "        gdal2tiles.process()\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def resize_image(filepath, basewidth, savepath):\n",
    "    if not os.path.isfile(filepath):\n",
    "        return\n",
    "#    if os.path.isfile(savepath):\n",
    "#        return\n",
    "    img = Image.open(filepath)\n",
    "    wpercent = (basewidth / float(img.size[0]))\n",
    "    hsize = int(float(img.size[1]) * float(wpercent))\n",
    "    img = img.resize((basewidth, hsize), Image.ANTIALIAS)\n",
    "    img.save(savepath)\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "def send_redis_message(granule_name, tiles_output_dir, kml_file, output_filename, r):\n",
    "    kml_text = open(kml_file, 'r').read()\n",
    "    prog = re.compile(r'<coordinates>(\\S* \\S*)</coordinates>')\n",
    "    coords = prog.findall(kml_text)[0]\n",
    "    BBox_attrib = []\n",
    "    for cs in coords.split():\n",
    "        BBox_attrib.append(cs.split(',')[0])\n",
    "        BBox_attrib.append(cs.split(',')[1])\n",
    "\n",
    "    xml_info_file = os.path.join(tiles_output_dir, 'tilemapresource.xml')\n",
    "\n",
    "    tree = ET.parse(xml_info_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    units_list = []\n",
    "    for child in root:\n",
    "        if child.tag == 'TileSets':\n",
    "            for TSchild in child:\n",
    "                # print child.attrib\n",
    "                units_list.append(TSchild.attrib['units-per-pixel'])\n",
    "    resolution_list = [int(75 * math.pow(2, i))\n",
    "                       for i in range(len(units_list))]\n",
    "    resolution_list.reverse()\n",
    "    print '=======>', BBox_attrib\n",
    "    print resolution_list\n",
    "\n",
    "    message_text = {\n",
    "      'PRODUCT_NAME': 'ASAR',\n",
    "      'GRANULE_NAME': granule_name,\n",
    "      'PNG_PATH': output_filename,\n",
    "      'OUTPUT_DIRECTORY': tiles_output_dir,\n",
    "      'METADATA': {\n",
    "          'bbox': BBox_attrib,\n",
    "          'resolution': resolution_list\n",
    "          }\n",
    "    }\n",
    "    r.publish('NewGranule', output_filename)\n",
    "\n",
    "    r.publish('Metadata', message_text)\n",
    "\n",
    "fileName = 'ASA_WSM_1PNPDK20100927_195408_000000862093_00200_44843_3688.N1'\n",
    "# input_filename = '/nfs1/store/satellite/asar/2010/270/ASA_WSM_1PNPDK20100927_195408_000000862093_00200_44843_3688.N1'\n",
    "#~ asar_path = '/nfs1/store/satellite/asar'\n",
    "asar_path = '/media/SOLabNFS2/store/satellite/asar'\n",
    "pp_names = ['roughness', 'wind_speed']\n",
    "#out_path = '/media/SOLabNFS2/http/tiles/ASAR'\n",
    "out_path_w = '/media/SOLabNFS2/http/tiles/SOLAB_ASAR_WSPD'\n",
    "out_path_r = '/media/SOLabNFS2/http/tiles/SOLAB_ASAR_ROUGH'\n",
    "\n",
    "\n",
    "def mkdirs(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "roughness_flag = True\n",
    "\n",
    "\n",
    "#Start 538 granule 2012\n",
    "\n",
    "#Start 594 granule 2011\n",
    "\n",
    "\n",
    "count = 0\n",
    "offset = 593\n",
    "for _dir, sub_dir, _files in os.walk(asar_path):\n",
    "    if not '2011' in _dir:\n",
    "        continue\n",
    "    for fileName in _files:\n",
    "        if fileName.startswith('ASA_') and fileName.endswith('.N1'):\n",
    "            count += 1\n",
    "            if count <= offset:\n",
    "                continue\n",
    "            print \"Start %d granule\" % count\n",
    "#            if fileName in ['ASA_IMM_1PNPDK20080202_152546_000001902065_00369_30984_0214.N1']:\n",
    "#                continue\n",
    "            #_dir = '/media/SOLabNFS2/store/satellite/asar/2008/001'\n",
    "            #fileName = 'ASA_IMM_1PNPDK20080101_084943_000000812064_00408_30522_3741.N1'\n",
    "            # _dir = '/nfs1/store/satellite/asar/2010/270'\n",
    "            # fileName = 'ASA_WSM_1PNPDK20100927_195408_000000862093_00200_44843_3688.N1'\n",
    "            input_filename = os.path.join(_dir, fileName)\n",
    "            dt = datetime.datetime.strptime(\n",
    "                fileName[14:22], '%Y%m%d'\n",
    "            ).timetuple()\n",
    "            year = str(dt.tm_year)\n",
    "            day = str(dt.tm_yday)\n",
    "\n",
    "            if len(day) == 1:\n",
    "                day = '00' + day\n",
    "            elif len(day) == 2:\n",
    "                day = '0' + day\n",
    "            print year, day\n",
    "\n",
    "            # _dir = '/nfs1/store/satellite/asar/%s/%s' % (year, day)\n",
    "            oPath_4326_r = os.path.join(out_path_r, pp_names[0], 'epsg_4326',\n",
    "                                        year, day, fileName)\n",
    "            oPath_3413_r = os.path.join(out_path_r, pp_names[0], 'epsg_3413',\n",
    "                                        year, day, fileName)\n",
    "            oPath_4326_w = os.path.join(out_path_w, pp_names[1], 'epsg_4326',\n",
    "                                        year, day, fileName)\n",
    "            oPath_3413_w = os.path.join(out_path_w, pp_names[1], 'epsg_3413',\n",
    "                                        year, day, fileName)\n",
    "\n",
    "            print \"Start granule: %s\" % fileName\n",
    "\n",
    "            # create dirs\n",
    "#            mkdirs(oPath_4326_r)\n",
    "#            mkdirs(oPath_3413_r)\n",
    "#            mkdirs(oPath_4326_w)\n",
    "#            mkdirs(oPath_3413_w)\n",
    "\n",
    "            # check png file\n",
    "            png_4326_r_filename = os.path.join(oPath_4326_r, fileName+'.png')\n",
    "            png_3413_r_filename = os.path.join(oPath_3413_r, fileName+'.png')\n",
    "            png_4326_w_filename = os.path.join(oPath_4326_w, fileName+'.png')\n",
    "            png_3413_w_filename = os.path.join(oPath_3413_w, fileName+'.png')\n",
    "\n",
    "#            if roughness_flag:\n",
    "#                oPaths = [(oPath_4326_r, None),\n",
    "#                          (oPath_3413_r, None)]\n",
    "#            else:\n",
    "#                oPaths = [(None, oPath_4326_w),\n",
    "#                          (None, oPath_3413_w)]\n",
    "            oPaths = [(oPath_4326_r, oPath_4326_w),\n",
    "                      (oPath_3413_r, oPath_3413_w)]\n",
    "            pngPaths = [(png_4326_r_filename, png_4326_w_filename),\n",
    "                        (png_3413_r_filename, png_3413_w_filename)]\n",
    "\n",
    "#            if roughness_flag:\n",
    "#                if not os.path.isfile(png_4326_r_filename) or not os.path.isfile(png_3413_r_filename):\n",
    "#                    if not create_asar_image(_dir, oPaths, fileName):\n",
    "#                        continue\n",
    "#            else:\n",
    "#               if not os.path.isfile(png_4326_w_filename) or not os.path.isfile(png_3413_w_filename):\n",
    "#                   if not create_asar_image(_dir, oPaths, fileName, roughness_flag):\n",
    "#                       continue\n",
    "\n",
    "            if not os.path.isfile(png_4326_r_filename) or \\\n",
    "               not os.path.isfile(png_3413_r_filename) or \\\n",
    "               not os.path.isfile(png_4326_w_filename) or \\\n",
    "               not os.path.isfile(png_3413_w_filename):\n",
    "                print \"Start create image for %s\" % fileName\n",
    "                if not create_asar_image(_dir, oPaths, fileName):\n",
    "                    continue\n",
    "\n",
    "#            resize_image(png_3413_r_filename, 1024, os.path.join(oPath_3413_r, fileName+'_1024.png'))\n",
    "#            resize_image(png_3413_r_filename, 263, os.path.join(oPath_3413_r, fileName+'_263.png'))\n",
    "            # create thumbs\n",
    "            for num in range(len(oPaths)):\n",
    "                resize_image(pngPaths[num][0], 1024,\n",
    "                             os.path.join(oPaths[num][0],\n",
    "                             fileName+'_1024.png'))\n",
    "                resize_image(pngPaths[num][0], 263,\n",
    "                             os.path.join(oPaths[num][0],\n",
    "                             fileName+'_263.png'))\n",
    "                resize_image(pngPaths[num][1], 1024,\n",
    "                             os.path.join(oPaths[num][1],\n",
    "                             fileName+'_1024.png'))\n",
    "                resize_image(pngPaths[num][1], 263,\n",
    "                             os.path.join(oPaths[num][1],\n",
    "                             fileName+'_263.png'))\n",
    "\n",
    "            # check tiles\n",
    "            tiles_4326_r_output_dir = os.path.join(oPath_4326_r, 'tiles')\n",
    "            tiles_3413_r_output_dir = os.path.join(oPath_3413_r, 'tiles')\n",
    "            if not os.path.isdir(tiles_4326_r_output_dir):\n",
    "                print \"start create tiles for %s\" % tiles_4326_r_output_dir\n",
    "                create_asar_tiles(png_4326_r_filename,\n",
    "                                  tiles_4326_r_output_dir, 'EPSG:4326')\n",
    "                kml_file_4326 = os.path.join(oPath_4326_r, fileName+'.kml')\n",
    "                send_redis_message(input_filename, tiles_4326_r_output_dir, kml_file_4326,\n",
    "                                   png_4326_r_filename, r)\n",
    "            if not os.path.isdir(tiles_3413_r_output_dir):\n",
    "                print \"start create tiles for %s\" % tiles_3413_r_output_dir\n",
    "                create_asar_tiles(png_3413_r_filename,\n",
    "                                  tiles_3413_r_output_dir, 'EPSG:3413')\n",
    "                kml_file_3413 = os.path.join(oPath_3413_r, fileName+'.kml')\n",
    "                send_redis_message(input_filename, tiles_3413_r_output_dir, kml_file_3413,\n",
    "                                   png_3413_r_filename, r)\n",
    "\n",
    "            tiles_4326_w_output_dir = os.path.join(oPath_4326_w, 'tiles')\n",
    "            tiles_3413_w_output_dir = os.path.join(oPath_3413_w, 'tiles')\n",
    "\n",
    "            if not os.path.isdir(tiles_4326_w_output_dir):\n",
    "                print \"start create tiles for %s\" % tiles_4326_w_output_dir\n",
    "                create_asar_tiles(png_4326_w_filename,\n",
    "                                  tiles_4326_w_output_dir, 'EPSG:4326')\n",
    "                kml_file_4326 = os.path.join(oPath_4326_w, fileName+'.kml')\n",
    "                send_redis_message(input_filename, tiles_4326_w_output_dir,\n",
    "                                   kml_file_4326, png_4326_w_filename, r)\n",
    "            if not os.path.isdir(tiles_3413_w_output_dir):\n",
    "                print \"start create tiles for %s\" % tiles_3413_w_output_dir\n",
    "                create_asar_tiles(png_3413_w_filename,\n",
    "                                  tiles_3413_w_output_dir, 'EPSG:3413')\n",
    "                kml_file_3413 = os.path.join(oPath_3413_w, fileName+'.kml')\n",
    "                send_redis_message(input_filename, tiles_3413_w_output_dir,\n",
    "                                   kml_file_3413, png_3413_w_filename, r)\n",
    "\n",
    "            gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
