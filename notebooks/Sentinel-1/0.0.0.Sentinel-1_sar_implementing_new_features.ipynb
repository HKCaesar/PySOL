{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !TODO\n",
    "\n",
    "# CMOD for HH and HV/VH - Hwang\n",
    "\n",
    "# Ice from cross pol\n",
    "\n",
    "# Svalbard/Barents Area Case Study\n",
    "\n",
    "# Remove antenna pattern\n",
    "# https://github.com/senbox-org/s1tbx/blob/master/s1tbx-op-calibration/src/main/java/org/esa/nest/gpf/ASARCalibrator.java\n",
    "\n",
    "# Trimm the data by removing zero values from side rows and cols\n",
    "\n",
    "# Read and calibrate SLC product\n",
    "\n",
    "# Example from Fab (Chapron)\n",
    "# s1a-s5-grd-hh-20140818t181248-20140818t181312-001998-001ef8-001-roughness\n",
    "# https://mail.google.com/mail/u/0/#inbox/14961597bb0cef3c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import asarray, zeros, reshape, double, arange, \\\n",
    "                  ma, log10, diff, mean, flipud, floor, pi, sqrt, size, fliplr, meshgrid, exp, cos, radians, \\\n",
    "                  round, array, maximum, minimum, repeat\n",
    "from scipy.signal import argrelmin, argrelmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "import datetime\n",
    "\n",
    "from matplotlib.mlab import find\n",
    "import xmltodict\n",
    "\n",
    "from PIL import Image\n",
    "import StringIO\n",
    "\n",
    "from scipy.interpolate import RectBivariateSpline, interp1d\n",
    "from scipy.signal import wiener\n",
    "\n",
    "import os\n",
    "\n",
    "import distancelib\n",
    "\n",
    "__author__   = 'Alexander Myasoedov'\n",
    "__email__    = 'mag@rshu.ru'\n",
    "__created__  = datetime.datetime(2014, 10, 28)\n",
    "__modified__ = datetime.datetime(2014, 11, 13)\n",
    "__version__  = \"1.0\"\n",
    "__status__   = \"Development\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "numProcs = cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import linspace, arange\n",
    "\n",
    "def imresize(image, size):\n",
    "    \"\"\"\n",
    "    Resizes coefficient arrays using bivariate spline approximation.\n",
    "    \"\"\"\n",
    "    m, n = image.shape\n",
    "    X = linspace(0, m - 1, size[0])\n",
    "    Y = linspace(0, n - 1, size[1])\n",
    "    kx, ky = min([m - 1, 3]), min([n - 1, 3])\n",
    "    interp = RectBivariateSpline(\n",
    "        arange(m), arange(n), image, kx=kx, ky=ky)\n",
    "    resized = interp(X, Y)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import atan\n",
    "\n",
    "def windDirection(u, v):\n",
    "    U = u.ravel()\n",
    "    V = v.ravel()\n",
    "    direction = zeros(size(U))\n",
    "    for i in range(0, len(U)):\n",
    "        if U[i] >= 0 and V[i] > 0: direction[i] = ((180 / pi) * atan(abs(U[i] / V[i])) + 180)\n",
    "        if U[i] < 0 and V[i] > 0: direction[i] = (-(180 / pi) * atan(abs(U[i] / V[i])) + 180)\n",
    "        if U[i] >= 0 and V[i] < 0: direction[i] = (-(180 / pi) * atan(abs(U[i] / V[i])) + 360)\n",
    "        if U[i] < 0 and V[i] < 0: direction[i] = ((180 / pi) * atan(abs(U[i] / V[i])))\n",
    "        if V[i] == 0 and U[i] > 0: direction[i] = 270\n",
    "        if V[i] == 0 and U[i] < 0: direction[i] = 90\n",
    "        if V[i] == 0 and U[i] == 0: direction[i] = 0\n",
    "    return reshape(direction, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using NCEP\n",
    "from createMapsEtopo1 import findSubsetIndices\n",
    "import pygrib\n",
    "\n",
    "def ncepGFSmodel(startTime, lats_2, lons_2):\n",
    "    \"\"\"\n",
    "    NCEP GFS model wind for givven time, lat/lon crop \n",
    "    \"\"\"\n",
    "    ncepGFSmodel = {} # empty dict for ncepGFSmodel\n",
    "\n",
    "    iPath_wind = '/media/SOLabNFS2/store/model/ncep/gfs/'\n",
    "\n",
    "    # find the ncep gfs filename to open from ASAR filename\n",
    "    baseHour = floor((startTime.hour+3/2)/6)*6\n",
    "    baseHour = min(18, baseHour)\n",
    "    if startTime.hour-baseHour>1.5:\n",
    "        forecastHour = 3\n",
    "    else:\n",
    "        forecastHour = 0\n",
    "\n",
    "    if startTime <= datetime.datetime(2014, 8, 19):\n",
    "        ncepFileName = 'gfs' + startTime.strftime(\"%Y%m%d\") + '/gfs.t' + '%.2d' %(baseHour) + 'z.master.grbf' + '%.2d' %(forecastHour)\n",
    "\n",
    "        grbs = pygrib.open(iPath_wind + ncepFileName)\n",
    "\n",
    "        u_wind = None\n",
    "        v_wind = None\n",
    "\n",
    "        # wind contains u=u_wind.values[:], Lats=u_wind.latlons()[0], Lons=u_wind.latlons()[1]\n",
    "        for idx, msg_info in enumerate(grbs.select()):\n",
    "            if msg_info['short_name'] == '10u':\n",
    "                u_wind = grbs.message(idx + 1)\n",
    "            elif msg_info['short_name'] == '10v':\n",
    "                v_wind = grbs.message(idx + 1)\n",
    "\n",
    "        u = u_wind.values[:]\n",
    "        v = v_wind.values[:]\n",
    "        lats_wind = u_wind.latlons()[0]\n",
    "        lons_wind = u_wind.latlons()[1]\n",
    "    else:\n",
    "        try:\n",
    "            ncepFileName = 'gfs.' + startTime.strftime(\"%Y%m%d\") + '%.2d' %(baseHour) + '/gfs.t' + '%.2d' %(baseHour) + 'z.master.grbf' + '%.2d' %(forecastHour) + '.10m.uv.grib2'\n",
    "\n",
    "            grbs = pygrib.open(iPath_wind + ncepFileName)\n",
    "\n",
    "            u_wind = grbs.message(1)\n",
    "            v_wind = grbs.message(2)\n",
    "            u = u_wind['values']\n",
    "            v = v_wind['values']\n",
    "            lats_wind = u_wind['latitudes']\n",
    "            lons_wind = u_wind['longitudes']\n",
    "            lons_wind = reshape(lons_wind, (lons_wind.shape[0]/720, 720))\n",
    "            lats_wind = reshape(lats_wind, (lats_wind.shape[0]/720, 720))\n",
    "        except Exception:\n",
    "            ncepFileName = 'gfs.' + startTime.strftime(\"%Y%m%d\") + '%.2d' %(baseHour) + '/gfs.t' + '%.2d' %(baseHour) + 'z.pgrb2.0p25.f' + '%.3d' %(forecastHour)\n",
    "\n",
    "            grbs = pygrib.open(iPath_wind + ncepFileName)\n",
    "\n",
    "            u_wind = grbs.message(1)\n",
    "            v_wind = grbs.message(2)\n",
    "            u = u_wind['values']\n",
    "            v = v_wind['values']\n",
    "            lats_wind = u_wind['latitudes']\n",
    "            lons_wind = u_wind['longitudes']\n",
    "            lons_wind = reshape(lons_wind, (lons_wind.shape[0]/1440, 1440))\n",
    "            lats_wind = reshape(lats_wind, (lats_wind.shape[0]/1440, 1440))\n",
    "\n",
    "    #Make sure the longitude is between -180.00 .. 179.9\n",
    "    lons_wind = map(lambda x : (lons_wind.ravel()[x]+180)-int((lons_wind.ravel()[x]+180)/360)*360-180, range(0,lons_wind.size))\n",
    "    lons_wind = reshape(lons_wind, lats_wind.shape)\n",
    "    # plt.close('all')\n",
    "    # plt.imshow(lons_wind)\n",
    "    # plt.colorbar()\n",
    "\n",
    "#     #Make sure the latitudes is between -90.00 .. 89.9, starting from North - positive\n",
    "#     lats_wind = map(lambda x : (lats_wind.ravel()[x]+90)-int((lats_wind.ravel()[x]+90)/180)*180-90, xrange(0,lats_wind.size))\n",
    "#     lats_wind = reshape(lats_wind, lons_wind.shape)\n",
    "#     if lats_wind[0,0] < lats_wind[-1,-1]:\n",
    "#         lats_wind = flipud(lats_wind)\n",
    "#         u = flipud(u)\n",
    "#         v = flipud(v)\n",
    "#     plt.close('all')\n",
    "#     plt.imshow(lats_wind)\n",
    "#     plt.colorbar()\n",
    "\n",
    "\n",
    "    # find subset\n",
    "    res = findSubsetIndices(lats_2.min(),lats_2.max(),lons_2.min(),lons_2.max(),lats_wind[:,0],lons_wind[0,:])\n",
    "    # expand subset by 1 pixel for better further pyresample\n",
    "    res[0]=res[0]-2\n",
    "    res[1]=res[1]+2\n",
    "    res[2]=res[2]-2\n",
    "    res[3]=res[3]+2\n",
    "\n",
    "    # crop the data\n",
    "    u = u[int(res[2]):int(res[3]),int(res[0]):int(res[1])]\n",
    "    v = v[int(res[2]):int(res[3]),int(res[0]):int(res[1])]\n",
    "    ncepGFSmodel['lats_wind'] = lats_wind[int(res[2]):int(res[3]),int(res[0]):int(res[1])]\n",
    "    ncepGFSmodel['lons_wind'] = lons_wind[int(res[2]):int(res[3]),int(res[0]):int(res[1])]\n",
    "\n",
    "    ncepGFSmodel['wind_dir'] = windDirection(u,v)\n",
    "    ncepGFSmodel['wind_speed'] = sqrt(u**2 + v**2)\n",
    "    ncepGFSmodel['u'] = u\n",
    "    ncepGFSmodel['v'] = v\n",
    "#     del u_wind, v_wind\n",
    "    return ncepGFSmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def swath_area_def(name='Temporal SWATH EPSG Projection 4326', proj='eqc', lonlim=(-180,180), latlim=(-90,90), ellps=\"WGS84\", res=111.2e3, lat_ts=None, lat_0=None, lon_0=None):\n",
    "    \"\"\"\n",
    "    Convert given swath coordinates to pyresample area definition.\n",
    "    The arguments are standard for Proj:\n",
    "    name\n",
    "    proj\n",
    "    lonlim\n",
    "    latlim\n",
    "    ellipsoid\n",
    "    resolution(meters)\n",
    "    lat_ts (latitude of true scale)\n",
    "    lat_0,lon_0 is central point\n",
    "    EXAMPLE:\n",
    "    \n",
    "    epsg3426 is the default one\n",
    "    for epsg3413:\n",
    "    swath_area_def(name='Temporal SWATH EPSG Projection 3413', proj='stere', lonlim=(-180,180), latlim=(30,90), ellps=\"WGS84\", res=111.2e3, lat_ts=70, lat_0=90, lon_0=-45)\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    area_id = name.replace(\" \", \"_\").lower()\n",
    "    proj_id = area_id\n",
    "\n",
    "    up    = min(latlim)\n",
    "    down  = max(latlim)\n",
    "    left  = min(lonlim)\n",
    "    right = max(lonlim)\n",
    "    \n",
    "    if proj == 'eqc':\n",
    "        p = Proj(proj=proj, llcrnrlat=up, urcrnrlat=down, llcrnrlon=left, urcrnrlon=right, ellps=ellps)\n",
    "        proj4_args = '+proj=' + str(proj) + ' ' + \\\n",
    "             '+llcrnrlat=' + str(up) + ' ' + \\\n",
    "             '+urcrnrlat=' + str(down) + ' ' + \\\n",
    "             '+llcrnrlon=' + str(left) + ' ' + \\\n",
    "             '+urcrnrlon=' + str(right) + ' ' + \\\n",
    "             '+ellps=' + str(ellps)\n",
    "    elif lat_ts!=None and lat_0!=None:\n",
    "        # lat_ts is latitude of true scale.\n",
    "        # lon_0,lat_0 is central point.\n",
    "        p = Proj(proj=proj, lat_0=lat_0, lon_0=lon_0, lat_ts=lat_ts, ellps=ellps)\n",
    "        proj4_args = '+proj=' + str(proj) + ' ' + \\\n",
    "             '+lat_0=' + str(lat_0) + ' ' + \\\n",
    "             '+lon_0=' + str(lon_0) + ' ' + \\\n",
    "             '+lat_ts=' + str(lat_ts) + ' ' + \\\n",
    "             '+ellps=' + str(ellps)\n",
    "    elif lon_0!=None and lat_0!=None and lat_ts==None:\n",
    "        # lon_0,lat_0 is central point.\n",
    "        p = Proj(proj=proj, lat_0=lat_0, lon_0=lon_0, ellps=ellps)\n",
    "        proj4_args = '+proj=' + str(proj) + ' ' + \\\n",
    "             '+lat_0=' + str(lat_0) + ' ' + \\\n",
    "             '+lon_0=' + str(lon_0) + ' ' + \\\n",
    "             '+ellps=' + str(ellps)\n",
    "    elif lon_0==None and lat_0==None and lat_ts==None:\n",
    "        # lon_0,lat_0 is central point.\n",
    "        lat_0 = (min(latlim) + max(latlim)) / 2\n",
    "        lon_0 = (min(lonlim) + max(lonlim)) / 2\n",
    "        p = Proj(proj=proj, lat_0=lat_0, lon_0=lon_0, ellps=ellps)\n",
    "        proj4_args = '+proj=' + str(proj) + ' ' + \\\n",
    "             '+lat_0=' + str(lat_0) + ' ' + \\\n",
    "             '+lon_0=' + str(lon_0) + ' ' + \\\n",
    "             '+ellps=' + str(ellps)\n",
    "\n",
    "    # area_extent defined as (x_min, y_min, x_max, y_max)\n",
    "    left_ex1, up_ex1 = p(left, up)\n",
    "    right_ex1, up_ex2 = p(right, up)\n",
    "    left_ex2, down_ex1 = p(left, down)\n",
    "    right_ex2, down_ex2 = p(right, down)\n",
    "\n",
    "    area_extent = (min(left_ex1, left_ex2),\n",
    "                   min(up_ex1, up_ex2),\n",
    "                   max(right_ex1, right_ex2),\n",
    "                   max(down_ex1, down_ex2))\n",
    "\n",
    "    # минимум из всех координат X, Y, максимум из всех координат X, Y\n",
    "    # Такой результат даёт правильный area_extent для 3413\n",
    "    # При этом для 4326 area_extent остаётся неизменным\n",
    "    # area_def_3413 = swath_area_def(name='Temporal SWATH EPSG Projection 3413', proj='stere', \\\n",
    "    #                                lonlim=(-180,180), latlim=(30,90), ellps=\"WGS84\", res=1500, \\\n",
    "    #                                lat_ts=70, lat_0=90, lon_0=-45)\n",
    "    # Area extent: (-5050747.263141337, 0.0, 0.0, 5050747.263141336)\n",
    "    area_extent = (min(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                   min(up_ex1, up_ex2, down_ex1, down_ex2),\n",
    "                   max(left_ex1, left_ex2, right_ex1, right_ex2),\n",
    "                   max(up_ex1, up_ex2, down_ex1, down_ex2))\n",
    "\n",
    "#     Using abs() to avoid negative numbers of coloumns/rows as for epsg3413 for example\n",
    "    xsize = abs(int((area_extent[2] - area_extent[0]) / res[0]))\n",
    "    ysize = abs(int((area_extent[3] - area_extent[1]) / res[1]))\n",
    "\n",
    "    swath_area_def = pr.utils.get_area_def(area_id, name, proj_id, proj4_args, xsize, ysize, area_extent)\n",
    "\n",
    "#     print swath_area_def\n",
    "\n",
    "    return swath_area_def\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _format_extent_spacing(extent, spacing, GEOgrid, midazimuth=False,\n",
    "                           midrange=False):\n",
    "    \"\"\"Format (and check) extent and spacing.\"\"\"\n",
    "    # Check extent\n",
    "    ext = round(extent).flatten()\n",
    "    if ext.size != 4:\n",
    "        raise Exception('extent must contain 4 elements')\n",
    "    extmax = (0.,0., GEOgrid['numberOfLines']-1, GEOgrid['numberOfSamples']-1)\n",
    "    if (ext[0:2] < extmax[0:2]).any() or (ext[2:4] > extmax[2:4]).any():\n",
    "        exttmp = array(ext)\n",
    "        ext[0:2] = maximum(ext[0:2], extmax[0:2])\n",
    "        ext[2:4] = minimum(ext[2:4], extmax[2:4])\n",
    "        print 'Warning : extent is outside SAR image, '+str(exttmp)+\\\n",
    "            ' becomes '+str(ext)\n",
    "    if (ext[0:2] > ext[2:4]).any():\n",
    "        raise Exception('extent[0:2] must be less or equal than '+\\\n",
    "                        'extent[2:4]')\n",
    "    # Check spacing\n",
    "    spa = round(spacing).flatten()\n",
    "    if spa.size == 1:\n",
    "        spa = repeat(spa[0], 2)\n",
    "    elif spa.size == 2:\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception('spacing must contain 1 or 2 elements')\n",
    "    if (spa < [1, 1]).any():\n",
    "        spatmp = array(spa)\n",
    "        spa = maximum(spa, [1, 1])\n",
    "        print 'Warning : spacing too small, '+str(spatmp)+' becomes '+\\\n",
    "            str(spa)\n",
    "    if (spa > ext[2:4]-ext[0:2]).any():\n",
    "        spatmp = array(spa)\n",
    "        spa = minimum(spa, ext[2:4]-ext[0:2])\n",
    "        print 'Warning : spacing too large, '+str(spatmp)+' becomes '+\\\n",
    "            str(spa)\n",
    "    # Make extent to be spacing modulo\n",
    "    ext[2:4] -= (ext[2:4]-ext[0:2]) % spa\n",
    "#     # 1D extent\n",
    "#     if midazimuth == True:\n",
    "#         dim = (ext[2]-ext[0]+1)/spa[0]\n",
    "#         ext[0:3:2] = ext[0] + (dim-1)//2*spa[0] + [0, spa[0]-1]\n",
    "#     if midrange == True:\n",
    "#         dim = (ext[3]-ext[1]+1)/spa[1]\n",
    "#         ext[1:4:2] = ext[1] + (dim-1)//2*spa[1] + [0, spa[1]-1]\n",
    "    return (ext, spa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# READ THE RAW_COUNTS from GRD image\n",
    "\n",
    "def read_raw_counts(fn, fileLocation, polarization, scale, GEOgrid):\n",
    "\n",
    "\n",
    "    # Note that For SLC images BitsPerSample=32 and for GRD BitsPerSample=16\n",
    "\n",
    "    # im = Image.open(inpath + fileLocation['s1aiwgrd' + polarization])\n",
    "\n",
    "    im = zf.read(fn[:-4] + '.SAFE' + fileLocation[fn.lower().replace(\"_\",\"\")[0:8] + polarization][1:])\n",
    "    im = StringIO.StringIO(im) #Encode the raw data to be used by Image.open()\n",
    "    im = Image.open(im)        #Open the image\n",
    "    im = asarray(im)\n",
    "\n",
    "    arrShape =  asarray([GEOgrid['numberOfLines'], GEOgrid['numberOfSamples']])\n",
    "    ext, spa = _format_extent_spacing((0.,0.,arrShape[0]-1,arrShape[1]-1), scale, GEOgrid)\n",
    "    if scale.max() > 1:\n",
    "        im = im[ext[0]:ext[2],ext[1]:ext[3]]\n",
    "        sha = (im.shape[0]/spa[0], spa[0],\n",
    "               im.shape[1]/spa[1], spa[1])\n",
    "        im = im.reshape(sha).mean(-1).mean(1)\n",
    "    \n",
    "    return im, ext, spa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# READ the ANNOTATION\n",
    "\n",
    "def read_anotation(fn, fileLocation, polarization):\n",
    "    # open the fileLocation\n",
    "\n",
    "    # annotation = open(inpath + fileLocation['products1aiwgrd' + polarization], \"r\") # Open a file in read-only mode\n",
    "    # annotation = annotation.read() # read the file object\n",
    "\n",
    "    annotation = zf.read(fn[:-4] + '.SAFE' + fileLocation['product' + fn.lower().replace(\"_\",\"\")[0:8] + polarization][1:])\n",
    "    annotation = xmltodict.parse(annotation) # Parse the read document string\n",
    "    \n",
    "    # get geolocationGrid parameters from the Annotation Data Set Records (ADSR)\n",
    "    # preallocate variables\n",
    "    GEOgrid = {} # empty dict for GEOgrids\n",
    "\n",
    "    GEOgrid['rangePixelSpacing']   = float(annotation['product']['imageAnnotation']['imageInformation']['rangePixelSpacing'])\n",
    "    GEOgrid['azimuthPixelSpacing'] = float(annotation['product']['imageAnnotation']['imageInformation']['azimuthPixelSpacing'])\n",
    "    GEOgrid['numberOfSamples']   = float(annotation['product']['imageAnnotation']['imageInformation']['numberOfSamples'])\n",
    "    GEOgrid['numberOfLines'] = float(annotation['product']['imageAnnotation']['imageInformation']['numberOfLines'])\n",
    "\n",
    "    geolocationGridPointList = annotation['product']['geolocationGrid']['geolocationGridPointList']\n",
    "    GEOgrid['lats']  = zeros( ( int(geolocationGridPointList['@count']), 1) )\n",
    "    GEOgrid['lons']  = zeros( GEOgrid['lats'].shape )\n",
    "    GEOgrid['line']  = zeros( GEOgrid['lats'].shape, dtype=int )\n",
    "    GEOgrid['pixel'] = zeros( GEOgrid['lats'].shape, dtype=int )\n",
    "    GEOgrid['incidenceAngle'] = zeros( GEOgrid['lats'].shape )\n",
    "    GEOgrid['elevationAngle'] = zeros( GEOgrid['lats'].shape )\n",
    "\n",
    "    # read Geolocation grid points\n",
    "    for n in range(int(geolocationGridPointList['@count'])):\n",
    "        GEOgrid['lats'][n]  = float(geolocationGridPointList['geolocationGridPoint'][n]['latitude'])\n",
    "        GEOgrid['lons'][n]  = float(geolocationGridPointList['geolocationGridPoint'][n]['longitude'])\n",
    "        GEOgrid['line'][n]  = int(geolocationGridPointList['geolocationGridPoint'][n]['line'])\n",
    "        GEOgrid['pixel'][n] = int(geolocationGridPointList['geolocationGridPoint'][n]['pixel'])\n",
    "        GEOgrid['incidenceAngle'][n] = float(geolocationGridPointList['geolocationGridPoint'][n]['incidenceAngle'])\n",
    "        GEOgrid['elevationAngle'][n] = float(geolocationGridPointList['geolocationGridPoint'][n]['elevationAngle'])\n",
    "\n",
    "\n",
    "    # find zero pixel to reshape grid points to array\n",
    "    ind = find(GEOgrid['pixel'] == 0)\n",
    "    GEOgrid['pixel'] = reshape(GEOgrid['pixel'], (ind.size, GEOgrid['lats'].size/ind.size))\n",
    "    GEOgrid['line']  = reshape(GEOgrid['line'], (ind.size, GEOgrid['lats'].size/ind.size))\n",
    "    GEOgrid['lats']  = reshape(GEOgrid['lats'], (ind.size, GEOgrid['lats'].size/ind.size))\n",
    "    GEOgrid['lons']  = reshape(GEOgrid['lons'], (ind.size, GEOgrid['lats'].size/ind.size))\n",
    "    GEOgrid['incidenceAngle'] = reshape(GEOgrid['incidenceAngle'], (ind.size, GEOgrid['lats'].size/ind.size))\n",
    "    GEOgrid['elevationAngle'] = reshape(GEOgrid['elevationAngle'], (ind.size, GEOgrid['lats'].size/ind.size))\n",
    "\n",
    "    return GEOgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# READ the CALIBRATION LUTs\n",
    "\n",
    "def read_clbrtn_luts(fn, fileLocation, polarization):\n",
    "    # The calibration data set contains calibration information\n",
    "    # and the beta nought, sigma nought, gamma and digital\n",
    "    # number (DN) Look-up Tables (LUT)s that can be used for\n",
    "    # absolute product calibration.\n",
    "\n",
    "    # We take only the calibrationVector record\n",
    "    # This record holds the calibration vectors and associated fields required to\n",
    "    # derive radiometrically calibrated imagery from the image MDS.\n",
    "\n",
    "    # open the fileLocation\n",
    "\n",
    "    # calibration = open(inpath + fileLocation['calibrations1aiwgrd' + polarization], \"r\") # Open a file in read-only mode\n",
    "    # calibration = calibration.read() # read the file object\n",
    "\n",
    "    calibration = zf.read(fn[:-4] + '.SAFE' + fileLocation['calibration' + fn.lower().replace(\"_\",\"\")[0:8] + polarization][1:])\n",
    "    calibration = xmltodict.parse(calibration) # Parse the read document string\n",
    "\n",
    "    calibrationVectorList = calibration['calibration']['calibrationVectorList']\n",
    "\n",
    "    cLUTs = {} # empty dict for CALIBRATION LUTs\n",
    "\n",
    "    cLUTs['line']  = zeros( ( int(calibrationVectorList['@count']), 1), dtype=int )\n",
    "    cLUTs['pixel'] = zeros( (cLUTs['line'] .shape[0], int(calibrationVectorList['calibrationVector'][0]['pixel']['@count'])), dtype=int )\n",
    "    cLUTs['sigmaNought']  = zeros( cLUTs['pixel'].shape, dtype=float)\n",
    "\n",
    "    # read Calibration Vector points\n",
    "    for n in range(int(calibrationVectorList['@count'])):\n",
    "        cLUTs['line'][n] = int(calibrationVectorList['calibrationVector'][n]['line'])\n",
    "        pixel_     = calibrationVectorList['calibrationVector'][0]['pixel']['#text']\n",
    "        cLUTs['pixel'][n,:] = asarray(pixel_.split(' '), dtype=int)\n",
    "        sigmaNought_     = calibrationVectorList['calibrationVector'][0]['sigmaNought']['#text']\n",
    "        cLUTs['sigmaNought'][n,:] = asarray(sigmaNought_.split(' '), dtype=float)\n",
    "\n",
    "    return cLUTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# READ the NOISE LUTs\n",
    "\n",
    "def read_noise_luts(fn, fileLocation, polarization):\n",
    "    # The L1 Noise ADS provides a LUT – with values provided in linear power – \n",
    "    # that can be used to derive calibrated noise profiles which match the calibrated GRD data.\n",
    "\n",
    "    # open the fileLocation\n",
    "\n",
    "    noise = zf.read(fn[:-4] + '.SAFE' + fileLocation['noise' + fn.lower().replace(\"_\",\"\")[0:8] + polarization][1:])\n",
    "    noise = xmltodict.parse(noise) # Parse the read document string\n",
    "\n",
    "    noiseVectorList = noise['noise']['noiseVectorList']\n",
    "\n",
    "    nLUTs = {} # empty dict for NOISE LUTs\n",
    "\n",
    "    nLUTs['line']  = zeros( ( int(noiseVectorList['@count']), 1), dtype=int )\n",
    "    nLUTs['pixel'] = zeros( (nLUTs['line'] .shape[0], int(noiseVectorList['noiseVector'][0]['pixel']['@count'])), dtype=int )\n",
    "    nLUTs['noiseLut']  = zeros( nLUTs['pixel'].shape, dtype=float)\n",
    "\n",
    "    # read Calibration Vector points\n",
    "    for n in range(int(noiseVectorList['@count'])):\n",
    "        nLUTs['line'][n] = int(noiseVectorList['noiseVector'][n]['line'])\n",
    "        pixel_     = noiseVectorList['noiseVector'][0]['pixel']['#text']\n",
    "        nLUTs['pixel'][n,:] = asarray(pixel_.split(' '), dtype=int)\n",
    "        noiseLut_     = noiseVectorList['noiseVector'][0]['noiseLut']['#text']\n",
    "        nLUTs['noiseLut'][n,:] = asarray(noiseLut_.split(' '), dtype=float)\n",
    "\n",
    "    return nLUTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# inpath = '/media/SOLabNFS2/tmp/sentinel-1/'\n",
    "\n",
    "# fileNameList = []\n",
    "# for _dir, sub_dir, _files in os.walk(inpath):\n",
    "#     for fileName in _files:\n",
    "#         if fileName.startswith('S1A') and fileName.endswith('.zip') and fileName.find('RAW')==-1:\n",
    "#             fileNameList.append(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def xml2geo(self):\n",
    "#         \"\"\"\n",
    "#         Reading geolocation grids from attributes\n",
    "#         One may note that Ground Range, Multi-Look, Detected (GRD) products\n",
    "#         lie in the ground range by azimuth surface,\n",
    "#         with image coordinates oriented along ground range and flight direction.\n",
    "#         Slant Range, Single-Look Complex (SLC) products\n",
    "#         are images in the slant range by azimuth imaging plane,\n",
    "#         in the image plane of satellite data acquisition.\n",
    "#         \"\"\"\n",
    "\n",
    "# inpath = '/media/SOLabNFS2/tmp/sentinel-1/S1A_IW_GRDH_1SDV_20141004T155619_20141004T155644_002682_002FE5_BE58.SAFE/'\n",
    "inpath = '/media/SOLabNFS2/tmp/sentinel-1/'\n",
    "\n",
    "# READ THE MANIFEST - top level\n",
    "\n",
    "# manifest = open(inpath + \"manifest.safe\", \"r\") # Open a file in read-only mode\n",
    "# manifest = manifest.read()      # read the file object\n",
    "\n",
    "# open zip file without extraction\n",
    "# finnGulf\n",
    "# fn = 'S1A_IW_GRDH_1SDV_20141004T155619_20141004T155644_002682_002FE5_BE58.zip'\n",
    "\n",
    "# Svalbard-Barents\n",
    "inpath = '/media/SOLabNFS2/tmp/sentinel-1/Svalbard-Barents/'\n",
    "fileNameList = ['S1A_EW_GRDH_1SDH_20141003T071321_20141003T071421_002662_002F6B_AFCF.zip',\n",
    "                 'S1A_EW_GRDH_1SDH_20141003T071221_20141003T071321_002662_002F6B_0F56.zip',\n",
    "                 'S1A_EW_GRDH_1SDH_20141003T071117_20141003T071221_002662_002F6B_CAFE.zip',\n",
    "                 'S1A_EW_GRDH_1SDH_20141004T061601_20141004T061701_002676_002FBD_3300.zip',\n",
    "                 'S1A_EW_GRDH_1SDH_20141004T061701_20141004T061800_002676_002FBD_EF64.zip',\n",
    "                 'S1A_EW_GRDM_1SDH_20141004T061601_20141004T061701_002676_002FBD_B433.zip',\n",
    "                 'S1A_EW_GRDM_1SDH_20141004T061357_20141004T061501_002676_002FBD_A7E4.zip',\n",
    "                 'S1A_EW_GRDM_1SDH_20141004T061701_20141004T061800_002676_002FBD_89ED.zip',\n",
    "                 'S1A_EW_GRDM_1SDH_20141004T061501_20141004T061601_002676_002FBD_A842.zip',\n",
    "                 'S1A_EW_GRDH_1SDH_20141004T061501_20141004T061601_002676_002FBD_4B66.zip',\n",
    "                 'S1A_EW_GRDH_1SDH_20141004T061357_20141004T061501_002676_002FBD_D530.zip',\n",
    "                 'S1A_EW_GRDM_1SDH_20141003T151915_20141003T152019_002667_002F88_B77B.zip',\n",
    "                 'S1A_EW_GRDM_1SDH_20141003T152119_20141003T152229_002667_002F88_1BCA.zip',\n",
    "                 'S1A_EW_GRDH_1SDH_20141003T152119_20141003T152229_002667_002F88_8003.zip',\n",
    "                 'S1A_EW_GRDH_1SDH_20141003T152019_20141003T152119_002667_002F88_9106.zip',\n",
    "                 'S1A_EW_GRDH_1SDH_20141003T151915_20141003T152019_002667_002F88_C200.zip',\n",
    "                 'S1A_EW_GRDH_1SDH_20141003T134257_20141003T134338_002666_002F83_5FD6.zip',\n",
    "                 'S1A_EW_GRDH_1SDH_20141003T134057_20141003T134157_002666_002F83_7D9C.zip',\n",
    "                 'S1A_EW_GRDH_1SDH_20141003T134157_20141003T134257_002666_002F83_30DE.zip',\n",
    "                 'S1A_EW_GRDH_1SDH_20141003T133957_20141003T134057_002666_002F83_0BE7.zip',\n",
    "                 'S1A_IW_GRDH_1SDV_20150506T045446_20150506T045511_005796_00772F_623B.zip',\n",
    "                 'S1A_IW_GRDH_1SDV_20150506T161536_20150506T161601_005803_00775C_25DB.zip']\n",
    "\n",
    "# inpath = '/media/SOLabNFS2/tmp/sentinel-1/'\n",
    "# fileNameList = ['S1A_IW_GRDH_1SDV_20141004T155619_20141004T155644_002682_002FE5_BE58.zip']\n",
    "\n",
    "# for presentation nice wind over Svalbard\n",
    "# fn = fileNameList[9]\n",
    "\n",
    "fn = fileNameList[-1]\n",
    "\n",
    "# Testing readS1.py\n",
    "inpath = '/media/SOLabNFS2/store/satellite/sentinel-1/'\n",
    "# fn = 'S1A_IW_GRDH_1SSV_20141117T020131_20141117T020200_003315_003D72_EF86.zip'\n",
    "fn = 'S1A_IW_GRDH_1SDV_20141104T043153_20141104T043218_003127_003979_7F85.zip'\n",
    "\n",
    "inpath  = '/media/SOLabNFS2/tmp/different_SAR/sentinel-1/Ania_Ladoga_29_May_2015/'\n",
    "fn = 'S1A_EW_GRDM_1SDH_20150517T153117_20150517T153221_005963_007AED_56B0.zip'\n",
    "\n",
    "inpath = '/media/SOLabNFS2/tmp/different_SAR/sentinel-1/'\n",
    "fn = 'S1A_IW_GRDH_1SDV_20150519T213443_20150519T213512_005996_007BA4_89FC.zip'\n",
    "\n",
    "inpath = '/media/SOLabNFS2/store/satellite/sentinel-1/'\n",
    "fn = 'S1A_EW_GRDM_1SSH_20150603T222335_20150603T222440_006215_0081CB_A701.zip'\n",
    "\n",
    "zf = zipfile.ZipFile(inpath+fn, 'r')\n",
    "\n",
    "manifest = zf.read(fn[:-4] + '.SAFE/manifest.safe')\n",
    "manifest = xmltodict.parse(manifest) # Parse the read document string\n",
    "\n",
    "# we have different XML/GeoTIFF fileLocations for vv-vh (or hh-hv) products, respectively\n",
    "# create new dict with file paths to the fileLocations\n",
    "fileLocation = {} # empty dict\n",
    "dataObject = manifest['xfdu:XFDU']['dataObjectSection']['dataObject']\n",
    "for n in range(len(dataObject)):\n",
    "    if len(dataObject[n]['@ID']) > 45:\n",
    "        k = dataObject[n]['@ID'][0:-45] # get the new key from @ID\n",
    "    else:\n",
    "        k = dataObject[n]['@ID'] # get the new key from @ID\n",
    "    v = str(dataObject[n]['byteStream']['fileLocation']['@href']) # get the dict.value\n",
    "    fileLocation[k] = v # assign to new dict\n",
    "#     locals()['fileLocation_'+k]=v # create local variable from 'fileLocation' dict.key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the productType/polarization\n",
    "\n",
    "metadataObject = manifest['xfdu:XFDU']['metadataSection']['metadataObject']\n",
    "for n in range(len(metadataObject)):\n",
    "    if metadataObject[n]['@ID'] == 'generalProductInformation':\n",
    "        productType = metadataObject[n]['metadataWrap']['xmlData']['s1sarl1:standAloneProductInformation']['s1sarl1:productType']\n",
    "        transmitterReceiverPolarisation = metadataObject[n]['metadataWrap']['xmlData']['s1sarl1:standAloneProductInformation']['s1sarl1:transmitterReceiverPolarisation']\n",
    "\n",
    "polarization = []\n",
    "for p in range(0,len(transmitterReceiverPolarisation[0].lower())):\n",
    "    if len(transmitterReceiverPolarisation[0].lower()) == 1:\n",
    "        polarization = transmitterReceiverPolarisation.lower()\n",
    "    else:\n",
    "        polarization.append(transmitterReceiverPolarisation[p].lower())\n",
    "# If only one polarization, it is represented as basestring, we make it a list, to avoid mistakes in loops\n",
    "if isinstance(polarization, basestring):\n",
    "    polarization = [polarization]\n",
    "print \"Available polarizations: \\'%s\\'\" %polarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%timeit -n 1 -r 1\n",
    "\n",
    "# set default resolution\n",
    "resolution = 800\n",
    "if resolution is None:\n",
    "    resolution = 80\n",
    "\n",
    "raw_counts = {}\n",
    "lats_2 = {}\n",
    "lons_2 = {}\n",
    "incidenceAngle_2 = {}\n",
    "sigmaNought_2 = {}\n",
    "noiseLut_2 = {}\n",
    "sigma0 = {}\n",
    "\n",
    "# NB! if len(polarization[0]) == 1 then there is only one polarization, meaning polarization=='vv'\n",
    "# READ the ANNOTATION\n",
    "GEOgrid = read_anotation(fn, fileLocation, polarization[0])\n",
    "\n",
    "# READ the CALIBRATION LUTs\n",
    "cLUTs = read_clbrtn_luts(fn, fileLocation, polarization[0])\n",
    "\n",
    "# READ the NOISE LUTs\n",
    "nLUTs = read_noise_luts(fn, fileLocation, polarization[0])\n",
    "\n",
    "# Find scale to reduce image to the specified resolution\n",
    "arrShape =  asarray([GEOgrid['numberOfLines'], GEOgrid['numberOfSamples']])\n",
    "# scale = resolution/round(mean(asarray(distancelib.getPixelResolution(GEOgrid['lats'], \\\n",
    "#                                                                      GEOgrid['lons'], \\\n",
    "#                                                                      arrShape, 'km'))*1e3))\n",
    "scale = floor(resolution/asarray([GEOgrid['azimuthPixelSpacing'],GEOgrid['rangePixelSpacing']]))\n",
    "\n",
    "for p in polarization:\n",
    "    print \"Reading raw_counts: \\'%s\\' polarization\" %p\n",
    "    # READ THE RAW_COUNTS from GRD image\n",
    "    raw_counts[p], ext, spa = read_raw_counts(fn, fileLocation, p, scale, GEOgrid)\n",
    "\n",
    "\n",
    "#  ----------------------------------\n",
    "# INTERPOLATE DATA\n",
    "# Interpolate Geolocation grid points and calibration LUTs onto grid of raw_counts.shape\n",
    "\n",
    "# Serial Processing\n",
    "\n",
    "# Serial loop is faster than the Parallel Loop (see appropriate ipnb file)\n",
    "# 1 loops, best of 1: 31.5 s per loop\n",
    "# %%timeit -n 1 -r 1\n",
    "\n",
    "# create new grid of raw_counts shape\n",
    "# line_2 = arange(arrShape[0])[::scale[0]]\n",
    "# pixel_2 = arange(arrShape[1])[::scale[1]]\n",
    "line_2  = arange(arrShape[0])[ext[0]:ext[2]][::spa[0]]\n",
    "pixel_2 = arange(arrShape[1])[ext[1]:ext[3]][::spa[1]]\n",
    "\n",
    "\n",
    "# Fool Proof: if LonLims out of -180:+180 range after interpolation => correct\n",
    "# if lons overlap both negative and positive values from -180 to 180,\n",
    "# meaning the image covering Pole\n",
    "# I have tried interpolating using kx,ky=1 => linear interpolation, but that is not working very good\n",
    "# using griddata with \"nearest\" method does not work as well\n",
    "# I'll have to interpolate by hand as for MODIS:\n",
    "# Try to interpolate rows, then coloumns - too complicated\n",
    "# try using Spline but befor removing all negative values\n",
    "\n",
    "# Interpolate onto a new grid\n",
    "if (GEOgrid['lons'].min() < 0) & (GEOgrid['lons'].max()>0):\n",
    "#     pixel_2m, line_2m = meshgrid(pixel_2, line_2)\n",
    "#     lats_2 = griddata((GEOgrid['line'].flatten(), GEOgrid['pixel'].flatten()),\\\n",
    "#                       GEOgrid['lats'].flatten(),\\\n",
    "#                       (line_2m, pixel_2m), method='nearest')\n",
    "#     lons_2 = griddata((GEOgrid['line'].flatten(), GEOgrid['pixel'].flatten()),\\\n",
    "#                       GEOgrid['lons'].flatten(),\\\n",
    "#                       (line_2m, pixel_2m), method='nearest')\n",
    "    lns = GEOgrid['lons'].copy()\n",
    "    pxl = GEOgrid['pixel']\n",
    "    lin = GEOgrid['line']\n",
    "\n",
    "    # print ((lin[argrelmin(lns[:,0])] - lin[argrelmax(lns[:,0])])/2).min()\n",
    "    # on smaller grid we use negValue to summ, but on finer grid after interpolation\n",
    "    # one have to substract from the shifted grid\n",
    "\n",
    "    # I have tried different variants, looks like\n",
    "    shiftValue = ( GEOgrid['lons'].max() - GEOgrid['lons'].min() )/2\n",
    "    # is the best one\n",
    "    \n",
    "    negInd = lns<0\n",
    "    negValue = -2*lns.min()\n",
    "\n",
    "    lns[lns<0] = lns[lns<0]+negValue\n",
    "    lons_2 = RectBivariateSpline(GEOgrid['line'][:,0], GEOgrid['pixel'][0,:],\\\n",
    "                                 lns, kx=2, ky=2)(line_2, pixel_2)\n",
    "    lons_2[lons_2>shiftValue] = lons_2[lons_2>shiftValue]-negValue\n",
    "else:\n",
    "    lats_2 = RectBivariateSpline(GEOgrid['line'][:,0], GEOgrid['pixel'][0,:],\\\n",
    "                                 GEOgrid['lats'], kx=2, ky=2)(line_2, pixel_2)\n",
    "    lons_2 = RectBivariateSpline(GEOgrid['line'][:,0], GEOgrid['pixel'][0,:],\\\n",
    "                                 GEOgrid['lons'], kx=2, ky=2)(line_2, pixel_2)\n",
    "\n",
    "for p in polarization:\n",
    "    print \"Interpolating LUTs: \\'%s\\' polarization\" %p\n",
    "\n",
    "    # interpolate incidenceAngle\n",
    "    incidenceAngle_2[p] = RectBivariateSpline(GEOgrid['line'][:,0], GEOgrid['pixel'][0,:], GEOgrid['incidenceAngle'], kx=2, ky=2)(line_2, pixel_2)\n",
    "\n",
    "    # interpolate sigmaNought\n",
    "    sigmaNought_2[p] = RectBivariateSpline(cLUTs['line'][:,0], cLUTs['pixel'][0,:], cLUTs['sigmaNought'], kx=2, ky=2)(line_2, pixel_2)\n",
    "\n",
    "    # interpolate noiseLut\n",
    "    noiseLut_2[p] = RectBivariateSpline(nLUTs['line'][:,0], nLUTs['pixel'][0,:], nLUTs['noiseLut'], kx=2, ky=2)(line_2, pixel_2)\n",
    "\n",
    "    # Apply Calibration, remove the thermal noise estimation and Convert to Intensity\n",
    "    # for VH, HV - multiply S1 noiseLUTs by nLtCoeff=1e10\n",
    "    # for VV, HH - multiply S1 noiseLUTs by nLtCoeff=sqrt(2)*1e10\n",
    "    if p=='vv' or p=='hh':\n",
    "        nLtCoeff=sqrt(2)*1e10\n",
    "    elif p=='vh' or p=='hv':\n",
    "        nLtCoeff=1e10\n",
    "    #~ For production purposes use smaller noise coeficient to\n",
    "    #~ avoid infinite values when calculating sigma0 in dB with log10\n",
    "    #~ when substracting noise from low wind areas with smaller radar returns\n",
    "    # New data after 2015 in EW GRDM mode hase correct noise LUTs, so we check for that\n",
    "    if noiseLut_2[p].mean() <= 1e-9 and noiseLut_2[p].min() <= 1e-10:\n",
    "        nLtCoeff=0.78e10\n",
    "    else:\n",
    "        nLtCoeff=1\n",
    "\n",
    "    sigma0[p] = ( double(raw_counts[p])**2 - noiseLut_2[p]*nLtCoeff )/sigmaNought_2[p]**2\n",
    "\n",
    "# Close ZIP-file\n",
    "zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from scipy.signal import argrelmin, argrelmax\n",
    "# # from scipy.interpolate import interp1d\n",
    "\n",
    "# lns = GEOgrid['lons'].copy()\n",
    "# pxl = GEOgrid['pixel']\n",
    "# lin = GEOgrid['line']\n",
    "\n",
    "# print ((lin[argrelmin(lns[:,0])] - lin[argrelmax(lns[:,0])])/2).min()\n",
    "# on smaller grid we use negValue to summ, but on finer grid after interpolation\n",
    "# one have to substract from the shifted grid\n",
    "\n",
    "# I have tried different variants, looks like\n",
    "# shiftValue = ( GEOgrid['lons'].max() - GEOgrid['lons'].min() )/2\n",
    "# is the best one\n",
    "\n",
    "# shiftValue = zeros(lns.shape[1])\n",
    "# for x in range(0,lns.shape[1]):\n",
    "#     if not argrelmin(lns[:,x])[0]:\n",
    "#         shiftValue[x] =  -1*(lns[argrelmax(lns[:,x])]).min()\n",
    "#     else:\n",
    "#         shiftValue[x] =  -1*((lns[argrelmin(lns[:,x])] - lns[argrelmax(lns[:,x])])/2).min()\n",
    "\n",
    "# shiftValue = shiftValue.max()\n",
    "\n",
    "\n",
    "\n",
    "# shiftValue = zeros(lns.shape[1])\n",
    "# for x in range(0,lns.shape[1]):\n",
    "#     if not argrelmin(lns[:,x])[0]:\n",
    "#         shiftValue[x] =  -1*(lns[argrelmax(lns[:,x])]).min()\n",
    "#     else:\n",
    "#         shiftValue[x] =  -1*((lns[argrelmin(lns[:,x])] - lns[argrelmax(lns[:,x])])/2).min()\n",
    "\n",
    "# shiftValue_ = interp1d(GEOgrid['pixel'][0,:], shiftValue, bounds_error=False)(pixel_2)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.hold(True)\n",
    "# plt.plot(GEOgrid['pixel'][0,:], shiftValue, 'r.')\n",
    "# plt.plot(pixel_2, shiftValue_, 'b-')\n",
    "\n",
    "# shiftValue =  -1*((lns[argrelmin(lns[:,0])] - lns[argrelmax(lns[:,0])])/2).min()\n",
    "\n",
    "# negInd = lns<0\n",
    "# negValue = -2*lns.min()\n",
    "# shiftValue = ( GEOgrid['lons'].max() - GEOgrid['lons'].min() )/2\n",
    "\n",
    "# # print shiftValue, negValue\n",
    "\n",
    "# lns[lns<0] = lns[lns<0]+negValue\n",
    "# lons_2_ = RectBivariateSpline(GEOgrid['line'][:,0], GEOgrid['pixel'][0,:],\\\n",
    "#                              lns, kx=2, ky=2)(line_2, pixel_2)\n",
    "# lons_2 = lons_2_.copy()\n",
    "# lons_2[lons_2>shiftValue] = lons_2[lons_2>shiftValue]-negValue\n",
    "\n",
    "# plt.figure(figsize=(21,8))\n",
    "# plt.subplot(141)\n",
    "# plt.imshow(GEOgrid['lons'])\n",
    "# plt.colorbar()\n",
    "# plt.subplot(142)\n",
    "# plt.imshow(lns)\n",
    "# plt.colorbar()\n",
    "# plt.subplot(143)\n",
    "# plt.imshow(lons_2_)\n",
    "# plt.colorbar()\n",
    "# plt.subplot(144)\n",
    "# plt.imshow(lons_2)\n",
    "# plt.colorbar()\n",
    "\n",
    "# plt.figure() \n",
    "# plt.plot(GEOgrid['line'][:,0], GEOgrid['lons'][:,0], 'g.')\n",
    "# plt.plot(line_2, lons_2[:,0], 'b-')\n",
    "\n",
    "# print GEOgrid['lons'].min(), GEOgrid['lons'].max()\n",
    "# print lons_2.min(), lons_2.max()\n",
    "# print lons_2.min()-GEOgrid['lons'].min(), lons_2.max()-GEOgrid['lons'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Bullshit - too complicated\n",
    "# from scipy.signal import argrelmin, argrelmax\n",
    "# from numpy import concatenate\n",
    "\n",
    "# lons_2l = zeros([GEOgrid['lons'].shape[0], raw_counts[p].shape[1]])\n",
    "\n",
    "# for line in range(0,GEOgrid['lons'].shape[1]):\n",
    "\n",
    "#     lns = GEOgrid['lons'][line,:]\n",
    "#     pxl = GEOgrid['pixel'][line,:]\n",
    "\n",
    "#     # lons_2 = interp1d(pxl, lns)(pixel_2)\n",
    "\n",
    "#     miind = argrelmin(lns)[0]\n",
    "#     maind = argrelmax(lns)[0]\n",
    "#     midpxl = (pxl[maind] + pxl[miind])/2\n",
    "#     midpxl_2 = pixel_2.shape[0]/2\n",
    "    \n",
    "#     if not miind or not maind:\n",
    "#         lons_2l[line,:] = interp1d(pxl, lns, bounds_error=False)(pixel_2)\n",
    "#     else:\n",
    "#         lns_2 = interp1d(pxl[0:maind], lns[0:maind], bounds_error=False)(pixel_2[0:midpxl_2])\n",
    "#         lns_2_ = interp1d(pxl[maind:], lns[maind:], bounds_error=False)(pixel_2[midpxl_2:])\n",
    "#         lons_2l[line,:] = concatenate((lns_2, lns_2_), axis=0)\n",
    "\n",
    "# lons_2p = zeros(raw_counts[p].shape)\n",
    "\n",
    "# lin = GEOgrid['line'][:,0]\n",
    "\n",
    "# for pixel in range(0,lons_2l.shape[1]):\n",
    "\n",
    "#     lns = lons_2l[:,pixel]\n",
    "\n",
    "#     # lons_2 = interp1d(pxl, lns)(pixel_2)\n",
    "\n",
    "#     miind = argrelmin(lns)[0]\n",
    "#     maind = argrelmax(lns)[0]\n",
    "#     midpxl = (lin[maind] + lin[miind])/2\n",
    "#     midpxl_2 = line_2.shape[0]/2\n",
    "    \n",
    "#     print miind, maind\n",
    "\n",
    "#     if not miind or not maind:\n",
    "#         lons_2p[:,pixel] = interp1d(lin, lns, bounds_error=False)(pixel_2)\n",
    "#     else:\n",
    "#         lns_2 = interp1d(lin[0:maind], lns[0:maind], bounds_error=False)(line_2[0:midpxl_2])\n",
    "#         lns_2_ = interp1d(lin[maind:], lns[maind:], bounds_error=False)(line_2[midpxl_2:])\n",
    "#         lons_2p[:,pixel] = concatenate((lns_2, lns_2_), axis=0)\n",
    "\n",
    "# del lns_2, lns_2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lons_2p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GEOgrid['line'][:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GEOgrid['pixel'][0,:], GEOgrid['pixel'][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GEOgrid['line'][0,:], GEOgrid['line'][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lons_2l.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lons_2l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.plot(GEOgrid['pixel'][5,:], GEOgrid['lons'][5,:], 'g.')\n",
    "plt.plot(pixel_2, lons_2, 'b-')\n",
    "plt.plot(pixel_2[0:midpxl_2], lns_2, 'g-')\n",
    "plt.plot(pixel_2[midpxl_2:], lns_2_, 'g-')\n",
    "plt.plot(pixel_2, lns_2__, 'r-')\n",
    "# plt.plot(GEOgrid['pixel'][5,:], lns, 'r.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(GEOgrid['lons'])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(lons_2)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(GEOgrid['lons'][-1,:], 'g.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(line_2,lons_2[:,0], 'b-')\n",
    "plt.plot(line_2,lons_2[:,-1], 'r--')\n",
    "plt.plot(GEOgrid['line'][:,0],GEOgrid['lons'][:,0], 'g.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(line_2,lats_2[:,0])\n",
    "plt.plot(line_2,lats_2[:,-1], 'r--')\n",
    "plt.plot(GEOgrid['line'][:,0],GEOgrid['lats'][:,0], 'g.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(pixel_2,lats_2[0,:])\n",
    "plt.plot(pixel_2,lats_2[-1,:], 'r--')\n",
    "plt.plot(GEOgrid['pixel'][0,:],GEOgrid['lats'][0,:], 'g.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print GEOgrid['lats'].min(), GEOgrid['lats'].max(), lats_2.min(), lats_2.max(), lons_2.min(), lons_2.max(), GEOgrid['lons'].min(), GEOgrid['lons'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.imshow(sigma0['hh'], vmin=0, vmax=0.05)\n",
    "plt.gray()\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(GEOgrid['elevationAngle'][:], '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scale = 1\n",
    "\n",
    "sigma0w = {}\n",
    "roughness = {}\n",
    "\n",
    "print \"Scale set to: \\'%s\\' \" %scale\n",
    "\n",
    "if len(polarization[0])>=2: # if 2 polarizations\n",
    "    for p in polarization:\n",
    "        print \"Filtering Image: \\'%s\\' polarization\" %p\n",
    "\n",
    "        # filter the image\n",
    "        sigma0w[p] = wiener(sigma0[p][::scale,::scale], mysize=(7,7), noise=None)\n",
    "#         sigma0w[p] = sigma0[p]\n",
    "elif len(polarization[0])==1: # if only 1 polarization\n",
    "    p = polarization\n",
    "    sigma0w[p] = wiener(sigma0[p][::scale,::scale], mysize=(7,7), noise=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# S1 Pixel resolution\n",
    "# we use pxlResSAR for further GSHHS rasterizing and reprojecting data with pyresample\n",
    "\n",
    "lonlim = (lons_2[::scale,::scale].min(),lons_2[::scale,::scale].max())\n",
    "latlim = (lats_2[::scale,::scale].min(),lats_2[::scale,::scale].max())\n",
    "\n",
    "# enlarge lonlims for cropping a bit larger area for masking\n",
    "lonlimGSHHS = (lonlim[0]-1.0, lonlim[1]+1.0)\n",
    "latlimGSHHS = (latlim[0]-1.0, latlim[1]+1.0)\n",
    "\n",
    "\n",
    "# Get first guess pixel resolution\n",
    "import distancelib\n",
    "pxlResSARm  = asarray(distancelib.getPixelResolution(lats_2[::scale,::scale], \\\n",
    "                                                     lons_2[::scale,::scale], \\\n",
    "                                                     lons_2[::scale,::scale].shape, 'km'))*1e3\n",
    "pxlResSARdeg  = asarray(distancelib.getPixelResolution(lats_2[::scale,::scale], \\\n",
    "                                                       lons_2[::scale,::scale], \\\n",
    "                                                       lons_2[::scale,::scale].shape, 'deg'))\n",
    "\n",
    "print \"S1 cell resolution, %s deg\"  % str(pxlResSARdeg)\n",
    "print \"S1 cell resolution, %s m\"  % str(pxlResSARm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyresample as pr\n",
    "from pyproj import Proj\n",
    "\n",
    "# Define areas with pyresample\n",
    "swath_def = pr.geometry.SwathDefinition(lons=lons_2[::scale,::scale], lats=lats_2[::scale,::scale])\n",
    "\n",
    "area_def_4326 = swath_area_def(name='Temporal SWATH EPSG Projection 4326', proj='eqc',\n",
    "                          lonlim=lonlimGSHHS, latlim=latlimGSHHS, ellps=\"WGS84\", res=pxlResSARm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the SAR pixel resolution from the area_def for further identical shapes\n",
    "up    = min(latlimGSHHS)\n",
    "down  = max(latlimGSHHS)\n",
    "left  = min(lonlimGSHHS)\n",
    "right = max(lonlimGSHHS)\n",
    "area_extent_deg = (left, down, right, up)\n",
    "\n",
    "area_extent_deg_shape = area_def_4326.shape\n",
    "\n",
    "pxlResSARdeg = asarray( (abs(area_extent_deg[2] - area_extent_deg[0]) / float(area_extent_deg_shape[1]), \\\n",
    "                abs(area_extent_deg[3] - area_extent_deg[1]) / float(area_extent_deg_shape[0])) )\n",
    "\n",
    "pxlResSARm = asarray( (area_def_4326.pixel_size_x, area_def_4326.pixel_size_y) )\n",
    "print \"S1 cell resolution, %s deg\"  % str(pxlResSARdeg)\n",
    "print \"S1 cell resolution, %s m\"  % str(pxlResSARm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply Mask from GSHHS\n",
    "\n",
    "import gshhs_rasterize\n",
    "reload(gshhs_rasterize)\n",
    "\n",
    "# ESRI shapefile containing land polygons\n",
    "shapefile = '/media/SOLabNFS/store/auxdata/coastline/GSHHS_shp/f/GSHHS_f_L1.shp'\n",
    "\n",
    "# reproject GSHHS onto S1 grid before calculations\n",
    "print \"Rasterizing Land Mask\"\n",
    "mask_arr_4326 = gshhs_rasterize.gshhs_rasterize_4326(lonlimGSHHS, latlimGSHHS, \\\n",
    "                                     pxlResSARdeg, area_def_4326.shape, True, \\\n",
    "                                     shapefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask_arr_swath = pr.kd_tree.resample_nearest(area_def_4326, mask_arr_4326, swath_def, \\\n",
    "                                             radius_of_influence=4*pxlResSARm.max(), epsilon=0.5, fill_value=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print area_def_4326.shape, mask_arr_4326.shape\n",
    "print mask_arr_swath.shape, sigma0w[p].shape, swath_def.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Nice Image (Roughness)\n",
    "\n",
    "sigma0wAvg = {}\n",
    "roughnessNrmlzd = {}\n",
    "\n",
    "if len(polarization[0])>=2: # if 2 polarizations\n",
    "    for p in polarization:\n",
    "        print \"Nice Image: \\'%s\\' polarization\" %p\n",
    "        roughness[p] = ma.masked_where(mask_arr_swath, sigma0w[p])\n",
    "        sigma0wAvg[p] = ma.median(roughness[p], axis=0)\n",
    "        roughnessNrmlzd[p] = (roughness[p]-sigma0wAvg[p])/sigma0wAvg[p]\n",
    "elif len(polarization[0])==1: # if only 1 polarization\n",
    "    p = polarization\n",
    "    print \"Nice Image: \\'%s\\' polarization\" %p\n",
    "    roughness[p] = ma.masked_where(mask_arr_swath, sigma0w[p])\n",
    "    sigma0wAvg[p] = ma.median(roughness[p], axis=0)\n",
    "    roughnessNrmlzd[p] = (roughness[p]-sigma0wAvg[p])/sigma0wAvg[p]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# Save images\n",
    "oPath = '/home/mag/tmp/'\n",
    "\n",
    "if len(polarization[0])>=2: # if 2 polarizations\n",
    "    for p in polarization:\n",
    "        print \"Saving Image: \\'%s\\' polarization\" %p\n",
    "        plt.close('all')\n",
    "        oFileName = os.path.join(oPath, fn[:-3]+p+'_bone_r.png')\n",
    "        plt.imsave(oFileName, roughnessNrmlzd[p], vmin=-1, vmax=1, cmap=plt.cm.bone_r)\n",
    "        oFileName = os.path.join(oPath, fn[:-3]+p+'_RdBu_r.png')\n",
    "        plt.imsave(oFileName, roughnessNrmlzd[p], vmin=-1, vmax=1, cmap=plt.cm.RdBu_r)\n",
    "elif len(polarization[0])==1: # if only 1 polarization\n",
    "    p = polarization\n",
    "    print \"Saving Image: \\'%s\\' polarization\" %p\n",
    "    plt.close('all')\n",
    "    oFileName = os.path.join(oPath, fn[:-3]+p+'_bone_r.png')\n",
    "    plt.imsave(oFileName, roughnessNrmlzd[p], vmin=-1, vmax=1, cmap=plt.cm.bone_r)\n",
    "    oFileName = os.path.join(oPath, fn[:-3]+p+'_RdBu_r.png')\n",
    "    plt.imsave(oFileName, roughnessNrmlzd[p], vmin=-1, vmax=1, cmap=plt.cm.RdBu_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reproject\n",
    "\n",
    "roughness_4326 = {}\n",
    "\n",
    "for p in polarization:\n",
    "    print \"Reprojecting Image: \\'%s\\' polarization\" %p\n",
    "\n",
    "    roughness_4326[p] = pr.kd_tree.resample_nearest(swath_def, roughnessNrmlzd[p], area_def_4326, \\\n",
    "                                                 radius_of_influence=4*pxlResSARm.max(), epsilon=0.5, fill_value=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Save images\n",
    "oPath = '/home/mag/tmp/'\n",
    "\n",
    "for p in polarization:\n",
    "    print \"Saving Projected Image: \\'%s\\' polarization\" %p\n",
    "    plt.close('all')\n",
    "    oFileName = os.path.join(oPath+'proj/', fn[:-3]+p+'_4326_bone_r.png')\n",
    "    plt.imsave(oFileName, roughness_4326[p], vmin=-1, vmax=1, cmap=plt.cm.bone_r)\n",
    "    oFileName = os.path.join(oPath+'proj/', fn[:-3]+p+'_4326_RdBu_r.png')\n",
    "    plt.imsave(oFileName, roughness_4326[p], vmin=-1, vmax=1, cmap=plt.cm.RdBu_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = 'vv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.plot(noiseLut_2[p][::scale,::scale].mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.imshow(noiseLut_2[p][::scale,::scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.imshow(incidenceAngle_2[p][::scale,::scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.plot(sigma0wAvg[p])\n",
    "plt.plot(sigma0w[p].mean(axis=0), 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.imshow(roughness[p], vmin=0, vmax=0.01)\n",
    "# plt.imshow(roughness[p], vmin=0, vmax=0.1)\n",
    "plt.gray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(roughnessNrmlzd[p], vmin=-1, vmax=1)\n",
    "plt.set_cmap('bone_r')\n",
    "# plt.set_cmap('seismic')\n",
    "# plt.set_cmap('RdBu_r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.figure(figsize=(16,16/3*double(sigma0w[p].shape[0])/double(sigma0w[p].shape[1])))\n",
    "plt.subplot(121)\n",
    "plt.imshow(roughness[p], vmin=0, vmax=0.1)\n",
    "plt.gray()\n",
    "plt.colorbar()\n",
    "plt.title(p)\n",
    "plt.subplot(122)\n",
    "plt.imshow(roughnessNrmlzd[p], vmin=-1, vmax=1)\n",
    "plt.gray()\n",
    "plt.colorbar()\n",
    "plt.title(p + ' Nrmlzd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(roughnessNrmlzd[p], vmin=-1, vmax=1)\n",
    "# plt.set_cmap('bone_r')\n",
    "# plt.set_cmap('seismic')\n",
    "plt.set_cmap('RdBu_r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.figure(figsize=(16,16/3*double(sigma0w[polarization[0]].shape[0])/double(sigma0w[polarization[0]].shape[1])))\n",
    "plt.subplot(131)\n",
    "plt.imshow(10*log10(sigma0w[polarization[0]]), vmin=-20, vmax=5)\n",
    "plt.gray()\n",
    "plt.colorbar()\n",
    "plt.title(polarization[0])\n",
    "plt.axis('tight')\n",
    "plt.subplot(132)\n",
    "plt.imshow(10*log10(sigma0w[polarization[1]]), vmin=-30, vmax=-10)\n",
    "plt.gray()\n",
    "plt.colorbar()\n",
    "plt.title(polarization[1])\n",
    "plt.axis('tight')\n",
    "# plt.subplot(133)\n",
    "# plt.imshow(roughness[polarization[0]][::scale,::scale], vmin=0, vmax=roughness[polarization[0]].mean())\n",
    "# plt.gray()\n",
    "# plt.colorbar()\n",
    "# plt.title(polarization[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adding Model wind\n",
    "\n",
    "# startTime = datetime.datetime.strptime(\\\n",
    "#                               manifest['xfdu:XFDU']['metadataSection']['metadataObject'][12]\\\n",
    "#                               ['metadataWrap']['xmlData']['safe:acquisitionPeriod']['safe:startTime'],\\\n",
    "#                               \"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "\n",
    "Objects = manifest['xfdu:XFDU']['metadataSection']['metadataObject']\n",
    "    for Object in Objects:\n",
    "        try:\n",
    "            startTime = datetime.datetime.strptime(\n",
    "                Object['metadataWrap']['xmlData']['safe:acquisitionPeriod']['safe:startTime'],\n",
    "                \"%Y-%m-%dT%H:%M:%S.%f\"\n",
    "            )\n",
    "            break\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "ncepGFSmodelWind = ncepGFSmodel(startTime, lats_2, lons_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.figure(figsize=(16,16/3*double(sigma0w[p].shape[0])/double(sigma0w[p].shape[1])))\n",
    "plt.subplot(121)\n",
    "plt.imshow(ncepGFSmodelWind['wind_speed'])\n",
    "plt.jet()\n",
    "plt.colorbar()\n",
    "plt.axis('tight')\n",
    "plt.subplot(122)\n",
    "plt.imshow(ncepGFSmodelWind['wind_dir'])\n",
    "plt.jet()\n",
    "plt.colorbar()\n",
    "plt.axis('tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.close('all')\n",
    "# plt.figure(figsize=(16,4))\n",
    "# plt.subplot(121)\n",
    "# plt.imshow(ncepGFSmodelWind['lats_wind'])\n",
    "# plt.jet()\n",
    "# plt.colorbar()\n",
    "# plt.subplot(122)\n",
    "# plt.imshow(ncepGFSmodelWind['lons_wind'])\n",
    "# plt.jet()\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.close('all')\n",
    "# plt.plot(ncepGFSmodelWind['lons_wind'][0,:])\n",
    "# plt.plot(ncepGFSmodelWind['lats_wind'][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reprojecting data\n",
    "\n",
    "import distancelib\n",
    "\n",
    "# Pixel resolution\n",
    "# we use pxlResWind/pxlResSAR for further pyresample radius_of_influence and sigmas\n",
    "pxlResWind = asarray(distancelib.getPixelResolution(ncepGFSmodelWind['lats_wind'], \\\n",
    "                                                    ncepGFSmodelWind['lons_wind'], \\\n",
    "                                                    ncepGFSmodelWind['lons_wind'].shape, 'km'))\n",
    "# pxlResSAR  = asarray(distancelib.getPixelResolution(lats_2, lons_2, lons_2.shape, 'km'))*1e3\n",
    "\n",
    "# Note pxlResWind is in KM, multiply by 1e3 for meters\n",
    "print \"S1 cell resolution, %s m\"  % pxlResSARm\n",
    "print \"Wind cell resolution, %s km\" % pxlResWind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import RectSphereBivariateSpline\n",
    "\n",
    "def ncepGFSmodel2swath(lats, lons, data, lats_2, lons_2):\n",
    "\n",
    "    func = RectSphereBivariateSpline(lats, lons, data)\n",
    "    data_2 = func.ev(lats_2.ravel()*pi/180, \\\n",
    "                     lons_2.ravel()*pi/180)\\\n",
    "                     .reshape(lats_2.shape)\n",
    "    return data_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reproject NCEP onto S1 grid before calculations\n",
    "# Using RectSphereBivariateSpline - Bivariate spline approximation over a rectangular mesh on a sphere\n",
    "# as it is much more efficiant for full resolution\n",
    "# as well as smoothes nicely the image\n",
    "\n",
    "# We don't want to work with full res wind so scaling the image for about 100m resolution\n",
    "# Adjust scale to get appropriate value\n",
    "scale = 10\n",
    "\n",
    "lts = flipud(ncepGFSmodelWind['lats_wind'])[:,0]*pi/180\n",
    "lns = ncepGFSmodelWind['lons_wind'][0,:]*pi/180\n",
    "\n",
    "lts_2 = lats_2[::scale,::scale]\n",
    "lns_2 = lons_2[::scale,::scale]\n",
    "\n",
    "ncepGFSmodelWindSwath = {}\n",
    "ncepGFSmodelWindSwath['wind_speed'] = ncepGFSmodel2swath(lts, lns, flipud(ncepGFSmodelWind['wind_speed']), lts_2, lns_2)\n",
    "ncepGFSmodelWindSwath['wind_dir']   = ncepGFSmodel2swath(lts, lns, flipud(ncepGFSmodelWind['wind_dir']),   lts_2, lns_2)\n",
    "ncepGFSmodelWindSwath['u']   = ncepGFSmodel2swath(lts, lns, flipud(ncepGFSmodelWind['u']),   lts_2, lns_2)\n",
    "ncepGFSmodelWindSwath['v']   = ncepGFSmodel2swath(lts, lns, flipud(ncepGFSmodelWind['v']),   lts_2, lns_2)\n",
    "    \n",
    "pxlResWindSwath = asarray(distancelib.getPixelResolution(lts_2, \\\n",
    "                                                    lns_2, \\\n",
    "                                                    lns_2.shape, 'km'))\n",
    "\n",
    "print \"Interpolated Wind cell resolution, %s km\" % pxlResWindSwath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.figure(figsize=(16,16/3*double(sigma0w[polarization[0]].shape[0])/double(sigma0w[polarization[0]].shape[1])))\n",
    "plt.subplot(121)\n",
    "plt.imshow(ncepGFSmodelWindSwath['wind_speed'][::33,::33])\n",
    "plt.jet()\n",
    "plt.colorbar()\n",
    "plt.subplot(122)\n",
    "plt.imshow(ncepGFSmodelWindSwath['wind_dir'][::33,::33])\n",
    "plt.jet()\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate bearing from initial lats/lons for further wind calculation\n",
    "# Taking initial values as bearing is more accurate after interpolation than vice versa\n",
    "bearing = zeros((GEOgrid['lons'].shape[0]-1,GEOgrid['lons'].shape[1]))\n",
    "\n",
    "for n in range(0,GEOgrid['lons'].shape[1]):\n",
    "    col = ([GEOgrid['lats'][:-1,n], GEOgrid['lons'][:-1,n]], [GEOgrid['lats'][1:,n], GEOgrid['lons'][1:,n]])\n",
    "    for m in range(0,GEOgrid['lons'].shape[0]-1):\n",
    "        bearing[m][n] = distancelib.bearing(asarray(col[0])[:,m], asarray(col[1])[:,m])\n",
    "\n",
    "# interpolate to raw_counts.shape\n",
    "bearing_2 = imresize(bearing, ncepGFSmodelWindSwath['wind_dir'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.figure(figsize=(16,16/3*double(sigma0w[p].shape[0])/double(sigma0w[p].shape[1])))\n",
    "plt.imshow(bearing_2)\n",
    "plt.jet()\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Wind Speed\n",
    "\n",
    "# windSpeed = {}\n",
    "\n",
    "# # the C-2PO (C-band Cross-Polarized Ocean) model\n",
    "# # B. Zhang and W. Perrie, Cross-polarized synthetic aperture radar:\n",
    "# # A new potential measurement technique for hurricanes, Bull. Amer. Meteor. Soc., pp. 531-541, 2012.\n",
    "# if 'vh' in polarization:\n",
    "#     windSpeed['vh'] = (10*log10(sigma0w['vh']) + 35.652)/0.58\n",
    "# if 'hv' in polarization:\n",
    "#     windSpeed['hv'] = (10*log10(sigma0w['hv']) + 35.652)/0.58\n",
    "\n",
    "# # convert the signal measured in HH into VV polarization before using a GMF from the CMOD family\n",
    "# if 'hh' in polarization:\n",
    "#     alpha=1 # for Sentinel Toolbox alpha=1, initially it was 0.6\n",
    "#     sigma0w['hh2vv'] = sigma0w['hh']*(1+2*tan(incidenceAngle_2['hh'])**2)**2/(1+alpha*tan(incidenceAngle_2['hh'])**2)**2\n",
    "\n",
    "# plt.close('all')\n",
    "# plt.figure(figsize=(16,16/3*double(sigma0w[polarization[0]].shape[0])/double(sigma0w[polarization[0]].shape[1])))\n",
    "# plt.imshow(windSpeed['vh'][::33,::33], vmin=0, vmax=20)\n",
    "# plt.jet()\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def PR_Mouche(theta, phi):\n",
    "    \n",
    "    A_0 = 0.00650704\n",
    "    B_0 = 0.128983\n",
    "    C_0 = 0.992839\n",
    "    A_HALF_PI = 0.00782194\n",
    "    B_HALF_PI = 0.121405\n",
    "    C_HALF_PI = 0.992839\n",
    "    A_PI = 0.00598416\n",
    "    B_PI = 0.140952\n",
    "    C_PI = 0.992885\n",
    "    \n",
    "    P_0 = A_0 * np.exp(B_0* theta) + C_0\n",
    "    P_HALF_PI = A_HALF_PI * np.exp(B_HALF_PI* theta) + C_HALF_PI\n",
    "    P_PI = A_PI * np.exp(B_PI* theta) + C_PI\n",
    "    \n",
    "    C0 = (P_0 + P_PI + 2 * P_HALF_PI) / 4\n",
    "    C1 = (P_0 - P_PI) / 2\n",
    "    C2 = (P_0 + P_PI - 2 * P_HALF_PI) / 4\n",
    "    \n",
    "    P = C0 + C1 * np.cos(np.radians(phi)) + C2 * np.cos(np.radians(2 * phi))\n",
    "    \n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#NB! WINDDIR = 0 WHEN WIND BLOWS TOWARDS RADAR!\n",
    "wind_dir_model_swath_rel = 90 + bearing_2 - ncepGFSmodelWindSwath['wind_dir']\n",
    "\n",
    "if p == 'hh':\n",
    "    PR = PR_Mouche(incidenceAngle_2[p][::scale,::scale], wind_dir_model_swath_rel)\n",
    "    try:\n",
    "        from cmod_gpu import rcs2windOpenCl\n",
    "        wind_speed_asar = rcs2windOpenCl(sar=sigma0w[p]*PR, \\\n",
    "                                         windir=wind_dir_model_swath_rel, \\\n",
    "                                         theta=incidenceAngle_2[p][::scale,::scale])\n",
    "    except Exception:\n",
    "        from cmod_vect import rcs2windPar\n",
    "        wind_speed_asar = rcs2windPar(sigma0w[p]*PR, cmdv=5, \\\n",
    "                                      windir=wind_dir_model_swath_rel, \\\n",
    "                                      theta=incidenceAngle_2[p][::scale,::scale], nprocs=numProcs)\n",
    "elif p == 'vv':\n",
    "    try:\n",
    "        from cmod_gpu import rcs2windOpenCl\n",
    "        wind_speed_asar = rcs2windOpenCl(sar=sigma0w[p], \\\n",
    "                                         windir=wind_dir_model_swath_rel, \\\n",
    "                                         theta=incidenceAngle_2[p][::scale,::scale])\n",
    "    except Exception:\n",
    "        from cmod_vect import rcs2windPar\n",
    "        wind_speed_asar = rcs2windPar(sigma0w[p], cmdv=5, \\\n",
    "                                      windir=wind_dir_model_swath_rel, \\\n",
    "                                      theta=incidenceAngle_2[p][::scale,::scale], nprocs=numProcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wind_speed_asar = ma.masked_where(mask_arr_swath, wind_speed_asar)\n",
    "ncepGFSmodelWindSwath['wind_speed'] = ma.masked_where(mask_arr_swath, ncepGFSmodelWindSwath['wind_speed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.figure(figsize=(16,16/3*double(sigma0w[p].shape[0])/double(sigma0w[p].shape[1])))\n",
    "plt.plot(ncepGFSmodelWindSwath['wind_speed'][1400,:])\n",
    "plt.plot(wind_speed_asar[1400,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.figure(figsize=(16,16/3*double(sigma0w[p].shape[0])/double(sigma0w[p].shape[1])))\n",
    "plt.plot(ncepGFSmodelWindSwath['wind_speed'][:,1500])\n",
    "plt.plot(wind_speed_asar[:,1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BE CAREFULL of U and V \"-\" sign!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_speed = 3\n",
    "max_speed = 13\n",
    "\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(16,16/3*double(sigma0w[p].shape[0])/double(sigma0w[p].shape[1])))\n",
    "plt.subplot(131)\n",
    "plt.imshow(fliplr(ncepGFSmodelWind['wind_speed']), vmin=min_speed, vmax=max_speed, interpolation=\"nearest\")\n",
    "plt.jet()\n",
    "plt.colorbar()\n",
    "plt.axis('tight')\n",
    "plt.quiver(fliplr(ncepGFSmodelWind['u']), -fliplr(ncepGFSmodelWind['v']))\n",
    "\n",
    "X,Y = meshgrid( arange(0,roughness[p].shape[1]),arange(0,roughness[p].shape[0]) )\n",
    "U = ncepGFSmodelWindSwath['u']\n",
    "V = -ncepGFSmodelWindSwath['v']\n",
    "scl = 100\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(ncepGFSmodelWindSwath['wind_speed'], vmin=min_speed, vmax=max_speed)\n",
    "plt.jet()\n",
    "plt.colorbar()\n",
    "plt.axis('tight')\n",
    "plt.quiver(X[::scl,::scl], Y[::scl,::scl], U[::scl,::scl], V[::scl,::scl])\n",
    "\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(wind_speed_asar, vmin=min_speed, vmax=max_speed)\n",
    "plt.jet()\n",
    "plt.colorbar()\n",
    "plt.axis('tight')\n",
    "plt.quiver(X[::scl,::scl], Y[::scl,::scl], U[::scl,::scl], V[::scl,::scl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving figures for presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save images for presentation\n",
    "oPath = '/home/mag/tmp/for_presentation/'\n",
    "\n",
    "for p in polarization:\n",
    "    plt.close('all')\n",
    "    oFileName = os.path.join(oPath, fn[:-39] + '_' + p + '_bone_r.png')\n",
    "    plt.imshow(roughnessNrmlzd[p], vmin=-1, vmax=1, cmap=plt.cm.bone_r)\n",
    "    plt.colorbar()\n",
    "    plt.axis('tight')\n",
    "    plt.savefig(oFileName, dpi=300,\n",
    "                facecolor='None',\n",
    "                bbox_inches='tight',\n",
    "                transparent=True,\n",
    "                pad_inches=0)\n",
    "\n",
    "    plt.close('all')\n",
    "    oFileName = os.path.join(oPath, fn[:-39] + '_' + p + '_RdBu_r.png')\n",
    "    plt.imshow(roughnessNrmlzd[p], vmin=-1, vmax=1, cmap=plt.cm.RdBu_r)\n",
    "    plt.colorbar()\n",
    "    plt.axis('tight')\n",
    "    plt.savefig(oFileName, dpi=300,\n",
    "                facecolor='None',\n",
    "                bbox_inches='tight',\n",
    "                transparent=True,\n",
    "                pad_inches=0)\n",
    "\n",
    "plt.close('all')\n",
    "oFileName = os.path.join(oPath, fn[:-39] + '_' + polarization[0] + '_sigma0w.png')\n",
    "plt.imshow(10*log10(sigma0w[polarization[0]]), vmin=-20, vmax=5)\n",
    "plt.gray()\n",
    "plt.colorbar()\n",
    "plt.axis('tight')\n",
    "plt.savefig(oFileName, dpi=300,\n",
    "            facecolor='None',\n",
    "            bbox_inches='tight',\n",
    "            transparent=True,\n",
    "            pad_inches=0)\n",
    "\n",
    "plt.close('all')\n",
    "oFileName = os.path.join(oPath, fn[:-39] + '_' + polarization[1] + '_sigma0w.png')\n",
    "plt.imshow(10*log10(sigma0w[polarization[1]]), vmin=-30, vmax=-10)\n",
    "plt.gray()\n",
    "plt.colorbar()\n",
    "plt.axis('tight')\n",
    "plt.savefig(oFileName, dpi=300,\n",
    "            facecolor='None',\n",
    "            bbox_inches='tight',\n",
    "            transparent=True,\n",
    "            pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BE CAREFULL of U and V \"-\" sign!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = polarization[0]\n",
    "\n",
    "min_speed = 3\n",
    "max_speed = 13\n",
    "\n",
    "plt.close('all')\n",
    "oFileName = os.path.join(oPath, fn[:-39] + '_' + p + '_wind_ncep.png')\n",
    "plt.imshow(fliplr(ncepGFSmodelWind['wind_speed']), vmin=min_speed, vmax=max_speed, interpolation=\"nearest\")\n",
    "plt.jet()\n",
    "plt.colorbar()\n",
    "plt.axis('tight')\n",
    "plt.quiver(fliplr(ncepGFSmodelWind['u']), -fliplr(ncepGFSmodelWind['v']))\n",
    "plt.savefig(oFileName, dpi=300,\n",
    "            facecolor='None',\n",
    "            bbox_inches='tight',\n",
    "            transparent=True,\n",
    "            pad_inches=0)\n",
    "\n",
    "X,Y = meshgrid( arange(0,roughness[p].shape[1]),arange(0,roughness[p].shape[0]) )\n",
    "U = ncepGFSmodelWindSwath['u']\n",
    "V = -ncepGFSmodelWindSwath['v']\n",
    "scl = 100\n",
    "\n",
    "plt.close('all')\n",
    "oFileName = os.path.join(oPath, fn[:-39] + '_' + p + '_wind_ncep_swath.png')\n",
    "plt.imshow(ncepGFSmodelWindSwath['wind_speed'], vmin=min_speed, vmax=max_speed)\n",
    "plt.jet()\n",
    "plt.colorbar()\n",
    "plt.axis('tight')\n",
    "plt.quiver(X[::scl,::scl], Y[::scl,::scl], U[::scl,::scl], V[::scl,::scl])\n",
    "plt.savefig(oFileName, dpi=300,\n",
    "            facecolor='None',\n",
    "            bbox_inches='tight',\n",
    "            transparent=True,\n",
    "            pad_inches=0)\n",
    "\n",
    "plt.close('all')\n",
    "oFileName = os.path.join(oPath, fn[:-39] + '_' + p + '_wind_S1.png')\n",
    "plt.imshow(wind_speed_asar, vmin=min_speed, vmax=max_speed)\n",
    "plt.jet()\n",
    "plt.colorbar()\n",
    "plt.axis('tight')\n",
    "plt.quiver(X[::scl,::scl], Y[::scl,::scl], U[::scl,::scl], V[::scl,::scl])\n",
    "plt.savefig(oFileName, dpi=300,\n",
    "            facecolor='None',\n",
    "            bbox_inches='tight',\n",
    "            transparent=True,\n",
    "            pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reprojecting data\n",
    "\n",
    "\n",
    "roughness_4326 = pr.kd_tree.resample_nearest(swath_def, roughnessNrmlzd, area_def_4326, \\\n",
    "                                             radius_of_influence=4*pxlResSARm.max(), epsilon=0.5, fill_value=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save png image and kml file\n",
    "\n",
    "import simplekml\n",
    "\n",
    "def create_KML_asar(area_extent, savepath):\n",
    "    kml = simplekml.Kml()\n",
    "\n",
    "    pol = kml.newpolygon(name='area_extent', visibility=1)\n",
    "    pol.tessellate = 1\n",
    "\n",
    "    pol.altitudemode = 'clampToGround'\n",
    "    pol.outerboundaryis.coords = [(area_extent[0], area_extent[1]), (area_extent[2], area_extent[3])]\n",
    "    if type(savepath) == list:\n",
    "        for _savepath in savepath:\n",
    "            kml.save(_savepath)\n",
    "    else:\n",
    "        kml.save(savepath)\n",
    "\n",
    "oPath = '/home/mag/tmp/'\n",
    "oFileName = os.path.join(oPath, fn+'.png')\n",
    "\n",
    "close('all')\n",
    "gray()\n",
    "imsave(oFileName, roughness_masked, vmin=0, vmax=2)\n",
    "create_KML_asar(area_def.area_extent, os.path.join(oPath, fn+'.kml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate tiles\n",
    "\n",
    "import gdal\n",
    "import sys\n",
    "sys.path.append('/usr/bin')\n",
    "from gdal2tiles import GDAL2Tiles\n",
    "\n",
    "def create_asar_tiles(png_filename, tiles_output_dir, proj):\n",
    "    local_argv = ['/usr/bin/gdal2tiles.py', '-p', 'raster', '-r', 'cubic',\n",
    "                  '-s', proj, png_filename, tiles_output_dir]\n",
    "    argv = gdal.GeneralCmdLineProcessor(local_argv)\n",
    "    if argv:\n",
    "        gdal2tiles = GDAL2Tiles(argv[1:])\n",
    "        gdal2tiles.process()\n",
    "\n",
    "create_KML_asar(area_def.area_extent, os.path.join(_path, fileName+'.kml'))\n",
    "\n",
    "tiles_3413_output_dir = os.path.join(oPath, 'tiles')\n",
    "png_3413_filename = oFileName\n",
    "create_asar_tiles(png_3413_filename, tiles_3413_output_dir, 'EPSG:3413')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check the lat/lon/incidenceAngle after interpolation\n",
    "\n",
    "print diff([GEOgrid['incidenceAngle'].min(),incidenceAngle_2.min()])\n",
    "print diff([GEOgrid['incidenceAngle'].max(),incidenceAngle_2.max()])\n",
    "\n",
    "print diff([GEOgrid['lats'].min(),lats_2.min()])\n",
    "print diff([GEOgrid['lats'].max(), lats_2.max()])\n",
    "\n",
    "print diff([GEOgrid['lons'].min(), lons_2.min()])\n",
    "print diff([GEOgrid['lons'].max(), lons_2.max()])\n",
    "\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(16,14))\n",
    "\n",
    "plt.subplot(321)\n",
    "plt.plot(range(0,raw_counts.shape[1]), lats_2[0,:])\n",
    "plt.plot(GEOgrid['pixel'][0,:], GEOgrid['lats'][0,:], 'r.')\n",
    "plt.hold\n",
    "plt.plot(range(0,raw_counts.shape[1]), lats_2[-1,:])\n",
    "plt.plot(GEOgrid['pixel'][-1,:], GEOgrid['lats'][-1,:], 'k.')\n",
    "\n",
    "plt.subplot(322)\n",
    "plt.plot(range(0,raw_counts.shape[0]), lats_2[:,0])\n",
    "plt.plot(GEOgrid['line'][:,0], GEOgrid['lats'][:,0], 'r.')\n",
    "plt.hold\n",
    "plt.plot(range(0,raw_counts.shape[0]), lats_2[:,-1])\n",
    "plt.plot(GEOgrid['line'][:,-1], GEOgrid['lats'][:,-1], 'k.')\n",
    "\n",
    "plt.subplot(323)\n",
    "plt.plot(range(0,raw_counts.shape[1]), incidenceAngle_2[0,:])\n",
    "plt.plot(GEOgrid['pixel'][0,:], GEOgrid['incidenceAngle'][0,:], 'r.')\n",
    "plt.hold\n",
    "plt.plot(range(0,raw_counts.shape[1]), incidenceAngle_2[-1,:])\n",
    "plt.plot(GEOgrid['pixel'][-1,:], GEOgrid['incidenceAngle'][-1,:], 'k.')\n",
    "\n",
    "plt.subplot(324)\n",
    "plt.plot(range(0,raw_counts.shape[0]), incidenceAngle_2[:,0])\n",
    "plt.plot(GEOgrid['line'][:,0], GEOgrid['incidenceAngle'][:,0], 'r.')\n",
    "plt.hold\n",
    "plt.plot(range(0,raw_counts.shape[0]), incidenceAngle_2[:,-1])\n",
    "plt.plot(GEOgrid['line'][:,-1], GEOgrid['incidenceAngle'][:,-1], 'k.')\n",
    "\n",
    "plt.subplot(325)\n",
    "plt.plot(range(0,raw_counts.shape[1]), sigmaNought_2[0,:])\n",
    "plt.plot(cLUTs['pixel'][0,::10], cLUTs['sigmaNought'][0,::10], 'r.')\n",
    "\n",
    "plt.subplot(326)\n",
    "plt.plot(range(0,raw_counts.shape[0]), sigmaNought_2[:,0])\n",
    "plt.plot(cLUTs['line'][:,0], cLUTs['sigmaNought'][:,0], 'r.')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Product:\tS1A_IW_GRDH_1SDV_20141004T155619_20141004T155644_002682_002FE5_BE58_Calib\n",
    "\n",
    "Image-X:\t10215\tpixel\n",
    "Image-Y:\t5465\tpixel\n",
    "Longitude:\t25°19'38\" E\tdegree\n",
    "Latitude:\t59°52'25\" N\tdegree\n",
    "\n",
    "BandName\tValue\tUnit\n",
    "Sigma0_VV:\t19.47602\tintensity\t\n",
    "\n",
    "latitude:\t59.87349\tdeg\n",
    "longitude:\t25.327261\tdeg\n",
    "incident_angle:\t37.08765\tdeg\n",
    "elevation_angle:\t32.87843\tdeg\n",
    "slant_range_time:\t5738716.0\tns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lats_2[5465,10215], lons_2[5465,10215], incidenceAngle_2[p][5465,10215], sigma0[p][5465,10215]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print arcsin((4.740000e+02/6.666194e+02)**2)*180/pi, incidenceAngle_2[p][0,0]\n",
    "print arcsin((4.740000e+02/5.596816e+02)**2)*180/pi, incidenceAngle_2[p][-1,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "\n",
    "ds = gdal.Open(inpath + fileLocation['s1aiwgrd' + polarization])\n",
    "ds.RasterCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds = gdal.Open('/media/data/data/OTHER/RS2 Agulhas and Lion/RS2_SQA_1xQGSS20091224_164846_00000004/imagery_HV.tif')\n",
    "ds.RasterCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds = gdal.Open('/media/SOLabNFS2/tmp/sentinel-1/S1A_IW_SLC__1SDV_20141003T151001_20141003T151028_002667_002F87_7088.SAFE/measurement/s1a-iw1-slc-vv-20141003t151002-20141003t151027-002667-002f87-004.tiff')\n",
    "slc = ds.ReadAsArray()\n",
    "slc.dtype\n",
    "del slc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ----------------------------------\n",
    "# from scipy.interpolate import griddata\n",
    "# from numpy import meshgrid, linspace\n",
    "\n",
    "# Slant Range, Single-Look Complex (SLC) products\n",
    "# are images in the slant range by azimuth imaging plane,\n",
    "# in the image plane of satellite data acquisition.\n",
    "# THAT MEANS that they must be interpolated more carefully using slantRangeTime and azimuthTime as in ASAR\n",
    "\n",
    "# create new grid of raw_counts shape\n",
    "# line_2, pixel_2 = meshgrid(linspace(0, lats.shape[0], raw_counts.shape[0]), linspace(0, lats.shape[1], raw_counts.shape[1]))\n",
    "# Interpolate onto a new grid\n",
    "# lats_2 = griddata((line.ravel(), pixel.ravel()), lats.ravel(), (line_2, pixel_2), method='cubic')\n",
    "# lons_2 = griddata((line.ravel(), pixel.ravel()), lons.ravel(), (line_2, pixel_2), method='cubic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#     # Nice Image (Roughness)\n",
    "#     if p == 'hh':\n",
    "#         ph = (2.20495, -14.3561e-2, 11.28e-4)\n",
    "#         sigma0_hh_ref = exp( ( ph[0]+incidenceAngle_2[p]*ph[1]+incidenceAngle_2[p]**2*ph[2])*log(10) )\n",
    "#         roughness[p] = sigma0w[p]/sigma0_hh_ref\n",
    "#     elif p == 'vv':\n",
    "#         pv = (2.29373, -15.393e-2, 15.1762e-4)\n",
    "#         sigma0_vv_ref = exp( ( pv[0]+incidenceAngle_2[p]*pv[1]+incidenceAngle_2[p]**2*pv[2])*log(10) )\n",
    "#         roughness[p] = sigma0w[p]/sigma0_vv_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "USING minidom\n",
    "\n",
    "from xml.dom import minidom\n",
    "manifest = minidom.parse(inpath + \"manifest.safe\")\n",
    "for node in manifest.getElementsByTagName('dataObject'):\n",
    "    if node.getAttribute('repID') == 's1Level1ProductSchema':\n",
    "        fileLocation.append(node.childNodes[1].childNodes[1].getAttribute('href'))\n",
    "\n",
    "# open first file with minidom\n",
    "xmldoc = minidom.parse(inpath + fileLocation[0])\n",
    "\n",
    "document_file = open(inpath + fileLocation[0], \"r\") # Open a file in read-only mode\n",
    "original_doc = document_file.read() # read the file object\n",
    "document = xmltodict.parse(original_doc) # Parse the read document string\n",
    "\n",
    "# get productType/polarisation from the Annotation Data Set Records (ADSR)\n",
    "document['product']['adsHeader'].keys()\n",
    "productType = xmldoc.getElementsByTagName('productType')[0].childNodes[0].data\n",
    "polarisation = xmldoc.getElementsByTagName('polarisation')[0].childNodes[0].data\n",
    "\n",
    "# get geolocation grid elements by tag name\n",
    "latGrid = xmldoc.getElementsByTagName('latitude')\n",
    "lonGrid = xmldoc.getElementsByTagName('longitude')\n",
    "lineGrid = xmldoc.getElementsByTagName('line')\n",
    "pixelGrid = xmldoc.getElementsByTagName('pixel')\n",
    "\n",
    "# preallocate variables\n",
    "lat = zeros( ( (latGrid).length, 1) )\n",
    "lon = zeros( lat.shape )\n",
    "line = zeros( lat.shape )\n",
    "pixel = zeros( lat.shape )\n",
    "\n",
    "# read Geolocation grid points into line\n",
    "for n in range((latGrid).length):\n",
    "    lat[n] = latGrid[n].childNodes[0].data\n",
    "    lon[n] = lonGrid[n].childNodes[0].data\n",
    "    line[n] = lineGrid[n].childNodes[0].data\n",
    "    pixel[n] = pixelGrid[n].childNodes[0].data\n",
    "\n",
    "# find zero pixel to rehape to array\n",
    "ind = find(pixel == 0)\n",
    "pixel = reshape(pixel, (ind.size, latGrid.length/ind.size))\n",
    "line = reshape(line, (ind.size, latGrid.length/ind.size))\n",
    "lat = reshape(lat, (ind.size, latGrid.length/ind.size))\n",
    "lon = reshape(lon, (ind.size, latGrid.length/ind.size))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# USING PIL IMAGE if no AGG with large file support\n",
    "\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "# get normalization func\n",
    "norm = Normalize(vmin=-1, vmax=+1)\n",
    "# normalize array\n",
    "imRoughness4326 = (norm(roughness_4326[p])*255).astype(np.uint8)\n",
    "# apply colormap to an array\n",
    "imRoughness4326 = (plt.cm.bone_r(imRoughness4326)*255).astype(np.uint8)\n",
    "# convert array to image\n",
    "imRoughness4326 = Image.fromarray(imRoughness4326)\n",
    "# convert to RGBA for transparency\n",
    "imRoughness4326 = imRoughness4326.convert('RGBA')\n",
    "oFileName = os.path.join(oPath+'proj/', fn[:-3]+p+'_4326_bone_r.png')\n",
    "imRoughness4326.save(oFileName)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Using PIL to make all white pixels transparent\n",
    "datas = img.getdata()\n",
    "\n",
    "newData = []\n",
    "for item in datas:\n",
    "    if item[0] == 255 and item[1] == 255 and item[2] == 255:\n",
    "        newData.append((255, 255, 255, 0))\n",
    "    else:\n",
    "        newData.append(item)\n",
    "\n",
    "img.putdata(newData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Areas for download\n",
    "# (minlon, minlat, maxlon, maxlat)\n",
    "Northern Arctic   (-180, 80, 180, 90)\n",
    "Norwegian Sea     (-45, 65, 20, 80)\n",
    "Barents Sea       (20, 60, 60, 80)\n",
    "Kara Sea          (60, 65, 100, 80)\n",
    "Laptev Sea        (100, 70, 140, 80)\n",
    "East Siberian Sea (140, 70, 180, 80)\n",
    "Beaufaurt Sea     (-180, 65, -120, 80)\n",
    "West Greenland    (-120, 60, -45, 80)\n",
    "Baltic            (10, 53, 34, 65)\n",
    "Black Sea         (27, 40, 42, 48)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
